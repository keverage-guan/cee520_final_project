 
 

<!-------------------------------- HEADER -------------------------------------------->

    
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> 
<head>

<title> MTO 27.3: Morrison, Encoding Post-Spectral Sound</title>

<link rel="SHORTCUT ICON" href="https://www.mtosmt.org/gifs/favicon.ico">
<link rel="stylesheet" href="https://www.mtosmt.org/scripts/colorbox.css">
<link rel=StyleSheet href="https://www.mtosmt.org/scripts/mto-tufte.css" type="text/css" media=all>
<link rel="stylesheet" href="//code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

<script src="https://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">_uacct = "UA-968147-1"; urchinTracker();</script>

<script type="text/javascript" src="https://www.mtosmt.org/scripts/expandingMenu.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/dropdownMenu.js"></script>
<!--<script language="JavaScript" type="text/javascript" src="https://www.mtosmt.org/scripts/AC_QuickTime.js"></script>-->
<!--<script type="text/javascript" src="https://www.mtosmt.org/scripts/examples.js"></script>-->
<script type="text/javascript" src="https://www.mtosmt.org/scripts/hover.js"></script>  
<script src="https://code.jquery.com/jquery-1.10.2.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
<script src="https://www.mtosmt.org/scripts/colorbox-master/jquery.colorbox.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/jQueryRotate.2.2.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script>
MathJax.Hub.Config({
    TeX: { noErrors: { disabled: true } }
});
</script>

  <script>
   $(function () {
      $(document).tooltip({
        position: { my: "center bottom-10", at: "center top", },
    content: function () {
              return $(this).prop('title');
          }
      });
  });
  </script>

  <style>
    .ui-tooltip {
      color: #3a3a3a;
      font: 300 14px/20px "Lato", "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
      max-width: 600px;
      box-shadow: 0 0 7px gray;
    }
    ol.mto-alpha {
        list-style: lower-alpha none outside;
    }
   ol.mto-alpha li {
       margin-bottom: 0.75em;
       margin-left: 2em;
       padding-left: 0.5em;
    }
  </style>

    <script language="Javascript">
        $(document).ready(function() {
            $(".mp3").colorbox({iframe:true, internalWidth:360, width:400, internalHeight:100, rel:'mp3', height:150, opacity:0.1, onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });
            $(".youtube").colorbox({iframe:true, innerWidth:640, innerHeight:390, opacity:0.1, rel:'youtube', onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });

      $("a[id^=footnote]").each(function(){
        var fnnum = $(this).attr('id').substring(8);
	var foot_me = '#fndiv'+fnnum;
        $("#footnote" + fnnum).attr('title', $(foot_me).html());

        });


        $("a[id^=citation]").each(function(){
         var separatorPos = $(this).attr('id').lastIndexOf('_');
         var linkid = $(this).attr('id');
         var citeref = $(this).attr('id').substring(8,separatorPos);
         var cite_me = '#citediv'+citeref;
         $("#" + linkid).attr('title', $(cite_me).html());

        });
    });

    </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-968147-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-968147-1');
</script>


<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 

<meta name="citation_title" content="Encoding Post-Spectral Sound: Kaija Saariaho&rsquo;s Early Electronic Music at IRCAM, 1982&ndash;87">

    <meta name="citation_author" content="Morrison, Landon">
      
<meta name="citation_publication_date" content="2021/09/01">
<meta name="citation_journal_title" content="Music Theory Online">
<meta name="citation_volume" content="27">
<meta name="citation_issue" content="3">

</head>

<body>
<div class="bannertop">
	<a id="smt-link" alt="Society for Music Theory" href="https://www.societymusictheory.org">&nbsp;</a>
</div>
		
		<div style = "height:160px; width:900px; background-image: url('../../gifs/banner_blue_grey_900px.png'); background-repeat: no-repeat; background-position: 0px 0px"></div>
		
<!-------------------------------- MENU -------------------------------------------->

  
<div class="dropdown_menu">

<ul class="fullwidth" id="ddm">
    <li><a href="https://www.mtosmt.org/index.php">MTO Home</a>
    </li>
    <li><a href="https://www.mtosmt.org/issues/mto.24.30.4/toc.30.4.html">Current Issue</a>    </li>
    <li><a href="https://www.mtosmt.org/issues/issues.php"
    	onmouseover="mopen('m3')" 
        onmouseout="mclosetime()">Previous Issues</a>
        <div id="m3" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/index-author.php">By Author</a>
	        <a href="https://www.mtosmt.org/issues/issues.php">By Volume&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
	</li>
	
    <li><a href="https://www.mtosmt.org/docs/authors.html.php"
    	onmouseover="mopen('m4')" 
        onmouseout="mclosetime()">For Authors</a>
        <div id="m4" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/mto-editorial-policy.html">MTO Editorial Policy</a>
	      <a href="https://www.mtosmt.org/docs/mto-style-guidelines.html">MTO Style Guidelines</a>
	      <a href="https://www.mtosmt.org/docs/how-to-submit-an-article-to-mto.html">How to Submit an Article</a>
	      <a href="https://www.mtosmt.org/ojs">Submit Article Online</a>
	      <a href="https://www.mtosmt.org/docs/reviewers.html">Book Review Guidelines</a>
        </div>
	</li>

 <!--   <li><a href="https://www.mtosmt.org/docs/authors.html">Submit</a>
	</li> -->
	
    <li><a href="https://www.mtosmt.org/mto-jobs.php"
    	onmouseover="mopen('m6')" 
        onmouseout="mclosetime()">Jobs</a>
        <div id="m6" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/mto-jobs.php">Current Job Listings</a>
	        <a href="https://www.mtosmt.org/mto-job-post.php">Submit Job Listing</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/docs/diss-index.php"
    	onmouseover="mopen('m7')" 
        onmouseout="mclosetime()">Dissertations</a>
        <div id="m7" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/diss-index.php">All Dissertations</a>
	        <a href="https://www.mtosmt.org/docs/diss-index.php?new=true">New Dissertations</a>
	        <a href="https://www.mtosmt.org/mto-diss-post.php">List Your Dissertation</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/about.html">About</a>
	</li>
<!--    <li><a href="https://www.mtosmt.org/mto_links.html">Journals</a>  
	</li> -->
    <li><a href="https://societymusictheory.org">SMT</a>
	</li>
   <!-- <li><a href="https://societymusictheory.org/announcement/contest-new-mto-logo-2024-02"><span style="color:yellow">Logo Design Contest</span></a>
	</li>-->

</ul>

</div>


<!-------------------------------- TITLE -------------------------------------------->

  <article>

<div id="content">
<a name="Beginning"></a>
			
	<h1 style="width:900px; margin-top:1em">Encoding Post-Spectral Sound: Kaija Saariaho&rsquo;s Early Electronic Music at IRCAM, 1982&ndash;87<sup><a name="FN0REF" href="#FN0" id="footnote0">*</a></sup> </h1>
	<div style="width:900px">
				</div>

	
				<h2><span style="font-weight: 400"><font size="5"><a style="color:black" href="#AUTHORNOTE1">Landon Morrison</a></font></span></h2><br><br><p><font size='4'>KEYWORDS: Kaija Saariaho, IRCAM, post-spectralism, synthesis, archival research, media and software studies</font></p><p><font size='4'>ABSTRACT: This article examines computer-based music (ca. 1982&ndash;87) created by Finnish composer Kaija Saariaho at the Institut de Recherche et Coordination Acoustique/Musique (IRCAM) in Paris. A detailed account of archival materials for an early &eacute;tude in voice synthesis, <i>Vers le blanc</i> (1982), demonstrates the music-theoretical import of software to Saariaho&rsquo;s development of a robust compositional method that resonated with the emergent aesthetics of a post-spectral milieu. Subsequent analyses of two additional works from this period&mdash;<i>Jardin secret II</i> (1984&ndash;86) for harpsichord and tape, and <i>IO</i> (1987) for large ensemble and electronics&mdash;serve to illustrate Saariaho&rsquo;s extension of this method into instrumental settings. Specific techniques highlighted include the use of interpolation systems to create continuous processes of transformation, the organization of individual musical parameters into multidimensional formal networks, and the exploration of harmonic structures based on the analysis of timbral phenomena. Relating these techniques to the affordances of contemporaneous IRCAM technologies, including CHANT, FORMES, and Saariaho&rsquo;s own customized program, &ldquo;transkaija,&rdquo; this article adopts a transductive approach to archival research that is responsive to the diverse media artifacts associated with computer-based composition.</font></p><p><small>DOI: 10.30535/mto.27.3.10</small></p>			
	<div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'><a href="https://mtosmt.org/issues/mto.21.27.3/mto.21.27.3.morrison.pdf">PDF text </a> | <a href="https://mtosmt.org/issues/mto.21.27.3/morrison_examples.pdf">PDF examples </a></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div>
			<div style="float:left; font-size:1.1rem;"><i>Received May 2020</i></div>
		<div style="width:850px">
	<div style="text-align:center; font-size: 1.1rem; margin-bottom:2em;margin-top:4em;margin-right:auto;margin-left:auto;width:870px">
		Volume 27, Number 3, September 2021 <br> Copyright &#0169; 2021 Society for Music Theory	</div>
	</div>

<hr style="width:850px"><br>
<section>
<!-------------------------------- ARTICLE BODY (begin) -------------------------------------->

<h2>1. Analyzing New Musical Media in the Archives</h2>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 1</b>. Saariaho, score for <i>Vers le blanc</i> (originally printed in 1987, 104)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=0&nonav=true"><img border="1" alt="Example 1 thumbnail" src="morrison_ex01_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[1.1] Finnish composer Kaija Saariaho&rsquo;s early electronic study, <i>Vers le blanc</i> (1982) for computer-generated sounds recorded to tape, has enjoyed a rather curious existence as a piece that is widely known despite being rarely heard. Because no recording was released, only those present for its premiere at the 1982 Darmstadt International Summer Courses and a handful of other concerts ever actually heard it. And yet, thanks to the image of the full score shown in <b>Example 1</b>, which Saariaho published in a 1987 article titled &ldquo;Timbre and Harmony,&rdquo; this music has lingered in musicians&rsquo; collective imagination.</p>

<p>[1.2] As notated, <i>Vers le blanc</i> consists of a fifteen-minute progression from one harmony to another which, according to Saariaho, happens &ldquo;so slow that changes of pitch become imperceptible to the ear&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954da51a">1987</a>, 104). In this regard, it evokes the processual aesthetics of French spectralism, embodying in exaggerated form G&eacute;rard Grisey&rsquo;s description of a style driven by the &ldquo;hypnotic power of slowness and by a virtual obsession with continuity, thresholds, transience and dynamic forms&rdquo; (<a href="#grisey_2000_1998" id="citation_grisey_2000_1998_67dc9954da521">[1998]</a>, 2). Several scholars have remarked on this connection (<a href="#pousset_et_al_2000" id="citation_pousset_et_al_2000_67dc9954da527">Pousset et al. 2000</a>; <a href="#battier_and_nouno_2003" id="citation_battier_and_nouno_2003_67dc9954da52c">Battier and Nouno 2003</a>; <a href="#howell_2006" id="citation_howell_2006_67dc9954da52f">Howell 2006</a>), citing the piece as evidence of Saariaho&rsquo;s shift toward post-spectralism and computer-based composition techniques upon moving to Paris and enrolling in a program at the Institut de Recherche et Coordination Acoustique/Musique (IRCAM). Others have taken a more general theoretical approach. Callender (<a href="#callender_2004" id="citation_callender_2004_67dc9954da533">2004</a>, [1.2]) for example, highlights the piece&rsquo;s extreme continuity as a &ldquo;clear example of infinitesimal voice leading&rdquo; and reconstructs an abridged audio simulation of the piece to demonstrate a broader mathematical exegesis of continuous musical processes. The concern is that, in the absence of a recording, these sources have bracketed out the material and perceptual basis of the music, analyzing the <i>work-as-seen</i> and not <i>as-heard</i>.</p>

<fig>
  <p class='fullwidth' style="text-align: center; margin-top:0em; margin-bottom:0.5em"><b>Audio Example 1</b>. Saariaho, Excerpt from <i>Vers le blanc</i> [14:30 &ndash; 15:04]</p><p class='fullwidth' style="text-align: center; margin-top:0em;"><audio preload="metadata" controls style="width:300px"><source src="morrison_audioex1.mp3" type="audio/mpeg"><source src="morrison_audioex1.ogg" type="audio/ogg"><script language="JavaScript" type="text/javascript"></script></audio></p> <p class='fullwidth' style="text-align: center; margin-top:0em; margin-bottom:0.5em"><b>Audio Example 2</b>. Saariaho, Excerpt from <i>Vers le blanc</i> [9:15 &ndash; 10:15]</p><p class='fullwidth' style="text-align: center; margin-top:0em;"><audio preload="metadata" controls style="width:300px"><source src="morrison_audioex2.mp3" type="audio/mpeg"><source src="morrison_audioex2.ogg" type="audio/ogg"><script language="JavaScript" type="text/javascript"></script></audio></p> <p class='fullwidth' style="text-align: center; margin-top:0em; margin-bottom:0.5em"><b>Audio Example 3</b>. Saariaho, Excerpt from <i>Vers le blanc</i> [0:00 &ndash; 0:48]</p><p class='fullwidth' style="text-align: center; margin-top:0em;"><audio preload="metadata" controls style="width:300px"><source src="morrison_audioex3.mp3" type="audio/mpeg"><source src="morrison_audioex3.ogg" type="audio/ogg"><script language="JavaScript" type="text/javascript"></script></audio></p></fig>

<p>[1.3] During a research stay at IRCAM in the summer of 2017, I came across a digitally archived recording of <i>Vers le blanc</i>, preserved as four separate audio tracks that correspond to the four channels of spatial diffusion the piece utilized in live performance. Using specifications provided by Saariaho’s longtime technical collaborator and partner, Jean-Baptiste Barrière, I blended these channels into a stereo mix, adjusting the left-right panning of the four tracks to produce a clear separation of voice streams, timbre changes, and acoustical beating effects. This reconstructed version of the piece approximates how the original might have sounded, with one notable exception—the recording plays backwards from Saariaho’s published score.<sup><a name="FN1REF" href="#FN1" id="footnote1">(1)</a></sup> In Audio Examples 1–3, I have maintained the temporal order indicated in Saariaho’s score by presenting the excerpts out of order—specifically, out of the original 920-second audio file, my first audio example presents 14:30–15:04, the second 9:15–10:15, and the third 0:00–0:48—which causes the morphological flow of each excerpt to run in reverse.</p>


<p>[1.4] On listening, one is immediately struck by the subtle microsonic details hidden within the music&rsquo;s timbral profile. A trio of almost natural-sounding (though clearly synthesized) voices marks the opening and closing sections, but in between, the choral timbre grows more distorted. Saariaho alludes to this transformation in her 1987 article, speaking of a desire to &ldquo;create the illusion of an endless human voice, sustained and &lsquo;non-breathing,&rsquo; which at times departs from its physical model&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954da561">1987</a>, 105). Clearly, then, <i>Vers le blanc</i> as heard is about more than harmony. As a result of its drastically scaled back pitch information, the piece encourages listeners to shift their focus away from that traditionally primary musical parameter to concentrate instead on other, traditionally &ldquo;secondary&rdquo; ones, most notably timbre.<sup><a name="FN2REF" href="#FN2" id="footnote2">(2)</a></sup> Recognition of this critical point renders the medium of staff notation ill-equipped to represent the kinds of sonic phenomena that are of central importance to understanding the work. Moreover, it provokes new questions. Given this rebalancing of traditional musical parameters&mdash;and thus also: aesthetic values&mdash;how can we reconcile the different types of information conveyed in the sonic archival traces? And what kinds of musical knowledge and experience might be recovered by thinking transductively across different media environments?</p>

<p>[1.5] Before an attempt is made to answer these questions, we must address two fundamental problems that arise in the process of archiving computer-based music. First, computers tend to precipitate a vast proliferation of musical texts, resulting in what Georgina Born characterizes as a &ldquo;vertical hierarchy of mediations&rdquo; that is &ldquo;inherently multi-textual,&rdquo; encompassing everything from graphic user interfaces to programming languages, operating systems, assembler code, and machine hardware (<a href="#born_1997" id="citation_born_1997_67dc9954da567">1997</a>, 145). Engaging at the level of the interface, composers gain access to a vastly expanded sound palette, but in exchange must specify microscopic aspects of sound that in traditional performance could be taken for granted. Working at Bell Laboratories in the early days of digital synthesis, Max Mathews was keenly aware of this condition, characterizing extant accounts of what constituted a musical note as &ldquo;grossly inadequate.&rdquo; He observed that even the simplest of tones necessitated an explicit definition of several parameters&mdash;period, amplitude, duration, wave shape, vibrato, tremolo, etc.&mdash;because &ldquo;the ear is sensitive to a number of nuances which must be introduced to obtain interesting timbres&rdquo; (<a href="#mathews_1961" id="citation_mathews_1961_67dc9954da56b">1961</a>, 679). To generate a tone as complex as, say, the human voice, required multiplying this process many times over, compounding a computer&rsquo;s unit generators (&ldquo;instruments&rdquo;) to create a makeshift &ldquo;orchestra,&rdquo; as well as writing an array of programs (&ldquo;scores&rdquo;) to shape each of the higher partials that naturally imbues a voice with its distinctive qualities. This was no easy feat at that time. In addition to the labor of programming subroutines and manually punching note cards, there were technical constraints and computational costs to contend with: depending on the sampling rate and number of unit generators deployed, synthesizing sound in the early sixties could cost &ldquo;as much as $100 per minute of music&rdquo; (<a href="#mathews_1961" id="citation_mathews_1961_67dc9954da56f">Mathews 1961</a>, 679). Today, of course, much of this work is automated by newer software, but Mathews&rsquo;s expensive and time-intensive experiments in early synthesis nonetheless serve to illustrate the many layers of scripted operations needed to digitally compose sounds that might otherwise be attained with a single dot on a page&mdash;assuming, that is, that one adopts conventional notation and subscribes to an aesthetically bounded universe of instruments, sounds, and practices.</p>

<p>[1.6] A second, related problem arises from the fact that computer-based music substitutes seemingly immaterial files and software prone to obsolescence in place of the hardy materiality of traditional manuscripts. This shift complicates efforts to preserve not only new media artifacts, but the technical systems and infrastructures on which they depend, since to remain viable, digital documents must be ported into new software and hardware environments every few years. Moreover, through these processes of continual adaptation, the documents themselves are altered many times over, raising questions about the faithfulness of subsequent versions to an original. Media theorist Wolfgang Ernst has coined the neologism <i>dynarchival</i> to describe this situation, drawing attention to what he sees as a transition from &ldquo;the ideal of archival eternity to permanent change<nobr>. . .</nobr> [as] both the archive in its media base <i>and</i> the archive as discourse have literally got <i>in motion</i>&rdquo; (<a href="#ernst_2014" id="citation_ernst_2014_67dc9954da573">2014</a>, 94). Art museum curators and conservators are perhaps more attuned to this issue than anyone: their charge often entails maintaining collections of public-facing digital art for the next hundred years or more, while contending with a fickle marketplace driven by perpetual system changes, software updates, and material makeovers (<a href="#serexhe_2013" id="citation_serexhe_2013_67dc9954da576">Serexhe 2013</a>). Facing a similar crisis, the music research community has also taken a keen interest in digital preservation, as evidenced by major data-archiving projects at centers such as IRCAM, where resident scientists have created the in-house Sidney server to maintain software needed to perform musical works commissioned by the center.<sup><a name="FN3REF" href="#FN3" id="footnote3">(3)</a></sup> Elsewhere, efforts have been made to establish international standards for the <i>authenticity</i>, <i>accuracy</i>, and <i>reliability</i> of digital documents (<a href="#lee_2006" id="citation_lee_2006_67dc9954da595">Lee 2006</a>; <a href="#roeder_2008" id="citation_roeder_2008_67dc9954da599">Roeder 2008</a>).<sup><a name="FN4REF" href="#FN4" id="footnote4">(4)</a></sup> Notwithstanding these exciting developments, the complex project of safeguarding algorithmic artifacts and documenting how computers impact musical creativity is still in its earliest stages of development.</p>

<p>[1.7] I am primarily interested in the dual problem of digital preservation because of how it draws together multiple disciplinary interests and provides a chance to reflect on what archival music research might gain by incorporating concepts and methods from related subfields, such as media archaeology and software studies (<a href="#born_1997" id="citation_born_1997_67dc9954da59f">Born 1997</a>; <a href="#manovich_2001" id="citation_manovich_2001_67dc9954da5a2">Manovich 2001</a>; <a href="#huhtamo_2011" id="citation_huhtamo_2011_67dc9954da5a5">Huhtamo 2011</a>; <a href="#chun_2011" id="citation_chun_2011_67dc9954da5a8">Chun 2011</a>; <a href="#sterne_2012" id="citation_sterne_2012_67dc9954da5ab">Sterne 2012</a>). The questions raised by digital sound demand a serious (re)consideration of which technical languages and skill sets are needed to engage new music, and thus, which new media literacies should be prioritized. There is much to be learned from a close engagement with instruments and sound technologies; however, this requires developing fresh approaches to study how media (whether acoustic, analog, or digital) first, shape knowledge about sound and music-making, second, encode aesthetic affordances, and last and more generally, inscribe cultural and cognitive processes in their operations. In recent years, these concerns have been taken up by a growing number of music scholars whose work, from a variety of perspectives, addresses the ways in which music is mediated by entanglements of people, objects, and ideas (<a href="#born_2005" id="citation_born_2005_67dc9954da5ae">Born 2005</a>; <a href="#tresch_and_dolan_2013" id="citation_tresch_and_dolan_2013_67dc9954da5b2">Tresch and Dolan 2013</a>; <a href="#piekut_2014" id="citation_piekut_2014_67dc9954da5b5">Piekut 2014</a>; <a href="#rehding_2016" id="citation_rehding_2016_67dc9954da5b8">Rehding 2016</a>; <a href="#rehding_et_al_2017" id="citation_rehding_et_al_2017_67dc9954da5bc">Rehding et al. 2017</a>). The present article builds on this line of research by positioning themes of digital mediation and instrumentality as a panoramic backdrop for a more narrowly focused analysis of Saariaho&rsquo;s early electronic music at IRCAM (ca. 1982&ndash;87), centering specifically on a collection of archival materials housed at IRCAM and at the Paul Sacher Foundation in Basel, Switzerland.<sup><a name="FN5REF" href="#FN5" id="footnote5">(5)</a></sup> Reassembling artifacts scattered between these locations, I aim to show how the media scripts of ancient software at IRCAM were integral to Saariaho&rsquo;s early artistic development and to the formation of a wider post-spectral milieu. To this end, I combine historical, cultural, and technological strains of research with a detailed investigation of the materials and methods underlying specific pieces of music. I take a broad view of the music and its attendant technologies as conjoined technical-aesthetic objects for analysis, foregrounding the case of <i>Vers le blanc</i>, which Saariaho created using the CHANT voice synthesis program. This mode of inquiry provides important clues to the origins of techniques that have since become hallmarks of her compositional aesthetic. These include the use of interpolations to produce continuous processes of transformation, the adoption of acoustic models as a basis for harmony, and the conceptualization of musical form as a multilevel network of independently controlled parameters. In the second half of the article, I show how Saariaho gradually formalized these techniques through development of a customized program dubbed &ldquo;transkaija,&rdquo; and I demonstrate how she extended their use into instrumental settings through analysis of select passages from two other works: <i>Jardin secret II</i> (1985&ndash;86) for harpsichord and computer-processed sounds on tape, and <i>IO</i> (1987) for large ensemble with tape and live electronics. Collectively, these pieces&mdash;along with other better-known works from this period, such as <i>Verblendungen</i> (1984) and <i>Lichtbogen</i> (1986)&mdash;mark Saariaho&rsquo;s entry into computer-based composition and her stylistic turn towards post-spectralism, offering a unique opportunity to study the convergence of art and science in contemporary sonic practices.</p>


<h2>2. In Search of a Lost &ldquo;Sound Synthesis Utopia&rdquo;: Reassembling <em>Vers le blanc</em> (1982)</h2>

<p>[2.1] During a recent interview in <i>Computer Music Journal</i>, Saariaho and Barri&egrave;re reflected on what it was like to work at IRCAM in the early eighties, when the center was still establishing itself as an international hub of computer-music research. Barri&egrave;re expresses a kind of nostalgia for what he describes as the once-common pursuit of a &ldquo;sound synthesis utopia <nobr>. . .</nobr> the promises of new territories <nobr>. . .</nobr> of building your own sound, which was paired with using the computer as an assistant to composition, a duplicate of yourself with which you can interact in an intelligent way.&rdquo; To this, Saariaho adds that, &ldquo;once we could build and control sound with computers, the question immediately raised itself about how to organize sound and also, for me, about how it was perceived&rdquo; (<a href="#campion_2017" id="citation_campion_2017_67dc9954da5c1">Campion 2017</a>, 12). Their appeal to a lost &ldquo;sound synthesis utopia&rdquo; evokes the braided strands of psychoacoustics, technological development, and composition that underpinned work at IRCAM in its formative years (<a href="#born_1995" id="citation_born_1995_67dc9954da5c4">Born 1995</a>). This epoch of the center&rsquo;s history was marked by a fundamental optimism that digital synthesis techniques would bring together art and science, offering a means both for researchers to map the psycho-physical nature of sound, and for composers to gain greater control over the inner structure of their sonic materials. Institutionally, this two-pronged mission was facilitated by an internal organization that coordinated activities across a number of complementary departments, each housing a distinguished team of researchers and composers.<sup><a name="FN6REF" href="#FN6" id="footnote6">(6)</a></sup> Technologically, it was carried out by converting programs designed for studying timbre perception into compositional environments (<a href="#wessel_1979" id="citation_wessel_1979_67dc9954da5ca">Wessel 1979</a>), and by improving on direct synthesis software like MUSIC V, a program inherited from Bell Labs and the Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University (<a href="#nelson_2015" id="citation_nelson_2015_67dc9954da5cd">Nelson 2015</a>). In this way, the utopian project at IRCAM was facilitated by a perpetual relay of personnel and innovation between like-minded research centers, which coalesced into a wide, inter-institutional network of actors dedicated to the advance of digital synthesis technologies.</p>

<p>[2.2] One of the earliest technologies invented at IRCAM&mdash;and the first with which Saariaho developed familiarity&mdash;was the CHANT program for voice synthesis. As described by Xavier Rodet and the CHANT development team, the program was designed to &ldquo;extrapolate new creative models for music on the basis of <i>knowledge models</i> developed using a <i>synthesis-by-rules</i> methodology&rdquo; (<a href="#rodet_et_al_1984" id="citation_rodet_et_al_1984_67dc9954da5e8">Rodet et al. 1984</a>, 15). In this case, &ldquo;knowledge models&rdquo; derived from analyses of the singing voice carried out by researchers working at IRCAM, such as Gerald Bennett (<a href="#bennett_1981" id="citation_bennett_1981_67dc9954da5ec">1981</a>) and Johan Sundberg (<a href="#sundberg_1977" id="citation_sundberg_1977_67dc9954da5ef">1977</a>), as well as by Gunnar Fant (<a href="#fant_1970" id="citation_fant_1970_67dc9954da5f2">1970</a>) and others outside the center whose work examined the spectral characteristics of vowels and phonemes. These studies involved recording a number of singers, analyzing the results with spectrograms, and cataloging the spectral envelopes and formant regions produced by different sounds; in some cases, this information was then correlated with x-rays showing physical measurements of the human vocal apparatus. Rodet&rsquo;s team drew on this information to devise a set of rules that were encoded to simulate the <i>transfer function</i> of the voice tract, i.e., the pairing of an excitation source, such as one finds in breathy disturbances of the glottis, with the resonant filtering properties of the mouth and nasal cavities. The success of this transductive process was measured by the re-synthesized voice&rsquo;s resemblance to an original (or rather, the <i>idea</i> of an original, as constructed through scientific research), a metric Rodet regarded as &ldquo;proof of both our understanding of sound phenomena, and of the music itself&rdquo; (<a href="#rodet_et_al_1984" id="citation_rodet_et_al_1984_67dc9954da5f7">1984</a>, 15). Out of this process then, a didactic feedback loop emerged, in which researchers alternated between analyzing, synthesizing, and listening to sound, all the while tweaking their models toward an invented notion of fidelity. Extended outward, this loop also came to encompass composers, encouraging them to formalize their knowledge of sound according to the control variables available within the CHANT interface.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 2</b>. Saariaho, form diagram of <i>Vers le blanc</i>, Sacher Foundation, Basel</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=1&nonav=true"><img border="1" alt="Example 2 thumbnail" src="morrison_ex02_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[2.3] To better grasp the significance of CHANT for Saariaho&rsquo;s compositional project, let us return to <i>Vers le blanc</i> and the question of how to reconcile different types of information in the notated score (Example 1) versus Audio Examples 1&ndash;3. It is not immediately clear how one might bridge the gap between these musical objects, but important clues can be found in a key archival document at the Sacher Foundation, in which Saariaho graphs the temporal evolution of parameters that lie beneath the level of the note; see <b>Example 2</b>. This form diagram&mdash;dated July 19, 1982, roughly a month before the piece premiered at Darmstadt&mdash;is exceptionally clean and was created after the piece was completed, possibly for presentation at the festival.<sup><a name="FN7REF" href="#FN7" id="footnote7">(7)</a></sup> Visually striking, its layering of line-graphs reads like a blueprint, mapping the interaction of various sonic parameters into a composite image that neatly encapsulates the composer&rsquo;s later conception of musical form as a &ldquo;multi-dimensional network in which detail is strictly controlled on several levels&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954da607">1987</a>, 124).</p>


<p>[2.4] As this diagram offers an unusual level of insight into the composer&rsquo;s formal plan of the piece, it is worth taking the time to unpack some of its finer points. At the beginning, the high-to-low pitch content from the opening trichord is spread over three systems, labeled I, II, and III. Within each of these voices, Saariaho charts the contours of individual sub-note parameters as a layered mesh of superimposed lines. Looking at System I, the fundamental frequency for the uppermost voice is defined along the top of the system. It is in this case, a B at 246.94&nbsp;Hz, which incrementally descends to an F at 174.61&nbsp;Hz. Next, values are listed for a <i>tremolo</i> parameter that moves in a pendular fashion from 0 to 1.8 (ca. 180&rdquo;), and then back to 0 by the end of the work. The same holds for all other parameters, including the variables for vibrato frequency, the amplitudes for different formant regions, and randomization factors. In this way, the trajectory of the work&rsquo;s sub-note elements is characterized by a movement away from, and then back to, an initial state of repose, as represented by default values within the CHANT program. Following suit, Voices II and III have their own sets of parameters applied to them. When three new voices enter a few minutes into the piece (Voices IV, V, and VI, ca. 180&rdquo;), each adopts parameters from the voice above but pairs them with a new set of functions. A simple set of instructions read (in Voice IV, e.g.): &ldquo;all values as in I, all phonemes as in II&rdquo; (note: I will return to the issue of phonemes momentarily). The entrance of these recombined voices, moreover, aligns with the commencement of a rhythmic process in which three patterns&mdash;indicated at the bottom of the diagram with values of .5, .33, and .25, which translate to eighth, triplet eighth, and sixteenth notes, respectively&mdash;are superimposed and gradually altered, with eighth and sixteenth notes converging on a triple subdivision by the end of the piece. Hence, a rhythmic interpolation of sorts runs in parallel with the notated harmonic interpolation. The reason I qualify the interpolation in this case is that these &ldquo;rhythms&rdquo; apply to the amplitude peaks of continuous voices, yielding a subtle pulsation more than a detectable metric pattern.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 3</b>. Saariaho, excerpt of parameter file for Voice I, Sacher Foundation, Basel</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=2&nonav=true"><img border="1" alt="Example 3 thumbnail" src="morrison_ex03_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[2.5] The wealth of conceptual information contained in Saariaho&rsquo;s form diagram draws attention to the relative dearth of aurally salient details conveyed by the better-known score. Such missing details point to the presence of an underlying code. Although the original CHANT program is no longer operative, the work&rsquo;s code is preserved in hard copy as thick stacks of old, sprocket-fed printer paper at the Sacher archives.<sup><a name="FN8REF" href="#FN8" id="footnote8">(8)</a></sup> Consulting this material resource, and with the aid of a hard-to-find CHANT user manual (<a href="#baisn&eacute;e_et_al_1985" id="citation_baisn&eacute;e_et_al_1985_67dc9954da613">Baisn&eacute;e et al. 1985</a>), I have excavated the work&rsquo;s code for significant musical data by again asking the central question, &ldquo;what does this archival trace show?&rdquo; Answers to this query yield a clearer picture of the synthesis processes driving <i>Vers le blanc</i> and a better understanding of how the CHANT program was utilized in actual practice. To gain insight into both matters, consider the <i>parameter</i> file for Voice I shown in <b>Example 3</b>. The list of numbers at the top plots a series of value-time pairs, or what is known in programming parlance as &ldquo;breakpoint functions.&rdquo;</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Examples 4a&ndash;c</b>. (a) table of frequency information for three parameter files;<br>(b) graph showing pitch contours as breakpoint functions;<br>(c) table of secondary parameters</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=3&nonav=true"><img border="1" alt="Examples 4a&ndash;c thumbnail" src="morrison_ex04a-c_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[2.6] The formatting of the code here is important, as it establishes a technical framework, according to which all time-based processes in CHANT were structured using breakpoints. Unsurprisingly, this design feature imbued the program with a strong sense of linearity, since breakpoints are coordinates that plot the trajectory of a line indicating change over time. In this case, the numbers on the right indicate duration, ranging from 0 to 920 seconds, while those on the left define frequencies for the fundamental pitch (246&nbsp;Hz to 174&nbsp;Hz). If we were to keep reading the file, we would find similar breakpoint lists for amplitude, tremolo, vibrato, and all of the other parameters detailed in the previous form diagram. In total, there are three parameter files for the work, corresponding with the three original voices (I, II, III); select information from these files has been tabulated in <b>Examples 4a&ndash;c</b> below.</p>


<p>[2.7] Example 4a shows the breakpoint functions for each voice-leading strain. Although these values give the impression of discrete events, it is important to remember that these notes are not emphasized as such, but rather act as silent intermediaries signaling the rate of change in a musical process that evolves smoothly over time.<sup><a name="FN9REF" href="#FN9" id="footnote9">(9)</a></sup> As Saariaho explains: &ldquo;Here the harmony is impossible to perceive as a series of different chords since it is presented as a continuum, as an uninterrupted chord that is continuously modified&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954da637">1987</a>, 105). Her observation can be visually confirmed by graphing the breakpoints as in Example 4b to show the pitch contour of each voice, a maneuver that effectively subdivides the original harmonic glissando into sixteen incremental steps. Notice how the plot lines correspond to the pitch contours in Saariaho&rsquo;s notated representation of the piece, except for briefly during the beginning and ending sections, where the harmony remains static for a period of time, anchoring the extremes of the interpolation process with greater temporal weight. We can also track the behavior of other parameters such as <i>tremolo</i>, <i>vibrato</i>, and the <i>amplitude of formant frequencies</i>, as well as randomization and other modifying agents. Shown in Example 4c, these secondary parameters modify the default vocal timbre of the CHANT program in interesting ways, giving Saariaho the ability to &ldquo;add different kinds of noises and shadings to the sound&rdquo; (<a href="#saariaho_1983" id="citation_saariaho_1983_67dc9954da63a">1983</a>, 270).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Examples 5a&ndash;c</b>. (a) Saariaho, function file for Voice I, Sacher Foundation, Basel;<br>(b) tabulation of phonemes in CHANT dictionary;<br>(c) a spectral envelope defined with five formant regions (reprinted from Baisn&eacute;e et al., <i>CHANT manual</i>, 8; &ldquo;f1&ndash;f5&rdquo; annotations are my own)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=4&nonav=true"><img border="1" alt="Examples 5a&ndash;c thumbnail" src="morrison_ex05a-c_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[2.8] In addition to parameter files, CHANT processed what was known as a <i>function</i> file, which Saariaho used to access a dictionary of speech phonemes stored in the program&rsquo;s long-term memory. The original code from this dictionary is pictured in <b>Example 5a</b>, with phonemes listed on the left (&ldquo;DI &ndash; YE &ndash; DE &ndash; EA &ndash; A&rdquo;) and corresponding formant structures on the right. Continuing for another five printed pages, the CHANT dictionary contained a total of twenty-five phonemes, tallied in <b>Example 5b</b>. These phonemes provided a basic vocabulary, such that when a particular phoneme was defined, the program looked up the corresponding formant structure and implemented the appropriate spectral envelope. As a general rule, these structures were represented in the program by five frequencies that acted as central peaks of the formant regions within a given spectrum. A typical envelope might look something like the one shown in <b>Example 5c</b>, with its five well-defined formant regions (labeled f1&ndash;f5) appearing as upward spikes in the curved line. In this way, each phoneme was mapped to a unique formant structure that was largely unaffected by changes in fundamental pitch, though gendered distinctions were constructed in the program for voices characterized as female (&ldquo;sex=0&rdquo;), male (&ldquo;sex=1&rdquo;), and castrati (&ldquo;sex=2&rdquo;).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 6</b>. Filter and FOF synthesis techniques in CHANT (reprinted from Baisn&eacute;e et al. 1985, 30)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=5&nonav=true"><img border="1" alt="Example 6 thumbnail" src="morrison_ex06_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[2.9] The technical details documented in these archival traces have relevance beyond the immediate context of <i>Vers le blanc</i>. They show how the operations of CHANT were reflected in a longer history of experimentation around hearing and voice synthesis technologies. Acoustic studies of speech had long been used to shape spectral envelopes through a subtractive process. In CHANT, though, these filter-based methods were supplemented by the addition of a newly developed technique called formant wave function synthesis (or <i>FOF</i>s, from the French <i>fonction d&rsquo;onde formantique</i>), where &ldquo;instead of distinguishing the source and the filter, the FOF technique associates the excitation and resonance&rdquo; (<a href="#baisn&eacute;e_et_al_1985" id="citation_baisn&eacute;e_et_al_1985_67dc9954da64b">Baisn&eacute;e et al. 1985</a>, 21). In this revised process, the excitation source was hitched directly to the resonating chamber in an equation that computed the central formant frequencies of the spectral envelope and calculated the appropriate bandwidth (i.e., &ldquo;spectral skirt&rdquo;) of each formant region. The diagram in <b>Example 6</b>, reprinted from the CHANT manual, illustrates the program&rsquo;s basic architecture, with filter-based (lower) and FOF-based (upper) synthesis methods running in parallel.<sup><a name="FN10REF" href="#FN10" id="footnote10">(10)</a></sup></p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 7</b>. &ldquo;Phrases&rdquo; composed of phoneme sequences in <i>Vers le blanc</i>, transcribed from CHANT code, Sacher Foundation, Basel</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=6&nonav=true"><img border="1" alt="Example 7 thumbnail" src="morrison_ex07_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[2.10] Drawing these historical elements into the creative domain, Saariaho used the dictionary of phonemes encoded in CHANT to build multi-syllabic musical &ldquo;phrases.&rdquo; In <b>Example 7</b>, the phrases for all three voices of <i>Vers le blanc</i> are transcribed as a series of breakpoint functions; each column indicates durational values in seconds on the left and phonemes on the right. These phrases were overlaid onto the parameters of each voice to achieve a state of continuous spectral flux, thus enriching what at first appears to be the work&rsquo;s relatively straightforward pitch content.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 8</b>. Saariaho, sketch of eight phoneme sequences, Sacher Foundation, Basel</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=7&nonav=true"><img border="1" alt="Example 8 thumbnail" src="morrison_ex08_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[2.11] The compositional logic behind Saariaho&rsquo;s structuring of phonemes is revealed in another sketch from the Sacher collection (see <b>Example 8</b>), which shows short phonemic phrases ordered into eight self-contained processes. Taking the first of these processes as an example (see Process I, top of page), we see a color-coded guide to select phonemes on the left (&ldquo;E, A, A<sub>2</sub>, O, I, U, OE<sub>2</sub>&rdquo;) and then corresponding diagrams on the right showing a given unit of time (two minutes, in this case) that is repeated, each time symmetrically sub-dividing into smaller increments, with new phonemes introduced. As the process unfolds, the durations of phonemes become shorter, quickening at points to the pace of nearly one per second. Moving down the left side of the page, each of the remaining processes, labeled II&ndash;VIII, proceeds in a similar fashion, providing eight phonemic strains that govern the phrases in Example 7. Of these, only Processes IV&ndash;VI contain consonants, while the rest feature vowels exclusively. The interplay of speech filters among different voices offers a means of organizing musical development at the microsonic level, which proves especially important in a piece that otherwise neutralizes the role of pitch as a primary musical parameter.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 9</b>. Saariaho, diagram of overall phoneme structure, Sacher Foundation, Basel</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=8&nonav=true"><img border="1" alt="Example 9 thumbnail" src="morrison_ex09_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[2.12] To gain a final perspective on how phonemes are deployed in <i>Vers le blanc</i>, we can turn to a synoptic diagram from the Sacher archives, shown in <b>Example 9</b>. Here, Saariaho maps out the entire work, with the eight phonemic processes from Example 8 woven together in continual transference across all three voices. The general rule, following from the unequal lengths of the processes, is that only one such shift may occur at a time. The sole exception is at the midpoint of the piece, where all three voices pivot around a central axis. Fanning outward, the voices maintain a loose mirror symmetry of phonemic processes around this axis, with each voice mapping onto itself. This last sketch reveals an over-arching palindromic shape that acts as a kind of metaprocess subsuming the eight smaller processes and their lower-level building blocks.</p>

<p>[2.13] Saariaho&rsquo;s approach to musical form in this work is striking in that it ties together two of her primary compositional influences. For one, she embraces the use of acoustic models of the human voice as a way of composing timbre, evincing her drift towards what Grisey famously characterized as a &ldquo;spectralist attitude.&rdquo; For another, she arranges these spectral models in symmetrical fashion, demonstrating a continued use of strict ordering procedures and abstract formal structures that harken back to her studies with Klaus Huber, Brian Ferneyhough, Paavo Heininen, and other serialists. These two sides of her musical persona mingle in <i>Vers le blanc</i>. As such, this early study in sound synthesis is exemplary of what Eric Drott has described as a broader shift from the &ldquo;more or less orthodox spectralism of the 1970s to the increasingly heterodox post-spectralism of the 1980s&rdquo; (<a href="#drott_2017" id="citation_drott_2017_67dc9954da66b">2017</a>, 265).</p>

<p>[2.14] Viewing <i>Vers le blanc</i> in its newly restored, more material form offers a deeper understanding of the techno-cultural origins of compositional techniques now considered to be central to Saariaho&rsquo;s music. To briefly review, this set of techniques includes a use of interpolation systems to build continuous musical processes, an approach that Saariaho applied at all levels of musical structure from the global (e.g., movement from one harmony to another) to the more local (e.g., smaller movements between rhythm patterns, phoneme structures, and other parameters). It also includes a use of spectral models&mdash;of speech, in this case&mdash;as an acoustical basis for exploring the threshold between timbre and harmony. And perhaps most importantly, it includes a shift towards parametric thought, wherein sound is decomposed into an assortment of features that are shaped independently and joined together into multi-dimensional networks. Engendered by technology, this parameterization of sound marked an important break with the rhetoric of first-wave spectralists like Grisey, who framed timbre as a holistic and irreducible phenomenon, encompassing such a complicated &ldquo;web of correlations that even the notion of parameters as defined and isolated by serial music seems obsolete and incapable of accounting for sound phenomena&rdquo; (<a href="#grisey_2018_2008" id="citation_grisey_2018_2008_67dc9954da66d">2018 [2008]</a>, 52). Yet as we have seen, this conception of timbre ran counter to software like CHANT, which allowed psychoacousticians to isolate what they deemed to be perceptually relevant parameters of timbre, manipulating each one individually to study its precise contribution to the overall sound. Thus, a technics of parameterization supplanted the holistic view of early spectralists, ushering in a new phase of quantification in the way composers approached working with elements like timbre. In the next section, we will see how the newfound mode of control offered by computers impacted Saariaho&rsquo;s compositional method, engendering aesthetic effects that would eventually emanate outside the studio and filter into her writing for acoustic instruments and mixed ensembles.</p>


<h2>3. Formalizing Musical Processes in &ldquo;Transkaija&rdquo;</h2>

<p>[3.1] After <i>Vers le blanc</i>, Saariaho continued to work with digital composition tools, leading to the development of a customized program called &ldquo;transkaija&rdquo; which, according to an artist statement for the piece <i>IO</i> (1987), was used as early as 1984. This dates the program&rsquo;s inception to a period when Saariaho was beginning work on <i>Jardin secret I</i> and <i>II</i> (1984&ndash;86), important milestones that allowed her to formalize her use of interpolations into a codified system.<sup><a name="FN11REF" href="#FN11" id="footnote11">(11)</a></sup> In this sense, the transkaija program represented a revamp of a compositional procedure introduced in <i>Vers le blanc</i>, as is clear from the following description:<p>

<blockquote>The central idea is the notion of interpolation. We give the program different patterns, lists of associations for the elements of successive patterns, and evolution curves between these patterns. Patterns can be applied to different parameters and have different lengths [<nobr>. . .</nobr>] the elements can divide or merge.<sup><a name="FN12REF" href="#FN12" id="footnote12">(12)</a></sup> (<a href="#vandenheede_and_saariaho_1988" id="citation_vandenheede_and_saariaho_1988_67dc9954da673">Vandenheede and Saariaho 1988</a>, 5)</blockquote>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Examples 10a&ndash;b</b>. Saariaho, rhythmic interpolations: a) even-to-uneven, and b) few-to-many (reproduced from Saariaho 1984, 164)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=9&nonav=true"><img border="1" alt="Examples 10a&ndash;b thumbnail" src="morrison_ex10a-b_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[3.2] Here, Saariaho is describing a generalized process, the makings of a compositional method that is intimately linked to the use of computers. The patterns, elements, and evolutionary curves defining motion between&mdash;these are all abstract properties that could be applied to any sonic parameter at any level of musical structure. The thread unifying them, of course, is the potential for numerical representation. Anything that can be assigned a value can be controlled in a similar fashion, so the same processes used to control macro-events like phrase structure can be applied to micro-events like the amplitude envelopes for individual sinusoids within a spectrum. Saariaho spelled out the implications of this in a paper delivered at the 1984 International Computer Music Conference (ICMC), illustrating rhythmic interpolations of various kinds in both standard notation and numerical representation. Reproduced in <b>Examples 10a and b</b>, her examples demonstrate two scenarios: (a) even septuplet sixteenth notes moving to an uneven rhythm pattern, but with the same number of elements (7-to-7), and (b) quintuplet sixteenth notes moving to septuplet sixteenth notes, yielding a few-to-many mapping of elements between patterns (5-to-7).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 11</b>. Saariaho, interpolation processes in multilevel network (reproduced from Saariaho 1984, 163)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=10&nonav=true"><img border="1" alt="Example 11 thumbnail" src="morrison_ex11_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[3.3] Saariaho continued beyond rhythm, applying these same interpolative procedures to other elements of sound, harnessing them &ldquo;to produce a multilevel network of continually changing but controlled items&rdquo; (<a href="#saariaho_1984" id="citation_saariaho_1984_67dc9954da689">Saariaho 1984</a>, 163). <b>Example 11</b> reproduces Saariaho&rsquo;s illustration of such a network, with interpolative processes applied to a range of parameters, each having its own properties (i.e., variables, cardinality, length). Incongruities between these properties cause the process to be staggered, with patterns departing and arriving in perpetual relay. As a result, the composite texture presents a network of overlapping time fields, where the boundaries of processes in different parameters rarely coincide.</p>


<p>[3.4] In Saariaho&rsquo;s computer-based music, interpolations act as a way to build continuous sound arcs within the discrete environment of digital media. This application was already apparent in the case of <i>Vers le blanc</i>, and in later works from this period, one finds a pervasive use of the more advanced interpolative procedures outlined in the examples above. To explore Saariaho&rsquo;s extension of CHANT-inspired compositional techniques into new electroacoustic and instrumental contexts, it will help to consider a few passages from <i>Jardin secret II</i> and <i>IO</i>. We will continue to take archival and technical documents into consideration; however, the focus in the next section will be more analytical and less philological. As such, rather than attempting to reconstruct underlying code, I will rely on a primarily score-based approach to reverse-engineering what might have been the technical basis for certain musical processes.</p>


<h2>4. Extended Uses of Interpolation in <i>Jardin secret II</i> (1985&ndash;86) and <i>IO</i> (1987)</h2>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 12</b>. Saariaho, sketch of spiral form for <i>Jardin secret II</i>, Sacher Foundation, Basel</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=11&nonav=true"><img border="1" alt="Example 12 thumbnail" src="morrison_ex12_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[4.1] Saariaho&rsquo;s <i>Jardin secret II</i> for harpsichord and computer-processed sounds was created with a newer version of CHANT nested within the FORMES system, which integrated higher-level controls for scheduling musical events and processes (<a href="#rodet_and_cointe_1984" id="citation_rodet_and_cointe_1984_67dc9954da68e">Rodet and Cointe 1984</a>). This technical innovation is reflected in the work&rsquo;s more elaborate form. The piece is composed around a small number of textures and sound characters, including trills, arpeggiations, and dense chordal clusters in the harpsichord, with processed recordings of the instrument joined by what the score describes as &ldquo;whispering&rdquo; and &ldquo;murmuring voices&rdquo; in the electronics. The cyclic return of a trill motif imparts a ritornello-like quality to the form; however, while appearances of the refrain are well marked, the passages that immediately follow never enter as sharp juxtapositions, but rather as imperceptible fades into contrasting material. As always, the aesthetic of continuity remains paramount. In a remarkable sketch at the Sacher Foundation (see <b>Example 12</b>), Saariaho illustrates her creative conception for these formal processes with a spiral diagram that maps the work&rsquo;s overall structure.<sup><a name="FN13REF" href="#FN13" id="footnote13">(13)</a></sup> Cross-cutting the prevailing circularity of the figure are recursive passes through five types of material&mdash;<i>trills</i>, <i>process 1</i>, <i>ostinato</i>, <i>process 2</i>, and <i>scales</i>&mdash;with penciled lines roughly demarcating their boundaries.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 13</b>. Formal analysis of <i>Jardin secret II</i></p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=12&nonav=true"><img border="1" alt="Example 13 thumbnail" src="morrison_ex13_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[4.2] As is the nature of spirals, each 360-degree cycle takes more time than the last, enacting a long-range process, whereby sectional proportions are gradually augmented over the course of the work. As shown in my own form diagram given in <b>Example 13</b>, the first cyclic pass (Section A) lasts barely a minute, the second (Section A&rsquo;) is slightly longer at two-and-a-half minutes, and the third (Section A&rsquo;&rsquo;) extends for over five minutes, after which an extended Coda reprises the trill motif in a slow melodic setting. In each section, the music oscillates between dynamic interpolation processes (P<sub>1&ndash;6</sub>), stable zones of ostinato material (ost.), and fixed scalar content (sc.). Acting as a beacon within this ebb and flow, the recurring trill motif helps to orient listeners to the musical form, but only for brief moments, as its repeated dissolutions ultimately frustrate attempts to discern clear structural divisions.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 14</b>. Saariaho, <i>Jardin secret II</i>, annotated score, mm. 1&ndash;17, Section A</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=13&nonav=true"><img border="1" alt="Example 14 thumbnail" src="morrison_ex14_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[4.3] The archival record for <i>Jardin secret II</i> contains many other noteworthy artifacts, including handwritten notes, multi-track diagrams for visualizing the electronics, printed documents showing results for various rhythm interpolations, and early sketches for the score. The latter provide some insight into Saariaho&rsquo;s compositional procedures, as fragmentary jottings and annotations appear to confirm the presence of at least two of the aforementioned &ldquo;processes&rdquo; in the score. In addition, her notes make reference to file names (e.g., &ldquo;js5b2&rdquo;) similar to those used for calculating interpolations in a packet of unidentified synthesis code from this time period. While a complete record of the code for this work does not appear to exist, even without knowing precisely how the technology operates, it is possible to determine the broad contours of the computational processes that define the music&rsquo;s formal architecture: harmonic and rhythmic interpolations are readily apparent in the score, with harpsichord and tape running through many of the same processes in parallel. In this case, the task is made easier owing to how the discrete properties of notation and the keyboard interface parse intermittent phases of each interpolation into coarse-grained sections, rendering them visible. Here, I will examine two excerpts, showing how interpolations initiate a movement away from the trills that begin each section. The first, taken from the beginning of the piece, is shown in <b>Example 14</b>.</p>


<p>[4.4] The piece opens with a long, sustained trill on C and <nobr><span style= 'letter-spacing:-1px'>D<span style='font-family: Arial Unicode MS, Lucida Sans Unicode;'>&#x266d;</span><span></nobr>; it is not until m. 6 that the initial semitonal dyad cumulatively expands, moving over the course of fourteen seconds to set class [01245689]. Meanwhile, the trill becomes a rhythmic ostinato of steady thirty-second notes and then splits into two pulse streams at m. 13, producing quintuplet sixteenth notes in the right hand and triplet eighth notes in the left hand. Within this interpolation, one may observe another embedded sub-process articulated by contrasting dynamics: the performer&rsquo;s left hand begins the passage in silence and gradually develops into a steady pulse stream, while a decrescendo from <i>mf</i> to <i>mp</i> is counterbalanced in the tape part by the swell of the granulated &ldquo;whispering&rdquo; texture (m.&nbsp;6, ca.&nbsp;25&rdquo;). Throughout, discrete phases in the harpsichord are contrasted with continuous interpolations in the tape part.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Examples 15a&ndash;c</b>. a) harmonic interpolation;<br>b) Pitches in left hand vs. right hand;<br>c) rhythmic interpolation.</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=14&nonav=true"><img border="1" alt="Examples 15a&ndash;c thumbnail" src="morrison_ex15a-c_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[4.5] In <b>Examples 15a&ndash;c</b>, I have isolated pitch and rhythm in this passage to show their respective paths of interpolation.<sup><a name="FN14REF" href="#FN14" id="footnote14">(14)</a></sup> Example 15a isolates vertical entities produced at structural cross-sections. From this perspective, contrapuntal motion coordinates a harmonic progression that gradually expands, while from a linear perspective, divergence occurs between left and right hands as they follow different paths, desynchronizing into separate harmonic and rhythmic streams. In terms of pitch, (Example 15b), the right hand moves from an initial state of two to five pitches, while the left hand moves from two to three. In terms of rhythm (Example 15c), the right hand begins with a constant stream of thirty-second notes and moves to a quintuplet pattern (with slurred asymmetries), while the left hand moves from silence to triplet eighths, also with slurred asymmetries. Consequently, in both harmony and rhythm, there is a movement from one to many, fusion to fission. However, due to fundamental differences in their beginning and ending points, these simultaneous processes unfold in mm. 1&ndash;12 at different rates. At m. 13, the music locks into a harmonic and rhythmic ostinato in both hands, marking the conclusion of Process 1 (P<sub>1</sub>).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 16</b>. Saariaho, <i>Jardin secret II</i>, annotated score, mm. 89&ndash;112, Section A&rsquo;&rsquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=15&nonav=true"><img border="1" alt="Example 16 thumbnail" src="morrison_ex16_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[4.6] Skipping ahead to Section A&rsquo;&rsquo; (m. 66, ca. 3&rsquo;48&rdquo;), the final return of the trill motif initiates a sub-process of its own (Process 5<sub>a</sub>), which then regroups and segues into another interpolation (Process 5<sub>b</sub>). The latter stage of this two-part process is pictured in <b>Example 16</b> and features two independent pulse streams moving in opposite directions: a decelerating trill in the right hand is overtaken at m. 101 by an accelerating and expanding collection of pitches in the left hand. After the harpsichord and tape synchronize on a shared quintuplet sixteenth-note pattern, the music undergoes a series of intermittent interpolations, slowing to triplet eighth notes (Process 5<sub>c</sub>) before splintering into three pulse layers in a 5:4:3 polyrhythmic ratio. At m. 108, the tape initiates another pace reduction (Process 5<sub>d</sub>), with the end goal of the multi-stage process in this case being a near-cessation of momentum prior to the final ostinato section (m. 115, ca. 6&rsquo;).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Examples 17a&ndash;c</b>. a) harmonic interpolation in Process 5b;<br>b) rhythmic convergence in Process 5b;<br>c) polyrhythmic striation in Processes 5c and 5d</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=16&nonav=true"><img border="1" alt="Examples 17a&ndash;c thumbnail" src="morrison_ex17_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[4.7] The trajectories for rhythm and harmony in this passage are plotted in <b>Examples 17a&ndash;c</b>. Two general threads of development can be observed: a harmonic expansion from the initial trill at m. 101 to a highly chromatic cluster (Example 17a); and a rhythmic convergence of separate pulse layers at m. 102 (Example 17b), followed by their refraction back into independent streams at m. 105 (Example 17c). The stop-and-go aspect of this polyrhythmic passage, in which a long-range deceleration is punctuated by moments of temporal stability, allows the music to expand on material from Section A. As this occurs, the alternation of tutti and solo tape serves to amplify differences between human and mechanical executions of the underlying interpolation processes. These techniques, at base, may be regarded as more sophisticated versions of those employed in <i>Vers le blanc</i>. Working together in the context of <i>Jardin secret II</i>, they impart to the piece a complex, multifaceted musical form.</p>

<p>[4.8] A few years after <i>Jardin secret II</i>, Saariaho further elaborated interpolation techniques in <i>IO</i> (1987) for large ensemble, tape, and live electronics. This piece employed not only the CHANT-FORMES system, but also a newly developed program called IANA, which analyzed sounds into perceptually weighted frequencies and translated the results into standard notation. Composed for the occasion of IRCAM&rsquo;s tenth anniversary, it encapsulated a decade of psychoacoustics research and technological development at the center, while also capping a formative five-year period in Saariaho&rsquo;s career. In a departure from <i>Vers le blanc</i> and <i>Jardin secret II</i>, the form of <i>IO</i> is characterized by an onion-like layering of processes, nested one within the other. These processes move at different speeds, sometimes synchronized and sometimes not, yielding a patchwork of processual shapes that constitutes the musical form. The piece overall projects a sense of formal continuity, yet makes use of sectional guideposts to orient the listener. Two tape solos act as natural boundary points: the first at ca. 2&rsquo;30&rdquo; is relatively short and serves to bring closure to the work&rsquo;s opening section; the second at ca. 11&rsquo;45&rdquo; stretches for nearly three minutes, growing into a self-contained, cadenza-like section in its own right. In addition, the piece is oriented around a network of oppositions in other parameters. Some, like the sound-noise or harmony-timbre continuums, are mainstays of Saariaho&rsquo;s compositional language. Other parameters are mentioned less often, but are equally important to the establishment of a multi-level formal network, including oppositional pairings such as vibrato vs. <i>senza</i> vibrato, <i>sul tasto</i> vs. <i>ponticello</i>, and loud vs. soft.</p>

<p>[4.9] Having grown accustomed to controlling microsonic variables in the CHANT program, Saariaho increasingly integrated these features into the larger model of sound production and auditory perception that grounded her compositional thought. Accordingly, individual sonic elements like vibrato were elevated in significance beyond their original function as style markers to become defining aspects of sound to be determined by the composer. Exerting control over the smallest of details, Saariaho imported a synthesis-like mindset to her instrumental writing in <i>IO</i>. In doing so, she embraced a technomorphic turn that had been decisive for French spectralists like Grisey, whose &ldquo;instrumental synthesis&rdquo; techniques derived from additive synthesis models (<a href="#wilson_2000_1989" id="citation_wilson_2000_1989_67dc9954da6ba">Wilson 2000 [1989]</a>), as well as for earlier composers like Stockhausen and Ligeti, whose encounters with analog synthesis at the WDR Studios led them to think about traditional musical parameters in technological terms (<a href="#stockhausen_1959_1957" id="citation_stockhausen_1959_1957_67dc9954da6bc">Stockhausen 1959 [1957]</a>; <a href="#levy_2009" id="citation_levy_2009_67dc9954da6be">Levy 2009</a>; <a href="#iverson_2011" id="citation_iverson_2011_67dc9954da6c0">Iverson 2011</a> and <a href="#iverson_2017" id="citation_iverson_2017_67dc9954da6c2">2017</a>). What set Saariaho&rsquo;s compositional model apart, however, was that it was digital, presenting a discrete, sample-based logic that was in many ways more compatible with the score-based constraints of orchestration. To demonstrate how computer-based techniques were translated into instrumental contexts, I will focus on a single excerpt from <i>IO</i>, which features interpolation processes like those we have already encountered, but on a grander scale.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 18</b>. Saariaho, <i>IO</i>, annotated score, mm. 24&ndash;54 (3 pages)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=17&nonav=true"><img border="1" alt="Example 18 thumbnail" src="morrison_ex18_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[4.10] <b>Example 18</b> depicts the structural downbeat of <i>IO</i>, which occurs at m. 24 (ca. 58&rdquo;) after an extended introduction. This event is signaled by a sudden shift in texture and the commencement of what is perhaps the first clearly bounded interpolation processes of the piece. These interpolations are realized entirely by the ensemble, without the aid of electronics, and are combined with a variety of other textural elements. These include a sound-noise continuum in the strings (m. 27), achieved through alternating bow placements between <i>sul ponticello</i> and <i>sul tasto</i> and under varying bow pressure; whispered phonemic articulations in the woodwinds (mm. 28&ndash;30 and mm. 38&ndash;41); and a series of brief solos for various instruments, which are passed around the ensemble in a conversational fashion, articulating a loose series of sub-phrases that showcase the harp (m. 27), bass flute (m. 38), piccolo (m. 41), and double bass (m. 45).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 19</b>. Reduction of rhythmic interpolation processes in <i>IO</i>, mm. 24&ndash;54</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="morrison_examples.php?id=18&nonav=true"><img border="1" alt="Example 19 thumbnail" src="morrison_ex19_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[4.11] Saariaho&rsquo;s approach to orchestration in this passage involved creating blocks of material that collectively articulate an overarching process, while maintaining schismatic variation at the surface level. Weaving its way through this varied texture is a nearly continuously fluctuating stream of ostinato pulse layers, which ground a larger network of rhythmic processes. As shown in <b>Example 19</b>, what starts at m. 24 as three superimposed rhythmic layers in the strings&mdash;septuplet, sextuplet, and quintuplet sixteenth notes&mdash;gradually slows and yields to the celesta, harp, percussion, and woodwinds, all of which continue their own interpolation processes. Beginning at m. 31, five polyrhythmically layered pulse streams in the percussion and harp evolve independently, until they too are interrupted by a solo in the bass flute. From m. 41 onwards, a network of decelerating interpolative processes in different instruments leads to the ultimate unraveling of rhythmic momentum in all but the celesta, which accelerates toward a concluding melodic flourish. The continuity of these interpolations is not immediately apparent from the score. The rhythmic reduction presented in Example 19, however, makes clear the connective tissue running throughout the passage and highlights how timbral distinctions serve to articulate both simultaneous and successive phases of interpolation processes. As this final example illustrates, with <i>IO</i>, Saariaho succeeded in extending and elaborating her interpolation technique by layering multiple processual streams, interrupting and resuming interpolations, and nesting local processes within a larger metaprocess.</p>

<p>[4.12] Saariaho&rsquo;s use of interpolation processes in the context of instrumental composition provided a generalized means of moving continuously&mdash;sometimes, paradoxically, via discrete phases&mdash;through temporal and spectral states. The complexity of the interpolation networks in the preceding example, where processes unfold polyphonically, foreshadows Saariaho&rsquo;s continued reliance on the technique in works composed shortly after <i>IO</i>, among them <i>Amers</i> (1992) for solo cello, ensemble, and live electronics (<a href="#stoianova_1994" id="citation_stoianova_1994_67dc9954da6c9">Stoianova 1994</a>; <a href="#lorieux_2004" id="citation_lorieux_2004_67dc9954da6cb">Lorieux 2004</a>) and more recent works, such as her acclaimed opera, <i>L&rsquo;amour de loin</i> (2001), for which, &ldquo;the notion of interpolation is essential for understanding certain sonic textures&rdquo; (<a href="#battier_and_nouno_2003" id="citation_battier_and_nouno_2003_67dc9954da6d8">Battier and Nouno 2003</a>, 52). Moreover, the processual forms and nebulous textures that result from these interpolations resonate with Judith Lochhead&rsquo;s description of musical &ldquo;radiance&rdquo; in pieces like <i>Lonh</i> (1996), which results from the interaction of &ldquo;moments of sonic luminance<nobr>. . .</nobr> moments of formal flickering<nobr>. . .</nobr> and moments of intensity arising from the completion of transformational processes&rdquo; (<a href="#lochhead_2016" id="citation_lochhead_2016_67dc9954da6da">2016</a>, 111). As these subsequent applications indicate, the interpolation techniques Saariaho worked out in germinal form for <i>Vers le blanc</i> remained central to her music over the coming decades.</p>


<h2>5. Transduction as an Analytical Frame for Archival Music Research</h2>

<p>[5.1] This article began with an inquiry into genetic artifacts from the creation of <i>Vers le blanc</i>, Saariaho&rsquo;s first study in computer-based music using the CHANT program. The pairing of these two objects&mdash;one aesthetic, the other technological&mdash;opened a new window onto compositional techniques and computational processes that would otherwise remain opaque and inaccessible. At all stages of analysis, however, it has been necessary to think transductively about all musical-media sources, at every turn posing the question, &ldquo;what does this particular archival trace show?&rdquo;</p>

<p>[5.2] Recapitulating briefly, Saariaho&rsquo;s published score of <i>Vers le blanc</i> (Example 1) showed a simple harmonic motion from one trichord to another, while the archival recordings (Audio Examples 1&ndash;3) revealed a chorus of voices harboring rich, fluctuating timbral profiles. The different kinds of information conveyed by these materials produced a fissure between the <i>work-as-seen</i> versus the <i>work-as-heard</i>. Thanks to an unusually complete archival record, it was possible to narrow that gap. First, Saariaho&rsquo;s form diagram of sub-note parameters in each voice (Example 2), as well as her sketches of phoneme sequences (Examples 8 and 9), revealed vital conceptual information for how the piece was organized at both micro- and macro-levels. Second, a printed record of the original code (Examples 3 and 5) showed technical specifications for how Saariaho controlled individual sonic parameters using lists of breakpoint functions. Third and finally, a CHANT user&rsquo;s manual (Example 6) was enlisted to decipher the code and understand the software&rsquo;s operational affordances, including its dictionary of spectral shapes representing phonemes. Brought together in the same analytical frame, these scattered traces offer unique insight into how Saariaho adopted interpolative processes as the basis of a compositional method, how she enriched and rebalanced musical parameters, most notably harmony and timbre, and how she came to think about musical form as a &ldquo;multidimensional network.&rdquo;</p>

<p>[5.3] We have seen that attending to the material and informational artifacts associated with Saariaho&rsquo;s early electronic music has value for analyzing her early works and for better understanding her development and influence as a composer. Critically, this approach has further utility in shining new light on the techno-cultural milieu she inhabited. Programs like CHANT and the pieces Saariaho created with their help can be thought of as sonic souvenirs of the &ldquo;sound synthesis utopia&rdquo; evoked by Barri&egrave;re, as they encompass both a set of assumptions about sound&rsquo;s perceived effects and their representation in software, as well as a particular mode of working with sound that flourished at IRCAM in the eighties. With this in mind, and taking a cue from nascent methodologies like those articulated by the New Organology, I have attempted to extend the scope of analysis in this study beyond the &ldquo;music itself,&rdquo; engaging with its underlying technologies, along with their &ldquo;material configurations, social and institutional locations, degrees of freedom, and teleologies&rdquo; (<a href="#tresch_and_dolan_2013" id="citation_tresch_and_dolan_2013_67dc9954da6dc">Tresch and Dolan 2013</a>, 278). The specific answers about Saariaho&rsquo;s music yielded from this approach contribute to a fuller understanding of how her style and techniques were deeply entangled with the technological affordances of IRCAM software and the cultural aesthetics of an emerging post-spectral milieu. While writ large, the questions this kind of methodology raises about analyzing across diverse media formats, old and new, point toward the necessity of developing transductive approaches to archival research.</p>

<!-------------------------------- END Article Body -------------------------------------------->

     
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Author Info -------------------------------------------->

  
<hr>

	<p><a name="AUTHORNOTE1"></a>
	
	Landon Morrison<br>
	College Fellow in Music Theory<br>Harvard University Department of Music<br>3 Oxford St.<br>Cambridge, MA 02138<br><a href="mailto:landonmorrison@fas.harvard.edu">landonmorrison@fas.harvard.edu</a><br>	
</p>

       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Works Cited List -------------------------------------------->

  
	<hr>
	
	<h3><a name="WorksCited">Works Cited</a></h3>
	
	<div id="citediv_baisn&eacute;e_et_al_1985" class="flyoverdiv">Baisn&eacute;e, Pierre-Fran&ccedil;ois, and The CHANT group. 1985. &ldquo;CHANT Manual.&rdquo; Document obtained through correspondence with IRCAM researcher Axel Roebel, February 12, 2019.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="baisn&eacute;e_et_al_1985"></a>Baisn&eacute;e, Pierre-Fran&ccedil;ois, and The CHANT group. 1985. &ldquo;CHANT Manual.&rdquo; Document obtained through correspondence with IRCAM researcher Axel Roebel, February 12, 2019.</p><div id="citediv_battier_and_nouno_2003" class="flyoverdiv">Battier, Marc, and Gilbert Nouno. 2003. &ldquo;L&rsquo;&eacute;lectronique dans l&rsquo;op&eacute;ra de Kaija Saariaho, <i>L&rsquo;Amour de loin</i>.&rdquo; <i>Musurgia</i> 10 (2): 51&ndash;59. <a href='https://www.jstor.org/stable/40591280'>https://www.jstor.org/stable/40591280</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="battier_and_nouno_2003"></a>Battier, Marc, and Gilbert Nouno. 2003. &ldquo;L&rsquo;&eacute;lectronique dans l&rsquo;op&eacute;ra de Kaija Saariaho, <i>L&rsquo;Amour de loin</i>.&rdquo; <i>Musurgia</i> 10 (2): 51&ndash;59. <a href='https://www.jstor.org/stable/40591280'>https://www.jstor.org/stable/40591280</a>.</p><div id="citediv_bennett_1979" class="flyoverdiv">Bennett, Gerald. 1979. &ldquo;Research at IRCAM in 1978.&rdquo; <i>Rapports IRCAM vol. 19</i>. Centre Georges Pompidou.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="bennett_1979"></a>Bennett, Gerald. 1979. &ldquo;Research at IRCAM in 1978.&rdquo; <i>Rapports IRCAM vol. 19</i>. Centre Georges Pompidou.</p><div id="citediv_bennett_1981" class="flyoverdiv">Bennett, Gerald. 1981. &ldquo;Singing Synthesis in Electronic Music.&rdquo; In <i>Research Aspects on Singing 33</i>, 34&ndash;50. Royal Swedish Academy of Music.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="bennett_1981"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1981. &ldquo;Singing Synthesis in Electronic Music.&rdquo; In <i>Research Aspects on Singing 33</i>, 34&ndash;50. Royal Swedish Academy of Music.</p><div id="citediv_besada_and_canov&aacute;s_2020" class="flyoverdiv">Besada, Jos&eacute;, and Crist&oacute;bal Pag&aacute;n C&aacute;novas. 2020. &ldquo;Timelines in Spectral Composition: A Cognitive Approach to Musical Creativity.&rdquo; <i>Organised Sound</i> 25 (2): 142&ndash;55. <a href='https://doi.org/10.1017/S1355771820000059'>https://doi.org/10.1017/S1355771820000059</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="besada_and_canov&aacute;s_2020"></a>Besada, Jos&eacute;, and Crist&oacute;bal Pag&aacute;n C&aacute;novas. 2020. &ldquo;Timelines in Spectral Composition: A Cognitive Approach to Musical Creativity.&rdquo; <i>Organised Sound</i> 25 (2): 142&ndash;55. <a href='https://doi.org/10.1017/S1355771820000059'>https://doi.org/10.1017/S1355771820000059</a>.</p><div id="citediv_bonardi_and_barth&eacute;lemy_2008" class="flyoverdiv">Bonardi, Alain, and J&eacute;rome Barth&eacute;lemy. 2008. &ldquo;The Preservation, Emulation, Migration, and Virtualization of Live Electronics for Performing Arts: An Overview of Musical and Technical Issues.&rdquo; <i>Journal on Computing and Cultural Heritage</i> 1 (1): 1&ndash;16. <a href='https://doi.org/10.1145/1367080.1367086'>https://doi.org/10.1145/1367080.1367086</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="bonardi_and_barth&eacute;lemy_2008"></a>Bonardi, Alain, and J&eacute;rome Barth&eacute;lemy. 2008. &ldquo;The Preservation, Emulation, Migration, and Virtualization of Live Electronics for Performing Arts: An Overview of Musical and Technical Issues.&rdquo; <i>Journal on Computing and Cultural Heritage</i> 1 (1): 1&ndash;16. <a href='https://doi.org/10.1145/1367080.1367086'>https://doi.org/10.1145/1367080.1367086</a>.</p><div id="citediv_born_1995" class="flyoverdiv">Born, Georgina. 1995. <i>Rationalizing Culture: IRCAM, Boulez, and the Institutionalization of the Avant-garde</i>. University of California Press. <a href='https://doi.org/10.1525/9780520916845'>https://doi.org/10.1525/9780520916845</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="born_1995"></a>Born, Georgina. 1995. <i>Rationalizing Culture: IRCAM, Boulez, and the Institutionalization of the Avant-garde</i>. University of California Press. <a href='https://doi.org/10.1525/9780520916845'>https://doi.org/10.1525/9780520916845</a>.</p><div id="citediv_born_1997" class="flyoverdiv">Born, Georgina. 1997. &ldquo;Computer Software as a Medium: Textuality, Orality, and Sociality in an Artificial Intelligence Culture.&rdquo; In <i>Rethinking Visual Anthropology</i>, ed. Howard Morphy and Marcus Banks, 139&ndash;69. Yale University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="born_1997"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1997. &ldquo;Computer Software as a Medium: Textuality, Orality, and Sociality in an Artificial Intelligence Culture.&rdquo; In <i>Rethinking Visual Anthropology</i>, ed. Howard Morphy and Marcus Banks, 139&ndash;69. Yale University Press.</p><div id="citediv_born_2005" class="flyoverdiv">Born, Georgina. 2005. &ldquo;On Musical Mediation: Ontology, Technology and Creativity.&rdquo; <i>Twentieth-Century Music</i> 2 (1): 7&ndash;36. <a href='https://doi.org/10.1017/S147857220500023X'>https://doi.org/10.1017/S147857220500023X</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="born_2005"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2005. &ldquo;On Musical Mediation: Ontology, Technology and Creativity.&rdquo; <i>Twentieth-Century Music</i> 2 (1): 7&ndash;36. <a href='https://doi.org/10.1017/S147857220500023X'>https://doi.org/10.1017/S147857220500023X</a>.</p><div id="citediv_boutard_and_guastavino_2012" class="flyoverdiv">Boutard, Guillaume, and Catherine Guastavino. 2012. &ldquo;Archiving Electroacoustic and Mixed Music: Significant Knowledge Involved in the Creative Process of Works with Spatialisation.&rdquo; <i>Journal of Documentation</i> 68 (6): 749&ndash;71. <a href='https://doi.org/10.1108/00220411211277028'>https://doi.org/10.1108/00220411211277028</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="boutard_and_guastavino_2012"></a>Boutard, Guillaume, and Catherine Guastavino. 2012. &ldquo;Archiving Electroacoustic and Mixed Music: Significant Knowledge Involved in the Creative Process of Works with Spatialisation.&rdquo; <i>Journal of Documentation</i> 68 (6): 749&ndash;71. <a href='https://doi.org/10.1108/00220411211277028'>https://doi.org/10.1108/00220411211277028</a>.</p><div id="citediv_callender_2004" class="flyoverdiv">Callender, Clifton. 2004. &ldquo;Continuous Transformations.&rdquo; <i>Music Theory Online</i> 10 (3). <a href='https://mtosmt.org/issues/mto.04.10.3/mto.04.10.3.callender.pdf'>https://mtosmt.org/issues/mto.04.10.3/mto.04.10.3.callender.pdf</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="callender_2004"></a>Callender, Clifton. 2004. &ldquo;Continuous Transformations.&rdquo; <i>Music Theory Online</i> 10 (3). <a href='https://mtosmt.org/issues/mto.04.10.3/mto.04.10.3.callender.pdf'>https://mtosmt.org/issues/mto.04.10.3/mto.04.10.3.callender.pdf</a>.</p><div id="citediv_campion_2017" class="flyoverdiv">Campion, Edmund. 2017. &ldquo;Dual Reflections: A Conversation with Kaija Saariaho and Jean-Baptiste Barri&egrave;re on Music, Art, and Technology.&rdquo; <i>Computer Music Journal</i> 41 (3): 9&ndash;20. <a href='https://doi.org/10.1162/comj_a_00426'>https://doi.org/10.1162/comj_a_00426</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="campion_2017"></a>Campion, Edmund. 2017. &ldquo;Dual Reflections: A Conversation with Kaija Saariaho and Jean-Baptiste Barri&egrave;re on Music, Art, and Technology.&rdquo; <i>Computer Music Journal</i> 41 (3): 9&ndash;20. <a href='https://doi.org/10.1162/comj_a_00426'>https://doi.org/10.1162/comj_a_00426</a>.</p><div id="citediv_chun_2011" class="flyoverdiv">Chun, Wendy Hui Kyong. 2011. <i>Programmed Visions: Software and Memory</i>. MIT Press. <a href='https://doi.org/10.7551/mitpress/9780262015424.001.0001'>https://doi.org/10.7551/mitpress/9780262015424.001.0001</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="chun_2011"></a>Chun, Wendy Hui Kyong. 2011. <i>Programmed Visions: Software and Memory</i>. MIT Press. <a href='https://doi.org/10.7551/mitpress/9780262015424.001.0001'>https://doi.org/10.7551/mitpress/9780262015424.001.0001</a>.</p><div id="citediv_donin_2009" class="flyoverdiv">Donin, Nicolas. 2009. &ldquo;Genetic Criticism and Cognitive Anthropology: A Reconstruction of Philippe Leroux&rsquo;s Compositional Process for Voi(rex).&rdquo; In <i>Genetic Criticism and the Creative Process: Essays from Music, Literature, and Theater</i>, ed. William Kinderman and Joseph E. Jones, 192&ndash;215. University of Rochester Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="donin_2009"></a>Donin, Nicolas. 2009. &ldquo;Genetic Criticism and Cognitive Anthropology: A Reconstruction of Philippe Leroux&rsquo;s Compositional Process for Voi(rex).&rdquo; In <i>Genetic Criticism and the Creative Process: Essays from Music, Literature, and Theater</i>, ed. William Kinderman and Joseph E. Jones, 192&ndash;215. University of Rochester Press.</p><div id="citediv_drott_2017" class="flyoverdiv">Drott, Eric. 2017. &ldquo;Saariaho, Timbre, and Tonality.&rdquo; In <i>Tonality Since 1950</i>, ed. Felix W&ouml;rner, Ullrich Scheideler, and Philip Rupprecht, 259&ndash;81. Franz Steiner Verlag.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="drott_2017"></a>Drott, Eric. 2017. &ldquo;Saariaho, Timbre, and Tonality.&rdquo; In <i>Tonality Since 1950</i>, ed. Felix W&ouml;rner, Ullrich Scheideler, and Philip Rupprecht, 259&ndash;81. Franz Steiner Verlag.</p><div id="citediv_dudley_et_al_1939" class="flyoverdiv">Dudley, Homer, R. R. Riesz, and S. S. A. Watkins. 1939. &ldquo;A Synthetic Speaker.&rdquo; <i>Journal of the Franklin Institute</i> 6 (227): 739&ndash;64. <a href='https://doi.org/10.1016/S0016-0032(39)90816-1'>https://doi.org/10.1016/S0016-0032(39)90816-1</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="dudley_et_al_1939"></a>Dudley, Homer, R. R. Riesz, and S. S. A. Watkins. 1939. &ldquo;A Synthetic Speaker.&rdquo; <i>Journal of the Franklin Institute</i> 6 (227): 739&ndash;64. <a href='https://doi.org/10.1016/S0016-0032(39)90816-1'>https://doi.org/10.1016/S0016-0032(39)90816-1</a>.</p><div id="citediv_ernst_2014" class="flyoverdiv">Ernst, Wolfgang. 2014. &ldquo;Between the Archive and the Anarchivable.&rdquo; <i>Mnemoscape</i> 1. <a href='https://issuu.com/verr/docs/mn_____issue_n__01'>https://issuu.com/verr/docs/mn_____issue_n__01</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="ernst_2014"></a>Ernst, Wolfgang. 2014. &ldquo;Between the Archive and the Anarchivable.&rdquo; <i>Mnemoscape</i> 1. <a href='https://issuu.com/verr/docs/mn_____issue_n__01'>https://issuu.com/verr/docs/mn_____issue_n__01</a>.</p><div id="citediv_fant_1970" class="flyoverdiv">Fant, Gunnar. 1970. <i>Acoustic Theory of Speech Production</i>. Mouton. <a href='https://doi.org/10.1515/9783110873429'>https://doi.org/10.1515/9783110873429</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="fant_1970"></a>Fant, Gunnar. 1970. <i>Acoustic Theory of Speech Production</i>. Mouton. <a href='https://doi.org/10.1515/9783110873429'>https://doi.org/10.1515/9783110873429</a>.</p><div id="citediv_feller_2005" class="flyoverdiv">Feller, Ross. 2005. &ldquo;E-Sketches: Brian Ferneyhough&rsquo;s Use of Computer-Assisted Compositional Tools.&rdquo; In <i>A Handbook to Twentieth-Century Musical Sketches</i>, ed. Patricia Hall and Friedemann Sallis, 176&ndash;88. Cambridge University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="feller_2005"></a>Feller, Ross. 2005. &ldquo;E-Sketches: Brian Ferneyhough&rsquo;s Use of Computer-Assisted Compositional Tools.&rdquo; In <i>A Handbook to Twentieth-Century Musical Sketches</i>, ed. Patricia Hall and Friedemann Sallis, 176&ndash;88. Cambridge University Press.</p><div id="citediv_gardner_1978" class="flyoverdiv">Gardner, John. 1978. &ldquo;Computer Facilities for Music at IRCAM, as of October, 1977.&rdquo; <i>Rapports IRCAM vol. 3</i>. Centre Georges Pompidou.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="gardner_1978"></a>Gardner, John. 1978. &ldquo;Computer Facilities for Music at IRCAM, as of October, 1977.&rdquo; <i>Rapports IRCAM vol. 3</i>. Centre Georges Pompidou.</p><div id="citediv_grisey_2000_1998" class="flyoverdiv">Grisey, G&eacute;rard. 2000 [1998]. &ldquo;Did You Say Spectral?&rdquo; <i>Contemporary Music Review</i> 19 (3):1&ndash;3. <a href='https://doi.org/10.1080/07494460000640311'>https://doi.org/10.1080/07494460000640311</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="grisey_2000_1998"></a>Grisey, G&eacute;rard. 2000 [1998]. &ldquo;Did You Say Spectral?&rdquo; <i>Contemporary Music Review</i> 19 (3):1&ndash;3. <a href='https://doi.org/10.1080/07494460000640311'>https://doi.org/10.1080/07494460000640311</a>.</p><div id="citediv_grisey_2018_2008" class="flyoverdiv">Grisey, G&eacute;rard. 2018 [2008]. <i>&Eacute;crits</i>. Edited by Guy Lelong and Anne-Marie R&eacute;by. &Eacute;ditions MF.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="grisey_2018_2008"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2018 [2008]. <i>&Eacute;crits</i>. Edited by Guy Lelong and Anne-Marie R&eacute;by. &Eacute;ditions MF.</p><div id="citediv_helmholtz_1954_1863" class="flyoverdiv">Helmholtz, Hermann V. 1954 [1863]. <i>On the Sensations of Tone as a Physiological Basis for the Theory of Music</i>. Translated by Alexander Ellis. Dover Publications.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="helmholtz_1954_1863"></a>Helmholtz, Hermann V. 1954 [1863]. <i>On the Sensations of Tone as a Physiological Basis for the Theory of Music</i>. Translated by Alexander Ellis. Dover Publications.</p><div id="citediv_howell_2006" class="flyoverdiv">Howell, Tim. 2006. <i>After Sibelius: Studies in Finnish Music</i>. Ashgate.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="howell_2006"></a>Howell, Tim. 2006. <i>After Sibelius: Studies in Finnish Music</i>. Ashgate.</p><div id="citediv_huhtamo_2011" class="flyoverdiv">Huhtamo, Erkki, and Jussi Parikka, eds. 2011. <i>Media Archaeology: Approaches, Applications, and Implications</i>. University of California Press. <a href='https://doi.org/10.1525/9780520948518'>https://doi.org/10.1525/9780520948518</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="huhtamo_2011"></a>Huhtamo, Erkki, and Jussi Parikka, eds. 2011. <i>Media Archaeology: Approaches, Applications, and Implications</i>. University of California Press. <a href='https://doi.org/10.1525/9780520948518'>https://doi.org/10.1525/9780520948518</a>.</p><div id="citediv_iverson_2011" class="flyoverdiv">Iverson, Jennifer. 2011. &ldquo;The Emergence of Timbre: Ligeti&rsquo;s Synthesis of Electronic and Acoustic Music in <i>Atmosph&egrave;res</i>.&rdquo; <i>Twentieth-Century Music</i> 7 (1): 61&ndash;89. <a href='https://doi.org/10.1017/S1478572211000053'>https://doi.org/10.1017/S1478572211000053</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="iverson_2011"></a>Iverson, Jennifer. 2011. &ldquo;The Emergence of Timbre: Ligeti&rsquo;s Synthesis of Electronic and Acoustic Music in <i>Atmosph&egrave;res</i>.&rdquo; <i>Twentieth-Century Music</i> 7 (1): 61&ndash;89. <a href='https://doi.org/10.1017/S1478572211000053'>https://doi.org/10.1017/S1478572211000053</a>.</p><div id="citediv_iverson_2017" class="flyoverdiv">Iverson, Jennifer. 2017. &ldquo;Invisible Collaboration: The Dawn and Evolution of elektronische Musik.&rdquo; <i>Music Theory Spectrum</i> (39): 200&ndash;22. <a href='https://doi.org/10.1093/mts/mtx017'>https://doi.org/10.1093/mts/mtx017</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="iverson_2017"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2017. &ldquo;Invisible Collaboration: The Dawn and Evolution of elektronische Musik.&rdquo; <i>Music Theory Spectrum</i> (39): 200&ndash;22. <a href='https://doi.org/10.1093/mts/mtx017'>https://doi.org/10.1093/mts/mtx017</a>.</p><div id="citediv_iverson_2019" class="flyoverdiv">Iverson, Jennifer. 2019. <i>Electronic Inspirations: Technologies of the Cold War Musical Avant-garde</i>. Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="iverson_2019"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2019. <i>Electronic Inspirations: Technologies of the Cold War Musical Avant-garde</i>. Oxford University Press.</p><div id="citediv_kankaanp&auml;&auml;_2011" class="flyoverdiv">Kankaanp&auml;&auml;, Vesa. 2011. &ldquo;Dichotomies, Relationships: Timbre and Harmony in Revolution.&rdquo; In <i>Kaija Saariaho: Visions, Narratives, Dialogues</i>, ed. Howell et al., 159&ndash;76. Ashgate.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="kankaanp&auml;&auml;_2011"></a>Kankaanp&auml;&auml;, Vesa. 2011. &ldquo;Dichotomies, Relationships: Timbre and Harmony in Revolution.&rdquo; In <i>Kaija Saariaho: Visions, Narratives, Dialogues</i>, ed. Howell et al., 159&ndash;76. Ashgate.</p><div id="citediv_von_kempelen_2017_1791" class="flyoverdiv">von Kempelen, Wolfgang. 2017 [1791]. <i>Der Mechanismus der menschlichen Sprache / The Mechanism of Human Speech</i>. Edited and translated by Fabian Brackhane, Richard Sproat, and J&uuml;rgen Trouvain. TUD Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="von_kempelen_2017_1791"></a>von Kempelen, Wolfgang. 2017 [1791]. <i>Der Mechanismus der menschlichen Sprache / The Mechanism of Human Speech</i>. Edited and translated by Fabian Brackhane, Richard Sproat, and J&uuml;rgen Trouvain. TUD Press.</p><div id="citediv_lee_2006" class="flyoverdiv">Lee, Brent. 2006. &ldquo;Issues Surrounding the Preservation of Digital Music Documents.&rdquo; <i>Archivaria</i> 50: 193&ndash;204. <a href='https://archivaria.ca/index.php/archivaria/article/view/12783'>https://archivaria.ca/index.php/archivaria/article/view/12783</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lee_2006"></a>Lee, Brent. 2006. &ldquo;Issues Surrounding the Preservation of Digital Music Documents.&rdquo; <i>Archivaria</i> 50: 193&ndash;204. <a href='https://archivaria.ca/index.php/archivaria/article/view/12783'>https://archivaria.ca/index.php/archivaria/article/view/12783</a>.</p><div id="citediv_lemouton_et_al_2018" class="flyoverdiv">Lemouton, Serge, Alain Bonardi, Laurent Pottier, and Jacques Warnier. 2018. &ldquo;On the Documentation of Electronic Music.&rdquo; <i>Computer Music Journal</i> 42 (4): 41&ndash;58. <a href='https://doi.org/10.1162/comj_a_00486'>https://doi.org/10.1162/comj_a_00486</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lemouton_et_al_2018"></a>Lemouton, Serge, Alain Bonardi, Laurent Pottier, and Jacques Warnier. 2018. &ldquo;On the Documentation of Electronic Music.&rdquo; <i>Computer Music Journal</i> 42 (4): 41&ndash;58. <a href='https://doi.org/10.1162/comj_a_00486'>https://doi.org/10.1162/comj_a_00486</a>.</p><div id="citediv_levy_2009" class="flyoverdiv">Levy, Benjamin. 2009. &ldquo;Shades of the Studio: Electronic Influence in Ligeti&rsquo;s <i>Apparitions</i>.&rdquo; <i>Perspectives of New Music</i> 47 (2): 59&ndash;87. <a href='https://www.jstor.org/stable/25753697'>https://www.jstor.org/stable/25753697</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="levy_2009"></a>Levy, Benjamin. 2009. &ldquo;Shades of the Studio: Electronic Influence in Ligeti&rsquo;s <i>Apparitions</i>.&rdquo; <i>Perspectives of New Music</i> 47 (2): 59&ndash;87. <a href='https://www.jstor.org/stable/25753697'>https://www.jstor.org/stable/25753697</a>.</p><div id="citediv_lochhead_2016" class="flyoverdiv">Lochhead, Judith. 2016. <i>Reconceiving Structure in Contemporary Music: New Tools in Music Theory and Analysis</i>. Routledge. <a href='https://doi.org/10.4324/9781315740744'>https://doi.org/10.4324/9781315740744</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lochhead_2016"></a>Lochhead, Judith. 2016. <i>Reconceiving Structure in Contemporary Music: New Tools in Music Theory and Analysis</i>. Routledge. <a href='https://doi.org/10.4324/9781315740744'>https://doi.org/10.4324/9781315740744</a>.</p><div id="citediv_lorieux_2004" class="flyoverdiv">Lorieux, Gr&eacute;goire. 2004. &ldquo;Une analyse d&rsquo;Amer de Kaija Saariaho.&rdquo; <i>Revue DEM&eacute;ter</i>. <a href='http://demeter.revue.univ-lille3.fr/analyse/lorieux.pdf'>http://demeter.revue.univ-lille3.fr/analyse/lorieux.pdf</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lorieux_2004"></a>Lorieux, Gr&eacute;goire. 2004. &ldquo;Une analyse d&rsquo;Amer de Kaija Saariaho.&rdquo; <i>Revue DEM&eacute;ter</i>. <a href='http://demeter.revue.univ-lille3.fr/analyse/lorieux.pdf'>http://demeter.revue.univ-lille3.fr/analyse/lorieux.pdf</a>.</p><div id="citediv_manovich_2001" class="flyoverdiv">Manovich, Lev. 2001. <i>The Language of New Media</i>. MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="manovich_2001"></a>Manovich, Lev. 2001. <i>The Language of New Media</i>. MIT Press.</p><div id="citediv_manovich_2013" class="flyoverdiv">Manovich, Lev. 2013. <i>Software Takes Command</i>. Bloomsbury Publishing.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="manovich_2013"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2013. <i>Software Takes Command</i>. Bloomsbury Publishing.</p><div id="citediv_mathews_1961" class="flyoverdiv">Mathews, Max. 1961. &ldquo;Compiler for Music and Psychological Stimuli.&rdquo; <i>Bell System Technical Journal</i> 40 (3): 677&ndash;94. <a href='https://doi.org/10.1002/j.1538-7305.1961.tb03237.x'>https://doi.org/10.1002/j.1538-7305.1961.tb03237.x</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="mathews_1961"></a>Mathews, Max. 1961. &ldquo;Compiler for Music and Psychological Stimuli.&rdquo; <i>Bell System Technical Journal</i> 40 (3): 677&ndash;94. <a href='https://doi.org/10.1002/j.1538-7305.1961.tb03237.x'>https://doi.org/10.1002/j.1538-7305.1961.tb03237.x</a>.</p><div id="citediv_mcadams_and_saariaho_1985" class="flyoverdiv">McAdams, Stephen, and Kaija Saariaho. 1985. &ldquo;Qualities and Functions of Musical Timbre.&rdquo; In <i>Proceedings of the 1985 International Computer Music Conference</i>, 367&ndash;74. Michigan Publishing.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="mcadams_and_saariaho_1985"></a>McAdams, Stephen, and Kaija Saariaho. 1985. &ldquo;Qualities and Functions of Musical Timbre.&rdquo; In <i>Proceedings of the 1985 International Computer Music Conference</i>, 367&ndash;74. Michigan Publishing.</p><div id="citediv_meyer_1989" class="flyoverdiv">Meyer, Leonard. 1989. <i>Style and Music: Theory, History, and Ideology</i>. University of Pennsylvania Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="meyer_1989"></a>Meyer, Leonard. 1989. <i>Style and Music: Theory, History, and Ideology</i>. University of Pennsylvania Press.</p><div id="citediv_morrison_2020" class="flyoverdiv">Morrison, Landon. 2020. &ldquo;Sounds, Signs, Signals: Transductive Currents in Post-Spectral Music at IRCAM.&rdquo; PhD diss., McGill University.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="morrison_2020"></a>Morrison, Landon. 2020. &ldquo;Sounds, Signs, Signals: Transductive Currents in Post-Spectral Music at IRCAM.&rdquo; PhD diss., McGill University.</p><div id="citediv_nelson_2015" class="flyoverdiv">Nelson, Andrew. 2015. <i>The Sound of Innovation: Stanford and the Computer Music Revolution</i>. MIT Press. <a href='https://doi.org/10.7551/mitpress/10086.001.0001'>https://doi.org/10.7551/mitpress/10086.001.0001</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="nelson_2015"></a>Nelson, Andrew. 2015. <i>The Sound of Innovation: Stanford and the Computer Music Revolution</i>. MIT Press. <a href='https://doi.org/10.7551/mitpress/10086.001.0001'>https://doi.org/10.7551/mitpress/10086.001.0001</a>.</p><div id="citediv_piekut_2014" class="flyoverdiv">Piekut, Benjamin. 2014. &ldquo;Actor-Networks in Music History: Clarifications and Critiques.&rdquo; <i>Twentieth-Century Music</i> 11 (2): 191&ndash;215. <a href='https://doi.org/10.1017/S147857221400005X'>https://doi.org/10.1017/S147857221400005X</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="piekut_2014"></a>Piekut, Benjamin. 2014. &ldquo;Actor-Networks in Music History: Clarifications and Critiques.&rdquo; <i>Twentieth-Century Music</i> 11 (2): 191&ndash;215. <a href='https://doi.org/10.1017/S147857221400005X'>https://doi.org/10.1017/S147857221400005X</a>.</p><div id="citediv_pousset_et_al_2000" class="flyoverdiv">Pousset, Damien, Joshua Fineberg, and Ronan Hyacinthe. 2000. &ldquo;The works of Kaija Saariaho, Philippe Hurel and Marc-Andr&eacute; Dalbavie-Stile concertato, stile concitato, stile rappresentativo.&rdquo; <i>Contemporary Music Review</i> 10 (3): 67&ndash;110. <a href='https://doi.org/10.1080/07494460000640371'>https://doi.org/10.1080/07494460000640371</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="pousset_et_al_2000"></a>Pousset, Damien, Joshua Fineberg, and Ronan Hyacinthe. 2000. &ldquo;The works of Kaija Saariaho, Philippe Hurel and Marc-Andr&eacute; Dalbavie-Stile concertato, stile concitato, stile rappresentativo.&rdquo; <i>Contemporary Music Review</i> 10 (3): 67&ndash;110. <a href='https://doi.org/10.1080/07494460000640371'>https://doi.org/10.1080/07494460000640371</a>.</p><div id="citediv_rehding_2016" class="flyoverdiv">Rehding, Alexander. 2016. &ldquo;Instruments of Music Theory.&rdquo; <i>Music Theory Online</i> 22 (4). <a href='https://doi.org/10.30535/mto.22.4.4'>https://doi.org/10.30535/mto.22.4.4</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="rehding_2016"></a>Rehding, Alexander. 2016. &ldquo;Instruments of Music Theory.&rdquo; <i>Music Theory Online</i> 22 (4). <a href='https://doi.org/10.30535/mto.22.4.4'>https://doi.org/10.30535/mto.22.4.4</a>.</p><div id="citediv_rehding_et_al_2017" class="flyoverdiv">Rehding, Alexander, Gundula Kreuzer, Peter McMurray, Sybille Kr&auml;mer, and Roger Moseley. 2017. &ldquo;Discrete/Continuous: Music and Media Theory After Kittler.&rdquo; <i>Journal of the American Musicological Society</i> 70 (1): 221&ndash;56. <a href='https://doi.org/10.1525/jams.2017.70.1.221'>https://doi.org/10.1525/jams.2017.70.1.221</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="rehding_et_al_2017"></a>Rehding, Alexander, Gundula Kreuzer, Peter McMurray, Sybille Kr&auml;mer, and Roger Moseley. 2017. &ldquo;Discrete/Continuous: Music and Media Theory After Kittler.&rdquo; <i>Journal of the American Musicological Society</i> 70 (1): 221&ndash;56. <a href='https://doi.org/10.1525/jams.2017.70.1.221'>https://doi.org/10.1525/jams.2017.70.1.221</a>.</p><div id="citediv_rodet_and_cointe_1984" class="flyoverdiv">Rodet, Xavier, and Pierre Cointe. 1984. &ldquo;FORMES: Composition and Scheduling of Processes.&rdquo; <i>Computer Music Journal</i> 8 (3): 32&ndash;50. <a href='https://doi.org/10.2307/3679811'>https://doi.org/10.2307/3679811</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="rodet_and_cointe_1984"></a>Rodet, Xavier, and Pierre Cointe. 1984. &ldquo;FORMES: Composition and Scheduling of Processes.&rdquo; <i>Computer Music Journal</i> 8 (3): 32&ndash;50. <a href='https://doi.org/10.2307/3679811'>https://doi.org/10.2307/3679811</a>.</p><div id="citediv_rodet_et_al_1984" class="flyoverdiv">Rodet, Xavier, Yves Potart, and Jean-Baptiste Barri&egrave;re. 1984. &ldquo;The CHANT Project: From the Synthesis of the Singing Voice to Synthesis in General.&rdquo; <i>Computer Music Journal</i> 8 (3): 15&ndash;31. <a href='https://doi.org/10.2307/3679810'>https://doi.org/10.2307/3679810</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="rodet_et_al_1984"></a>Rodet, Xavier, Yves Potart, and Jean-Baptiste Barri&egrave;re. 1984. &ldquo;The CHANT Project: From the Synthesis of the Singing Voice to Synthesis in General.&rdquo; <i>Computer Music Journal</i> 8 (3): 15&ndash;31. <a href='https://doi.org/10.2307/3679810'>https://doi.org/10.2307/3679810</a>.</p><div id="citediv_roeder_2008" class="flyoverdiv">Roeder, John. 2008. &ldquo;Art and Digital Records: Paradoxes and Problems of Preservation.&rdquo; <i>Archivaria</i> 65 (1): 151&ndash;63. <a href='https://archivaria.ca/index.php/archivaria/article/view/13173'>https://archivaria.ca/index.php/archivaria/article/view/13173</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="roeder_2008"></a>Roeder, John. 2008. &ldquo;Art and Digital Records: Paradoxes and Problems of Preservation.&rdquo; <i>Archivaria</i> 65 (1): 151&ndash;63. <a href='https://archivaria.ca/index.php/archivaria/article/view/13173'>https://archivaria.ca/index.php/archivaria/article/view/13173</a>.</p><div id="citediv_saariaho_1983" class="flyoverdiv">Saariaho, Kaija. 1983. &ldquo;Using the Computer in a Search for New Aspects of Timbre Organisation and Composition.&rdquo; In <i>Proceedings of the International Computer Music Conference</i>, 269&ndash;73. Michigan Publishing.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1983"></a>Saariaho, Kaija. 1983. &ldquo;Using the Computer in a Search for New Aspects of Timbre Organisation and Composition.&rdquo; In <i>Proceedings of the International Computer Music Conference</i>, 269&ndash;73. Michigan Publishing.</p><div id="citediv_saariaho_1984" class="flyoverdiv">Saariaho, Kaija. 1984. &ldquo;Shaping a Compositional Network with Computers.&rdquo; In <i>Proceedings of the International Computer Music Conference</i>, 163&ndash;65. Michigan Publishing.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1984"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1984. &ldquo;Shaping a Compositional Network with Computers.&rdquo; In <i>Proceedings of the International Computer Music Conference</i>, 163&ndash;65. Michigan Publishing.</p><div id="citediv_saariaho_1987" class="flyoverdiv">Saariaho, Kaija. 1987. &ldquo;Timbre and Harmony: Interpolations of Timbral Structures.&rdquo; <i>Contemporary Music Review</i> 2 (1): 93&ndash;133. <a href='https://doi.org/10.1080/07494468708567055'>https://doi.org/10.1080/07494468708567055</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1987"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1987. &ldquo;Timbre and Harmony: Interpolations of Timbral Structures.&rdquo; <i>Contemporary Music Review</i> 2 (1): 93&ndash;133. <a href='https://doi.org/10.1080/07494468708567055'>https://doi.org/10.1080/07494468708567055</a>.</p><div id="citediv_saariaho_2013" class="flyoverdiv">Saariaho, Kaija. 2013. <i>Le Passage Des Fronti&egrave;res &Eacute;crits Sur La Musique</i>. Edited by St&eacute;phane Roth. &Eacute;ditions MF.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_2013"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2013. <i>Le Passage Des Fronti&egrave;res &Eacute;crits Sur La Musique</i>. Edited by St&eacute;phane Roth. &Eacute;ditions MF.</p><div id="citediv_sallis_et_al_2018" class="flyoverdiv">Sallis, Friedemann, Valentina Bertolani, Jan Burle, and Laura Zattra, eds. 2018. <i>Live Electronic Music: Composition, Performance, Study</i>. Routledge. <a href='https://doi.org/10.4324/9781315776989'>https://doi.org/10.4324/9781315776989</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sallis_et_al_2018"></a>Sallis, Friedemann, Valentina Bertolani, Jan Burle, and Laura Zattra, eds. 2018. <i>Live Electronic Music: Composition, Performance, Study</i>. Routledge. <a href='https://doi.org/10.4324/9781315776989'>https://doi.org/10.4324/9781315776989</a>.</p><div id="citediv_serexhe_2013" class="flyoverdiv">Serexhe, Bernhard, ed. 2013. <i>Preservation of Digital Art: Theory and Practice</i>. Ambra Verlag.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="serexhe_2013"></a>Serexhe, Bernhard, ed. 2013. <i>Preservation of Digital Art: Theory and Practice</i>. Ambra Verlag.</p><div id="citediv_sterne_2003" class="flyoverdiv">Sterne, Jonathan. 2003. <i>The Audible Past: Cultural Origins of Sound Reproduction</i>. Duke University Press. <a href='https://doi.org/10.1215/9780822384250'>https://doi.org/10.1215/9780822384250</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sterne_2003"></a>Sterne, Jonathan. 2003. <i>The Audible Past: Cultural Origins of Sound Reproduction</i>. Duke University Press. <a href='https://doi.org/10.1215/9780822384250'>https://doi.org/10.1215/9780822384250</a>.</p><div id="citediv_sterne_2012" class="flyoverdiv">Sterne, Jonathan. 2012. <i>MP3: The Meaning of a Format</i>. Duke University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sterne_2012"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2012. <i>MP3: The Meaning of a Format</i>. Duke University Press.</p><div id="citediv_stockhausen_1959_1957" class="flyoverdiv">Stockhausen, Karlheinz. 1959 [1957]. &ldquo;<nobr>. . .</nobr>How Time Passes<nobr>. . .</nobr>&rdquo; <i>Die Riehe</i> 3: 10&ndash;40.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="stockhausen_1959_1957"></a>Stockhausen, Karlheinz. 1959 [1957]. &ldquo;<nobr>. . .</nobr>How Time Passes<nobr>. . .</nobr>&rdquo; <i>Die Riehe</i> 3: 10&ndash;40.</p><div id="citediv_stoianova_1994" class="flyoverdiv">Stoianova, Ivanka. 1994. &ldquo;Une &oelig;uvre de synth&egrave;se : analyse d&rsquo;<i>Amers</i>.&rdquo; <i>Cahiers de l&rsquo;Ircam</i> (6): 43&ndash;66. </div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="stoianova_1994"></a>Stoianova, Ivanka. 1994. &ldquo;Une &oelig;uvre de synth&egrave;se : analyse d&rsquo;<i>Amers</i>.&rdquo; <i>Cahiers de l&rsquo;Ircam</i> (6): 43&ndash;66. </p><div id="citediv_sundberg_1977" class="flyoverdiv">Sundberg, Johan. 1977. &ldquo;The Acoustics of the Singing Voice.&rdquo; <i>Scientific American</i> 236 (3): 82&ndash;91.  <a href='https://doi.org/10.1038/scientificamerican0377-82'>https://doi.org/10.1038/scientificamerican0377-82</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sundberg_1977"></a>Sundberg, Johan. 1977. &ldquo;The Acoustics of the Singing Voice.&rdquo; <i>Scientific American</i> 236 (3): 82&ndash;91.  <a href='https://doi.org/10.1038/scientificamerican0377-82'>https://doi.org/10.1038/scientificamerican0377-82</a>.</p><div id="citediv_tresch_and_dolan_2013" class="flyoverdiv">Tresch, John, and Emily Dolan. 2013. &ldquo;Toward a New Organology: Instruments of Music and Science.&rdquo; <i>Osiris</i> 28 (1): 278&ndash;98. <a href='https://doi.org/10.1086/671381'>https://doi.org/10.1086/671381</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="tresch_and_dolan_2013"></a>Tresch, John, and Emily Dolan. 2013. &ldquo;Toward a New Organology: Instruments of Music and Science.&rdquo; <i>Osiris</i> 28 (1): 278&ndash;98. <a href='https://doi.org/10.1086/671381'>https://doi.org/10.1086/671381</a>.</p><div id="citediv_vandenheede_and_saariaho_1988" class="flyoverdiv">Vandenheede, Jan, and Kaija Saariaho. 1988. &ldquo;&Eacute;l&eacute;ments d&rsquo;analyse technique de <i>IO</i>.&rdquo; <i>Cahier d&rsquo;analyse cr&eacute;ation et technologie</i>. IRCAM.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="vandenheede_and_saariaho_1988"></a>Vandenheede, Jan, and Kaija Saariaho. 1988. &ldquo;&Eacute;l&eacute;ments d&rsquo;analyse technique de <i>IO</i>.&rdquo; <i>Cahier d&rsquo;analyse cr&eacute;ation et technologie</i>. IRCAM.</p><div id="citediv_wessel_1979" class="flyoverdiv">Wessel, David. 1979. &ldquo;Timbre Space as a Musical Control Structure.&rdquo; <i>Computer Music Journal</i> 3 (2): 45&ndash;52. <a href='https://doi.org/10.2307/3680283'>https://doi.org/10.2307/3680283</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="wessel_1979"></a>Wessel, David. 1979. &ldquo;Timbre Space as a Musical Control Structure.&rdquo; <i>Computer Music Journal</i> 3 (2): 45&ndash;52. <a href='https://doi.org/10.2307/3680283'>https://doi.org/10.2307/3680283</a>.</p><div id="citediv_wilson_2000_1989" class="flyoverdiv">Wilson, Peter Niklas. 2000 [1989]. &ldquo;Vers une &lsquo;&eacute;cologie des sons&rsquo;: <i>Partiels</i> de G&eacute;rard Grisey et l&rsquo;esth&eacute;tique du groupe de l&rsquo;Itin&eacute;raire.&rdquo; <i>Analyse musicale</i> (3): 36&ndash;52.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="wilson_2000_1989"></a>Wilson, Peter Niklas. 2000 [1989]. &ldquo;Vers une &lsquo;&eacute;cologie des sons&rsquo;: <i>Partiels</i> de G&eacute;rard Grisey et l&rsquo;esth&eacute;tique du groupe de l&rsquo;Itin&eacute;raire.&rdquo; <i>Analyse musicale</i> (3): 36&ndash;52.</p><div id="citediv__" class="flyoverdiv"><h3>Sound Recordings and Scores</h3></div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="_"></a><h3>Sound Recordings and Scores</h3></p><div id="citediv_saariaho_1990a" class="flyoverdiv">Saariaho, Kaija. 1990. <i>Denis Smalley, Mesias Maiguashca, Gareth Loy, Kaija Saariaho, Jonathan Harvey</i>. Wergo, CD.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1990a"></a>Saariaho, Kaija. 1990. <i>Denis Smalley, Mesias Maiguashca, Gareth Loy, Kaija Saariaho, Jonathan Harvey</i>. Wergo, CD.</p><div id="citediv_saariaho_1990b" class="flyoverdiv">Saariaho, Kaija. 1990. <i>Cr&eacute;ations IRCAM: les ann&eacute;es 80</i>. IRCAM, CD.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1990b"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1990. <i>Cr&eacute;ations IRCAM: les ann&eacute;es 80</i>. IRCAM, CD.</p><div id="citediv_saariaho_1989" class="flyoverdiv">Saariaho, Kaija. 1989. <i>Jardin secret II: for Harpsichord and Tape</i>. Edition Wilhelm Hansen Helsinki.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1989"></a>Saariaho, Kaija. 1989. <i>Jardin secret II: for Harpsichord and Tape</i>. Edition Wilhelm Hansen Helsinki.</p><div id="citediv_saariaho_1997" class="flyoverdiv">Saariaho, Kaija. 1997. <i>IO: pour 16 musiciens, bande r&eacute;alis&eacute;e par ordinateur, et electronic-live (1986&ndash;87)</i>. Hansen. </div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="saariaho_1997"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1997. <i>IO: pour 16 musiciens, bande r&eacute;alis&eacute;e par ordinateur, et electronic-live (1986&ndash;87)</i>. Hansen. </p>
     
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Footnotes List -------------------------------------------->

  	
	<hr>
	
	<h3><a name="Footnotes">Footnotes</a></h3>
	
	           <p><a name="FN0">*</a> I offer special thanks to IRCAM and the Paul Sacher Foundation in Basel, Switzerland for providing the archival materials presented in this article. Research was conducted at IRCAM in June&ndash;July 2017, and at the Sacher Foundation in the summer and fall of 2018. At Sacher, I owe a huge debt of gratitude to Heidy Zimmermann and everyone on the library staff for facilitating multiple visits to the archive and for allowing me to reproduce facsimiles of key documents contained in the collection for Kaija Saariaho. At IRCAM, I would like to thank Nicolas Donin and members of the &ldquo;Analysis of Musical Practices&rdquo; team for warmly welcoming me into their work space, Serge Lemouton for granting access to the online Sidney server for technical documents, and Axel R&oelig;bel for providing a copy of an in-house user manual for the CHANT voice synthesis program.<br><a href="#FN0REF">Return to text</a></p><div id="fndiv0" class="flyoverdiv">I offer special thanks to IRCAM and the Paul Sacher Foundation in Basel, Switzerland for providing the archival materials presented in this article. Research was conducted at IRCAM in June&ndash;July 2017, and at the Sacher Foundation in the summer and fall of 2018. At Sacher, I owe a huge debt of gratitude to Heidy Zimmermann and everyone on the library staff for facilitating multiple visits to the archive and for allowing me to reproduce facsimiles of key documents contained in the collection for Kaija Saariaho. At IRCAM, I would like to thank Nicolas Donin and members of the &ldquo;Analysis of Musical Practices&rdquo; team for warmly welcoming me into their work space, Serge Lemouton for granting access to the online Sidney server for technical documents, and Axel R&oelig;bel for providing a copy of an in-house user manual for the CHANT voice synthesis program.</div><p><a name="FN1">1.</a> Barrière, who has discussed the matter with Saariaho, expressed surprise on learning of a recording of <i>Vers le blanc</i>, which he characterized as “an étude, an experiment about sound synthesis and perception, part of the research she was doing then, notably with me and psycho-acoustician Stephen McAdams” (e.g., <a href="#mcadams_and_saariaho_1985" id="citation_mcadams_and_saariaho_1985_67dc9954d5b65">McAdams and Saariaho 1985</a>). The two were also surprised to discover that the recording plays backwards from the original score. This, according to Barrière, is most likely because “the analog tape was read in the wrong direction by the person who made the transfer, which is a totally imaginable mistake, since it was indeed common usage by then to keep tapes stored backwards (in order to prevent pre-echo caused by magnetic transfer).&nbsp;.&nbsp;. the amazing thing is that it also works that way” (email correspondence with Barrière, March 9–April 21, 2020). <br><a href="#FN1REF">Return to text</a></p><p><a name="FN2">2.</a> The distinction between primary and secondary parameters in classical music is established in <a href="#meyer_1989" id="citation_meyer_1989_67dc9954d5b6a">Meyer 1989</a>, 209.<br><a href="#FN2REF">Return to text</a></p><p><a name="FN3">3.</a> Developed as an outgrowth of IRCAM&rsquo;s participation in the European CASPAR project, the Sidney server was spearheaded by Alain Bonardi, Serge Lemouton, and others as a database intended to provide &ldquo;technical information necessary to play the pieces composed at IRCAM,&rdquo; where one can find &ldquo;required equipment, technical diagrams, set-up instructions, and more&rdquo; (<a href='http://brahms.ircam.fr/sidney/'>http://brahms.ircam.fr/sidney/</a>). For further information, see <a href="#bonardi_and_barth&eacute;lemy_2008" id="citation_bonardi_and_barth&eacute;lemy_2008_67dc9954d5b6d">Bonardi and Barth&eacute;lemy 2008</a> and <a href="#lemouton_et_al_2018" id="citation_lemouton_et_al_2018_67dc9954d5b70">Lemouton et al. 2018</a>.<br><a href="#FN3REF">Return to text</a></p><p><a name="FN4">4.</a> A number of recent studies have attempted to forge new documentary approaches that move both inside and outside the traditional archive, engaging with musical practices that crop up around sound technologies and which are often conveyed on a person-to-person basis (<a href="#feller_2005" id="citation_feller_2005_67dc9954d5b72">Feller 2005</a>; <a href="#donin_2009" id="citation_donin_2009_67dc9954d5b74">Donin 2009</a>; <a href="#boutard_and_guastavino_2012" id="citation_boutard_and_guastavino_2012_67dc9954d5b75">Boutard and Guastavino 2012</a>; <a href="#sallis_et_al_2018" id="citation_sallis_et_al_2018_67dc9954d5b77">Sallis et al. 2018</a>).<br><a href="#FN4REF">Return to text</a></p><p><a name="FN5">5.</a> While at Sacher (Summer/Fall 2018), I encountered an impressive trove of manuscripts, sketches, notes, printed documents, and personal correspondences, but not much in the way of digital media or so-called &ldquo;e-sketches.&rdquo; At IRCAM (Summer 2017), the situation was reversed: researchers there maintain digital documentation for pieces commissioned by the center, but not paper-based artifacts from the creative process, nor older computers and operating systems.<br><a href="#FN5REF">Return to text</a></p><p><a name="FN6">6.</a> In 1977, IRCAM comprised six main departments that were dedicated to computer research, electroacoustic composition, voice and instrument analysis, pedagogy, technical coordination, and diagonal integration. Staff included Pierre Boulez (dir.), Luciano Berio, Max Mathews, Jean-Claude Risset, David Wessel, and others. For more, see <a href="#gardner_1978" id="citation_gardner_1978_67dc9954d5b79">Gardner 1978</a> and <a href="#bennett_1979" id="citation_bennett_1979_67dc9954d5b7a">Bennett 1979</a>, appendix 2.<br><a href="#FN6REF">Return to text</a></p><p><a name="FN7">7.</a> There exists an earlier draft of this form diagram, which Saariaho appears to have polished and revised before arriving at the final version shown in Example 2. The neatness of the diagram would have made it ideal for presenting her work during summer courses at Darmstadt. An inscription on the margins of the diagram that is not pictured here reads: &ldquo;This piece was realized at IRCAM, Paris, during the spring 1982 (programme &lsquo;chant&rsquo;), with a technical help of Jean-Baptiste Barri&egrave;re, whom I thank for the innumerable advices. The original version is on 4 traces.&rdquo; The reference here to &ldquo;4 traces&rdquo; (i.e., audio channels) helps to explain the four separate tracks contained in the archives at IRCAM.<br><a href="#FN7REF">Return to text</a></p><p><a name="FN8">8.</a> The code for <i>Vers le blanc</i> is dated between March 2 and July 9, 1982, according to the time stamps on printed code housed at the Sacher Foundation. I obtained a copy of the <i>CHANT Manual</i> through private email correspondence with IRCAM researchers Nicolas Donin and Axel Roebel, February 12, 2019.<br><a href="#FN8REF">Return to text</a></p><p><a name="FN9">9.</a> The rate at which parametric values were updated during interpolative processes (i.e., the &ldquo;quantum rate&rdquo; in Example 6) was hitched to the repetition of the excitation source which, in early versions of CHANT, equated with a voice&rsquo;s fundamental frequency. As a result, there was a rather unusual linkage between the digital processor&rsquo;s resolution and the voice&rsquo;s perceived pitch, so that as the fundamental frequency of a voice descended, there was a corresponding decrease in the resolution at which the program updated values for all of the individual parameters.<br><a href="#FN9REF">Return to text</a></p><p><a name="FN10">10.</a> While FOF and filter synthesis methods differ in their specific functionality, both embody a foundational metaphor between sound synthesis and the human voice that has roots in theories of sound going back to the nineteenth century. Two important historical precedents worthy of note include the work of Homer Dudley and Hermann von Helmholtz. In the first case, we find speech underpinning an operative framework for filter-based synthesis in Dudley&rsquo;s invention of the Voder at Bell Labs (<a href="#dudley_et_al_1939" id="citation_dudley_et_al_1939_67dc9954d5b7c">Dudley et al. 1939</a>). In this machine, a noisy excitation source assumed the role of the lungs and glottis, while a resonant filter emulated the mouth and nasal cavities. Using ten separate keys that mapped onto different bandwidths within the overall spectrum, a skilled operator could filter out certain frequencies to reproduce spectral envelopes that matched specific patterns of speech. This subtractive method differs from the additive model of speech synthesis outlined in Helmholtz (<a href="#helmholtz_1954_1863" id="citation_helmholtz_1954_1863_67dc9954d5b80">[1863]</a>, <i>Die Lehre von den Tonempfindungen</i>), where steady-state vowels were first analyzed by measuring sympathetic resonance in vibrating spheres. From there, he reverse-engineered the most salient parts of each vowel&rsquo;s spectrum, re-synthesizing &ldquo;artificial vowels&rdquo; by sounding out the appropriate frequencies on a bank of electromagnetically activated tuning-fork oscillators. Notably, he sought to reproduce the auditory effects of sound, rather than replicating its source and cause, as had been attempted, for instance, by Wolfgang von Kempelen in his &ldquo;speaking machine,&rdquo; ca. 1791 (for more on the shift from &ldquo;mouth-based&rdquo; to &ldquo;ear-based&rdquo; theories of sound in the nineteenth century, see <a href="#sterne_2003" id="citation_sterne_2003_67dc9954d5b82">Sterne 2003</a>, 31&ndash;85). This novel method rested on the general assumption that all sounds, regardless of their source, could be decomposed into a universal medium of raw frequencies and then reconstructed given the appropriate tools. In this sense, Helmholtz&rsquo;s tuning-fork oscillators set the stage for experiments with sine-tone generators nearly a century later at the Westdeutscher Rundfunk (WDR) Studio in Cologne, where, as Jennifer Iverson (<a href="#iverson_2019" id="citation_iverson_2019_67dc9954d5b84">2019</a>) has shown, composers such as Karlheinz Stockhausen, Gottfried Michael Koenig, Werner Meyer-Eppler and others used formants and additive speech synthesis as a model for working with timbre. These 1950s-era experiments, in turn, contributed to the subsequent development of voice synthesis software&mdash;CHANT among them&mdash;in which filter-based and FOF-based techniques converged in a single interface. For a more detailed investigation of how this dual lineage of synthesis technologies relates to the functionality of CHANT, see <a href="#morrison_2020" id="citation_morrison_2020_67dc9954d5b86">Morrison 2020</a>.<br><a href="#FN10REF">Return to text</a></p><p><a name="FN11">11.</a> For an analysis of interpolations in <i>Jardin secret I</i>, see <a href="#kankaanp&auml;&auml;_2011" id="citation_kankaanp&auml;&auml;_2011_67dc9954d5b88">Kankaanp&auml;&auml; 2011</a>, which uses spectrograms (rather than archival materials) to show how Saariaho plays on the boundaries between harmony vs. timbre, sound vs. noise, and concrete vs. synthesized sound sources.<br><a href="#FN11REF">Return to text</a></p><p><a name="FN12">12.</a> Elsewhere, Saariaho describes these patterns as &ldquo;matrices,&rdquo; distinguishing <i>simple</i> interpolations between two values and those built around a &ldquo;<i>circular</i> matrix in which each value is modified before being reproduced, which continually modifies the general character of the pattern&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954d5b8a">1987</a>, 124). She also introduces an &ldquo;expansion matrix,&rdquo; in which the spectral envelope is modified by a &ldquo;contraction or expansion of formant frequencies, whilst leaving intact the internal relationship of these frequencies&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954d5b8c">Saariaho 1987</a>, 128).<br><a href="#FN12REF">Return to text</a></p><p><a name="FN13">13.</a> During this period, Saariaho appears to have found musical inspiration in the mathematical proportions of the spiral, as evidenced by her use of a similar spiral template two years later in the <i>Nymph&eacute;a</i> string quartet (1987, sketch housed at the Sacher Foundation and recently published in <a href="#besada_and_canov&aacute;s_2020" id="citation_besada_and_canov&aacute;s_2020_67dc9954d5b8f">Besada and Canov&aacute;s 2020</a>, 149).<br><a href="#FN13REF">Return to text</a></p><p><a name="FN14">14.</a> Here, I borrow an annotative convention that Saariaho employs in her form diagram for <i>Vers le blanc</i> (see bottom of Example 2), as well as in sketches for other pieces from this period.<br><a href="#FN14REF">Return to text</a></p><div id="fndiv1" class="flyoverdiv">Barrière, who has discussed the matter with Saariaho, expressed surprise on learning of a recording of <i>Vers le blanc</i>, which he characterized as “an étude, an experiment about sound synthesis and perception, part of the research she was doing then, notably with me and psycho-acoustician Stephen McAdams” (e.g., <a href="#mcadams_and_saariaho_1985" id="citation_mcadams_and_saariaho_1985_67dc9954d5b65">McAdams and Saariaho 1985</a>). The two were also surprised to discover that the recording plays backwards from the original score. This, according to Barrière, is most likely because “the analog tape was read in the wrong direction by the person who made the transfer, which is a totally imaginable mistake, since it was indeed common usage by then to keep tapes stored backwards (in order to prevent pre-echo caused by magnetic transfer).&nbsp;.&nbsp;. the amazing thing is that it also works that way” (email correspondence with Barrière, March 9–April 21, 2020). </div><div id="fndiv2" class="flyoverdiv">The distinction between primary and secondary parameters in classical music is established in <a href="#meyer_1989" id="citation_meyer_1989_67dc9954d5b6a">Meyer 1989</a>, 209.</div><div id="fndiv3" class="flyoverdiv">Developed as an outgrowth of IRCAM&rsquo;s participation in the European CASPAR project, the Sidney server was spearheaded by Alain Bonardi, Serge Lemouton, and others as a database intended to provide &ldquo;technical information necessary to play the pieces composed at IRCAM,&rdquo; where one can find &ldquo;required equipment, technical diagrams, set-up instructions, and more&rdquo; (<a href='http://brahms.ircam.fr/sidney/'>http://brahms.ircam.fr/sidney/</a>). For further information, see <a href="#bonardi_and_barth&eacute;lemy_2008" id="citation_bonardi_and_barth&eacute;lemy_2008_67dc9954d5b6d">Bonardi and Barth&eacute;lemy 2008</a> and <a href="#lemouton_et_al_2018" id="citation_lemouton_et_al_2018_67dc9954d5b70">Lemouton et al. 2018</a>.</div><div id="fndiv4" class="flyoverdiv">A number of recent studies have attempted to forge new documentary approaches that move both inside and outside the traditional archive, engaging with musical practices that crop up around sound technologies and which are often conveyed on a person-to-person basis (<a href="#feller_2005" id="citation_feller_2005_67dc9954d5b72">Feller 2005</a>; <a href="#donin_2009" id="citation_donin_2009_67dc9954d5b74">Donin 2009</a>; <a href="#boutard_and_guastavino_2012" id="citation_boutard_and_guastavino_2012_67dc9954d5b75">Boutard and Guastavino 2012</a>; <a href="#sallis_et_al_2018" id="citation_sallis_et_al_2018_67dc9954d5b77">Sallis et al. 2018</a>).</div><div id="fndiv5" class="flyoverdiv">While at Sacher (Summer/Fall 2018), I encountered an impressive trove of manuscripts, sketches, notes, printed documents, and personal correspondences, but not much in the way of digital media or so-called &ldquo;e-sketches.&rdquo; At IRCAM (Summer 2017), the situation was reversed: researchers there maintain digital documentation for pieces commissioned by the center, but not paper-based artifacts from the creative process, nor older computers and operating systems.</div><div id="fndiv6" class="flyoverdiv">In 1977, IRCAM comprised six main departments that were dedicated to computer research, electroacoustic composition, voice and instrument analysis, pedagogy, technical coordination, and diagonal integration. Staff included Pierre Boulez (dir.), Luciano Berio, Max Mathews, Jean-Claude Risset, David Wessel, and others. For more, see <a href="#gardner_1978" id="citation_gardner_1978_67dc9954d5b79">Gardner 1978</a> and <a href="#bennett_1979" id="citation_bennett_1979_67dc9954d5b7a">Bennett 1979</a>, appendix 2.</div><div id="fndiv7" class="flyoverdiv">There exists an earlier draft of this form diagram, which Saariaho appears to have polished and revised before arriving at the final version shown in Example 2. The neatness of the diagram would have made it ideal for presenting her work during summer courses at Darmstadt. An inscription on the margins of the diagram that is not pictured here reads: &ldquo;This piece was realized at IRCAM, Paris, during the spring 1982 (programme &lsquo;chant&rsquo;), with a technical help of Jean-Baptiste Barri&egrave;re, whom I thank for the innumerable advices. The original version is on 4 traces.&rdquo; The reference here to &ldquo;4 traces&rdquo; (i.e., audio channels) helps to explain the four separate tracks contained in the archives at IRCAM.</div><div id="fndiv8" class="flyoverdiv">The code for <i>Vers le blanc</i> is dated between March 2 and July 9, 1982, according to the time stamps on printed code housed at the Sacher Foundation. I obtained a copy of the <i>CHANT Manual</i> through private email correspondence with IRCAM researchers Nicolas Donin and Axel Roebel, February 12, 2019.</div><div id="fndiv9" class="flyoverdiv">The rate at which parametric values were updated during interpolative processes (i.e., the &ldquo;quantum rate&rdquo; in Example 6) was hitched to the repetition of the excitation source which, in early versions of CHANT, equated with a voice&rsquo;s fundamental frequency. As a result, there was a rather unusual linkage between the digital processor&rsquo;s resolution and the voice&rsquo;s perceived pitch, so that as the fundamental frequency of a voice descended, there was a corresponding decrease in the resolution at which the program updated values for all of the individual parameters.</div><div id="fndiv10" class="flyoverdiv">While FOF and filter synthesis methods differ in their specific functionality, both embody a foundational metaphor between sound synthesis and the human voice that has roots in theories of sound going back to the nineteenth century. Two important historical precedents worthy of note include the work of Homer Dudley and Hermann von Helmholtz. In the first case, we find speech underpinning an operative framework for filter-based synthesis in Dudley&rsquo;s invention of the Voder at Bell Labs (<a href="#dudley_et_al_1939" id="citation_dudley_et_al_1939_67dc9954d5b7c">Dudley et al. 1939</a>). In this machine, a noisy excitation source assumed the role of the lungs and glottis, while a resonant filter emulated the mouth and nasal cavities. Using ten separate keys that mapped onto different bandwidths within the overall spectrum, a skilled operator could filter out certain frequencies to reproduce spectral envelopes that matched specific patterns of speech. This subtractive method differs from the additive model of speech synthesis outlined in Helmholtz (<a href="#helmholtz_1954_1863" id="citation_helmholtz_1954_1863_67dc9954d5b80">[1863]</a>, <i>Die Lehre von den Tonempfindungen</i>), where steady-state vowels were first analyzed by measuring sympathetic resonance in vibrating spheres. From there, he reverse-engineered the most salient parts of each vowel&rsquo;s spectrum, re-synthesizing &ldquo;artificial vowels&rdquo; by sounding out the appropriate frequencies on a bank of electromagnetically activated tuning-fork oscillators. Notably, he sought to reproduce the auditory effects of sound, rather than replicating its source and cause, as had been attempted, for instance, by Wolfgang von Kempelen in his &ldquo;speaking machine,&rdquo; ca. 1791 (for more on the shift from &ldquo;mouth-based&rdquo; to &ldquo;ear-based&rdquo; theories of sound in the nineteenth century, see <a href="#sterne_2003" id="citation_sterne_2003_67dc9954d5b82">Sterne 2003</a>, 31&ndash;85). This novel method rested on the general assumption that all sounds, regardless of their source, could be decomposed into a universal medium of raw frequencies and then reconstructed given the appropriate tools. In this sense, Helmholtz&rsquo;s tuning-fork oscillators set the stage for experiments with sine-tone generators nearly a century later at the Westdeutscher Rundfunk (WDR) Studio in Cologne, where, as Jennifer Iverson (<a href="#iverson_2019" id="citation_iverson_2019_67dc9954d5b84">2019</a>) has shown, composers such as Karlheinz Stockhausen, Gottfried Michael Koenig, Werner Meyer-Eppler and others used formants and additive speech synthesis as a model for working with timbre. These 1950s-era experiments, in turn, contributed to the subsequent development of voice synthesis software&mdash;CHANT among them&mdash;in which filter-based and FOF-based techniques converged in a single interface. For a more detailed investigation of how this dual lineage of synthesis technologies relates to the functionality of CHANT, see <a href="#morrison_2020" id="citation_morrison_2020_67dc9954d5b86">Morrison 2020</a>.</div><div id="fndiv11" class="flyoverdiv">For an analysis of interpolations in <i>Jardin secret I</i>, see <a href="#kankaanp&auml;&auml;_2011" id="citation_kankaanp&auml;&auml;_2011_67dc9954d5b88">Kankaanp&auml;&auml; 2011</a>, which uses spectrograms (rather than archival materials) to show how Saariaho plays on the boundaries between harmony vs. timbre, sound vs. noise, and concrete vs. synthesized sound sources.</div><div id="fndiv12" class="flyoverdiv">Elsewhere, Saariaho describes these patterns as &ldquo;matrices,&rdquo; distinguishing <i>simple</i> interpolations between two values and those built around a &ldquo;<i>circular</i> matrix in which each value is modified before being reproduced, which continually modifies the general character of the pattern&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954d5b8a">1987</a>, 124). She also introduces an &ldquo;expansion matrix,&rdquo; in which the spectral envelope is modified by a &ldquo;contraction or expansion of formant frequencies, whilst leaving intact the internal relationship of these frequencies&rdquo; (<a href="#saariaho_1987" id="citation_saariaho_1987_67dc9954d5b8c">Saariaho 1987</a>, 128).</div><div id="fndiv13" class="flyoverdiv">During this period, Saariaho appears to have found musical inspiration in the mathematical proportions of the spiral, as evidenced by her use of a similar spiral template two years later in the <i>Nymph&eacute;a</i> string quartet (1987, sketch housed at the Sacher Foundation and recently published in <a href="#besada_and_canov&aacute;s_2020" id="citation_besada_and_canov&aacute;s_2020_67dc9954d5b8f">Besada and Canov&aacute;s 2020</a>, 149).</div><div id="fndiv14" class="flyoverdiv">Here, I borrow an annotative convention that Saariaho employs in her form diagram for <i>Vers le blanc</i> (see bottom of Example 2), as well as in sketches for other pieces from this period.</div>
     
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- FOOTER -------------------------------------------->

  <hr>
<h3>Copyright Statement</h3>
<p><h4>Copyright &copy; 2021 by the Society for Music Theory. All rights reserved.</h4></p>
<p class="small">[1] Copyrights for individual items published in  <i>Music Theory Online</i> (<i>MTO</i>) 
are held by their authors. Items appearing in  <i>MTO</i> may be saved and stored in electronic or paper form, and may be shared among individuals for purposes of 
scholarly research or discussion, but may  <i>not</i>  be republished in any form, electronic or print, without prior, written permission from the author(s), and advance 
notification of the editors of  <i>MTO.</i></p>
<p class="small">[2] Any redistributed form of items published in  <i>MTO</i> must include the following information in a form appropriate to the medium in which the items are 
to appear: </p>
<blockquote>
<p class="small">This item appeared in  <i>Music Theory Online</i> in [VOLUME #, ISSUE #] on [DAY/MONTH/YEAR]. It was authored by [FULL NAME, EMAIL ADDRESS], with whose written 
permission it is reprinted here.</p>
</blockquote>
<p class="small">[3] Libraries may archive issues of  <i>MTO</i> in electronic or paper form for public access so long as each issue is stored in its entirety, and no access fee 
is charged. Exceptions to these requirements must be approved in writing by the editors of  <i>MTO,</i> who will act in accordance with the decisions of the Society 
for Music Theory. </p>
<p class="small">This document and all portions thereof are protected by U.S. and international copyright laws. Material contained herein may be copied and/or distributed for research 
purposes only. </p>
     
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
  	

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 


<div style="width:55%;float:right"><a href="https://societymusictheory.org">
<img alt="SMT" longdesc="Society for Music Theory" src="https://mtosmt.org/gifs/smtlogo_black.png" width="180"></a></div>
	
<div>
<p style='font-size:1.1rem'>Prepared by Andrew Eason, Editorial Assistant  


<br>
		
			<br>Number of visits:  

		6651		
	</p><br><br>
</i>		

</div>
</div>
</article>
</body>
</html>

