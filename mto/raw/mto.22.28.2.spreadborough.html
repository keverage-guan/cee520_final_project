 
 

<!-------------------------------- HEADER -------------------------------------------->

	  
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> 
<head>

<title> MTO 28.2: Spreadborough, Emotional Tones and Emotional Texts</title>

<link rel="SHORTCUT ICON" href="https://www.mtosmt.org/gifs/favicon.ico">
<link rel="stylesheet" href="https://www.mtosmt.org/scripts/colorbox.css">
<link rel=StyleSheet href="https://www.mtosmt.org/scripts/mto-tufte.css" type="text/css" media=all>
<link rel="stylesheet" href="//code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

<script src="https://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">_uacct = "UA-968147-1"; urchinTracker();</script>

<script type="text/javascript" src="https://www.mtosmt.org/scripts/expandingMenu.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/dropdownMenu.js"></script>
<!--<script language="JavaScript" type="text/javascript" src="https://www.mtosmt.org/scripts/AC_QuickTime.js"></script>-->
<!--<script type="text/javascript" src="https://www.mtosmt.org/scripts/examples.js"></script>-->
<script type="text/javascript" src="https://www.mtosmt.org/scripts/hover.js"></script>  
<script src="https://code.jquery.com/jquery-1.10.2.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
<script src="https://www.mtosmt.org/scripts/colorbox-master/jquery.colorbox.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/jQueryRotate.2.2.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script>
MathJax.Hub.Config({
    TeX: { noErrors: { disabled: true } }
});
</script>

  <script>
   $(function () {
      $(document).tooltip({
        position: { my: "center bottom-10", at: "center top", },
    content: function () {
              return $(this).prop('title');
          }
      });
  });
  </script>

  <style>
    .ui-tooltip {
      color: #3a3a3a;
      font: 300 14px/20px "Lato", "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
      max-width: 600px;
      box-shadow: 0 0 7px gray;
    }
    ol.mto-alpha {
        list-style: lower-alpha none outside;
    }
   ol.mto-alpha li {
       margin-bottom: 0.75em;
       margin-left: 2em;
       padding-left: 0.5em;
    }
  </style>

    <script language="Javascript">
        $(document).ready(function() {
            $(".mp3").colorbox({iframe:true, internalWidth:360, width:400, internalHeight:100, rel:'mp3', height:150, opacity:0.1, onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });
            $(".youtube").colorbox({iframe:true, innerWidth:640, innerHeight:390, opacity:0.1, rel:'youtube', onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });

      $("a[id^=footnote]").each(function(){
        var fnnum = $(this).attr('id').substring(8);
	var foot_me = '#fndiv'+fnnum;
        $("#footnote" + fnnum).attr('title', $(foot_me).html());

        });


        $("a[id^=citation]").each(function(){
         var separatorPos = $(this).attr('id').lastIndexOf('_');
         var linkid = $(this).attr('id');
         var citeref = $(this).attr('id').substring(8,separatorPos);
         var cite_me = '#citediv'+citeref;
         $("#" + linkid).attr('title', $(cite_me).html());

        });
    });

    </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-968147-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-968147-1');
</script>


<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 

<meta name="citation_title" content="Emotional Tones and Emotional Texts: A New Approach to Analyzing the Voice in Popular Vocal Song">

    <meta name="citation_author" content="Spreadborough, Kristal">
      
<meta name="citation_publication_date" content="2022/06/01">
<meta name="citation_journal_title" content="Music Theory Online">
<meta name="citation_volume" content="28">
<meta name="citation_issue" content="2">

</head>

<body>
<div class="bannertop">
	<a id="smt-link" alt="Society for Music Theory" href="https://www.societymusictheory.org">&nbsp;</a>
</div>
		
		<div style = "height:160px; width:900px; background-image: url('../../gifs/banner_blue_grey_900px.png'); background-repeat: no-repeat; background-position: 0px 0px"></div>
		
<!-------------------------------- MENU -------------------------------------------->

	
<div class="dropdown_menu">

<ul class="fullwidth" id="ddm">
    <li><a href="https://www.mtosmt.org/index.php">MTO Home</a>
    </li>
    <li><a href="https://www.mtosmt.org/issues/mto.24.30.4/toc.30.4.html">Current Issue</a>    </li>
    <li><a href="https://www.mtosmt.org/issues/issues.php"
    	onmouseover="mopen('m3')" 
        onmouseout="mclosetime()">Previous Issues</a>
        <div id="m3" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/index-author.php">By Author</a>
	        <a href="https://www.mtosmt.org/issues/issues.php">By Volume&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
	</li>
	
    <li><a href="https://www.mtosmt.org/docs/authors.html.php"
    	onmouseover="mopen('m4')" 
        onmouseout="mclosetime()">For Authors</a>
        <div id="m4" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/mto-editorial-policy.html">MTO Editorial Policy</a>
	      <a href="https://www.mtosmt.org/docs/mto-style-guidelines.html">MTO Style Guidelines</a>
	      <a href="https://www.mtosmt.org/docs/how-to-submit-an-article-to-mto.html">How to Submit an Article</a>
	      <a href="https://www.mtosmt.org/ojs">Submit Article Online</a>
	      <a href="https://www.mtosmt.org/docs/reviewers.html">Book Review Guidelines</a>
        </div>
	</li>

 <!--   <li><a href="https://www.mtosmt.org/docs/authors.html">Submit</a>
	</li> -->
	
    <li><a href="https://www.mtosmt.org/mto-jobs.php"
    	onmouseover="mopen('m6')" 
        onmouseout="mclosetime()">Jobs</a>
        <div id="m6" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/mto-jobs.php">Current Job Listings</a>
	        <a href="https://www.mtosmt.org/mto-job-post.php">Submit Job Listing</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/docs/diss-index.php"
    	onmouseover="mopen('m7')" 
        onmouseout="mclosetime()">Dissertations</a>
        <div id="m7" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/diss-index.php">All Dissertations</a>
	        <a href="https://www.mtosmt.org/docs/diss-index.php?new=true">New Dissertations</a>
	        <a href="https://www.mtosmt.org/mto-diss-post.php">List Your Dissertation</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/about.html">About</a>
	</li>
<!--    <li><a href="https://www.mtosmt.org/mto_links.html">Journals</a>  
	</li> -->
    <li><a href="https://societymusictheory.org">SMT</a>
	</li>
   <!-- <li><a href="https://societymusictheory.org/announcement/contest-new-mto-logo-2024-02"><span style="color:yellow">Logo Design Contest</span></a>
	</li>-->

</ul>

</div>


<!-------------------------------- TITLE -------------------------------------------->

	<article>

<div id="content">
<a name="Beginning"></a>
			
	<h1 style="width:900px; margin-top:1em">Emotional Tones and Emotional Texts: A New Approach to Analyzing the Voice in Popular Vocal Song</h1>
	<div style="width:900px">
				</div>

	
				<h2><span style="font-weight: 400"><font size="5"><a style="color:black" href="#AUTHORNOTE1">Kristal Spreadborough</a></font></span></h2><br><br><p><font size='4'>KEYWORDS: Voice quality, tone quality, emotion, song, popular music, music psychology, social semiotics, analysis</font></p><p><font size='4'>ABSTRACT: Vocal tone quality is a highly emotive musical resource in popular vocal songs. However, it is also one of the most difficult aspects to analyze due to the complexity and variety of the voice. This article presents a novel analytical approach to the sung voice by considering how emotion is conveyed through tone quality and text. The aim of the approach is to provide a system for annotating vocal tone quality and for analyzing its emotive content. The approach is informed by findings from psychology, music studies, and the social semiotics of sound&mdash;taking into consideration how our everyday experience of voice in communication contributes to our emotional perception of singing. Different modes of annotation, from static annotation to real-time annotation, are demonstrated and two new analytical parameters are introduced: the Affect Map and Cohesiveness. This paper first presents the theoretical underpinnings of the approach, followed by an outline of the approach itself, and finally demonstrates the approach through an analysis of the voice in Kris Kristofferson&rsquo;s 1970 song &ldquo;Casey&rsquo;s Last Ride.&rdquo;</font></p><p><small>DOI: 10.30535/mto.28.2.7</small></p>			
	<div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'><a href="https://mtosmt.org/issues/mto.22.28.2/mto.22.28.2.spreadborough.pdf">PDF text </a> | <a href="https://mtosmt.org/issues/mto.22.28.2/spreadborough_examples.pdf">PDF examples </a></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div>
			<div style="float:left; font-size:1.1rem;"><i>Received July 2021</i></div>
		<div style="width:850px">
	<div style="text-align:center; font-size: 1.1rem; margin-bottom:2em;margin-top:4em;margin-right:auto;margin-left:auto;width:870px">
		Volume 28, Number 2, June 2022 <br> Copyright &#0169; 2022 Society for Music Theory	</div>
	</div>

<hr style="width:850px"><br>
<section>
<!-------------------------------- ARTICLE BODY (begin) -------------------------------------->

<h2>Introduction</h2>
<p>[1] Humans have a rich palette of vocal cues to express meaning, from literal linguistic meanings to more abstract emotional expression (see, for example, <a href="#poyatos_1993" id="citation_poyatos_1993_67dc993d30940">Poyatos 1993</a>). Research has shown that similar cues can also play a role in musical communication (<a href="#juslin_and_laukka_2003" id="citation_juslin_and_laukka_2003_67dc993d30949">Juslin and Laukka 2003</a>). The sung voice is one area in which the connection between spoken and musical communication is most apparent. An artist&rsquo;s spoken voice often plays a central role in their vocal aesthetic in popular vocal songs (<a href="#lacasse_2010" id="citation_lacasse_2010_67dc993d3094e">Lacasse 2010</a>, 142). Because of this speaking-singing connection, the lived experience of speaking may heighten one&rsquo;s sensitivity to vocal expression in popular songs. As Simon Frith observes,</p>

<blockquote><p>The voice is a direct expression of the body,&nbsp;.&nbsp;.&nbsp;. it is as important for the way we listen as for the way we interpret what we hear: we can sing along, reconstruct in fancy our own versions of songs, in ways we can&rsquo;t even fantasize instrumental technique&mdash;however hard we may try with our air guitars&mdash;because with singing, we feel we know what to do. We have bodies too, throats and stomachs and lungs. And even if we can&rsquo;t get the breathing right, the pitch, the note durations&nbsp;.&nbsp;.&nbsp;. we still feel we understand what the singer is doing in physical principle (this is another reason why the voice seems so directly expressive an instrument: it doesn&rsquo;t take thought to know how that vocal noise was made). (<a href="#frith_1998" id="citation_frith_1998_67dc993d30951">Frith 1998</a>, 192)</p></blockquote>

<p>[2] Given its near ubiquity in much of popular music, and its potential for emotional expression, the analysis of voice in popular vocal songs is a fruitful avenue of research. However, there are few techniques which allow such an analysis (<a href="#spreadborough_2018" id="citation_spreadborough_2018_67dc993d30955">Spreadborough 2018</a>, chap.&nbsp;4). One reason for this is the complexity of vocal sounds that occur in popular vocal songs. On a physiological level, this complexity is due to no two human bodies being exactly alike. Basic differences in the size and shape of biological structures impact one&rsquo;s overall vocal quality (<a href="#titze_1989" id="citation_titze_1989_67dc993d30958">Titze 1989</a>). Lavan et al. explain, for example, that &ldquo;thickness of the vocal folds, differences in the shape of a person&rsquo;s palate, and the dynamic use of the vocal tract, give rise to differences in pronunciation, accent and other&rdquo; idiosyncratic features of one&rsquo;s vocal quality (<a href="#lavan_et_al_2019" id="citation_lavan_et_al_2019_67dc993d3095f">2019</a>, 90). Furthermore, a single human vocal tract can be manipulated to produce a multitude of different vocal qualities (<a href="#lavan_et_al_2019" id="citation_lavan_et_al_2019_67dc993d30963">Lavan et al. 2019</a>). Consider, for example, the differences in commonly heard vocalizations such as laughing, whispering, shouting, and speaking. Thus, the sung voice presents a unique challenge for music analysis: How, within this rich spectrum of acoustic cues that differ both within and between performers and performances, is one to achieve a coherent and systematic analysis of the sung voice?</p>

<p>[3] This paper takes a social semiotic approach to the analysis of tone quality in song. Social semiotics considers &ldquo;what you can &lsquo;say&rsquo; with sound, and how you can interpret the things that other people &lsquo;say with <i>sound</i>&rsquo;&rdquo; (<a href="#van_leeuwen_1999" id="citation_van_leeuwen_1999_67dc993d30967">van Leeuwen 1999</a>, 4). The social semiotic approach places our perception and lived experience of sound at the center of our understanding of sound. Others have sought to describe and analyze the sound characteristics of popular and recorded music; however, none have yet drawn on social semiotics to develop a systematic framework for the analysis of voice quality specifically. Work in electroacoustic and recorded music has faced similar challenges in describing and analyzing acousmatic sounds that are not traditionally notated (e.g., <a href="#smalley_1986" id="citation_smalley_1986_67dc993d3098d">Smalley 1986</a> and <a href="#smalley_1997" id="citation_smalley_1997_67dc993d30991">1997</a>; <a href="#moylan_2015" id="citation_moylan_2015_67dc993d30994">Moylan 2015</a>). Some of these works have drawn on a similar set of terminology as will be used in this paper (e.g., Moylan&rsquo;s Physical Dimensions, Perceived Parameters, and Artistic/Aesthetic Elements, see <a href="#moylan_2015" id="citation_moylan_2015_67dc993d30997">Moylan 2015</a>, chap.&nbsp;2). Other approaches have sought to define and examine specific characteristics of sound (e.g., <a href="#lomax_1968" id="citation_lomax_1968_67dc993d3099a">Lomax 1968</a>), or have provided mechanisms to describe in detail the various sounds employed in vocal production (e.g., <a href="#wishart_1996" id="citation_wishart_1996_67dc993d3099e">Wishart 1996</a>, chap.&nbsp;12). However, there is as yet no social semiotic framework for annotating and analyzing the sung voice.</p>

<p>[4] The goal of this current paper is to develop such a framework. In addition, this approach also allows the emotive content of tone quality to be compared with that of text (i.e., lyrical content), and to assess the implications of this relationship for a listener&rsquo;s overall emotional perception of the voice.</p>

<h3>The Analytical Approach</h3>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 1</b>. A high-level conceptualization of the analytical approach</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=0&nonav=true"><img border="1" alt="Example 1 thumbnail" src="spreadborough_ex01_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[5] <b>Example 1</b> shows a conceptualization of the analytical approach. The text in grey indicates the tools available for use at each level of the annotation and/or analysis. This conceptualization is based on the premise that singers perform (<i>sound quality</i>) music (<i>musical elements</i>) with lyrics (<i>text</i>). Since all musical sounds must be produced by an instrument, and each instrument has its own unique sound quality, <i>sound quality</i> is at the heart of the conceptualization. In the case of popular vocal songs, this is even more apparent as idiosyncratic vocal sound qualities are often central to an artist&rsquo;s performance style (<a href="#heidemann_2016" id="citation_heidemann_2016_67dc993d30aa0">Heidemann 2016</a>, 2). At the next level are <i>musical elements</i>, which are those features that are more commonly associated with traditional musical analysis (e.g., pitch, dynamic). Sound quality and musical elements together constitute tone quality. </p>

<p>[6] The broken boundary enclosing &ldquo;sound quality&rdquo; and musical elements demonstrates that while these are definable attributes of a tone quality, they are not discrete, wholly separate layers. Rather, they are dialectically related (<a href="#fairclough_2001" id="citation_fairclough_2001_67dc993d30aa4">Fairclough 2001</a>, 234). That is, sound qualities may play a role in musical elements, and vice versa. It is worth mentioning here that it is due to this dialectic relationship between sound quality and musical elements that tone quality more broadly is taken as the focus of the analytical technique presented in this paper. </p>

<p>[7] Text (i.e., lyrical content) is at the outermost layer in the conceptualization. Text includes both words and non-words that accompany the vocal performance. Emotionality of text is assessed against the <b>Affect Map</b> (discussed below). The tone/text relationship is the part of the conceptualization where the emotionality of tones and texts are compared and contrasted. This is achieved through the use of the tool <b>Cohesiveness</b> (discussed below).</p>

<h3>Lived Experience, Emotion Perception, and Popular Vocal Song Analysis</h3>
<p>[8] Before undertaking a discussion of the emotional models that underpin the approach presented in this article, it is useful to explore in more detail how our lived experience of speaking informs our emotional perception of the sung voice, and to consider other analytical approaches which have drawn on this connection in analyzing popular vocal songs.</p>

<p>[9] In spoken word contexts, paralinguistic features, the &ldquo;non-phonemic alterations of the pitch, stress, or tempo of ordinary speech, as in growling, shouting, or drawling&rdquo; (<a href="#wescott_1992" id="citation_wescott_1992_67dc993d30aa7">Wescott 1992</a>, 30), are important for optimal verbal communication (<a href="#wilson_2011" id="citation_wilson_2011_67dc993d30aa9">Wilson 2011</a>). Fernando Poyatos observed that &ldquo;words lack the capacity to carry the whole weight of a conversation, as our verbal lexicons are extremely poor in comparison with the capacity of our minds for encoding and decoding an infinitely wider gamut of meanings to which at times we must refer as ineffable&rdquo; (<a href="#poyatos_1992" id="citation_poyatos_1992_67dc993d30aab">Poyatos 1992</a>). Paralinguistic features of speech have the power to emphasize a message, &ldquo;deemphasize it or contradict it altogether&rdquo; (<a href="#poyatos_1992" id="citation_poyatos_1992_67dc993d30aae">Poyatos 1992</a>, 51).</p>

<p>[10] Similar features have been found to play a key role in musical expression. For example, it has been found that the &ldquo;breaking voice&rdquo; plays an essential role in conveying grief in Country songs (<a href="#paul_and_huron_2010" id="citation_paul_and_huron_2010_67dc993d30ab0">Paul and Huron 2010</a>). Similarities of tone quality in music and paralinguistic cues in speech have also been found in the expression of sarcasm, which appears to be reliably marked by nasality in both spoken and musical contexts (<a href="#plazak_2011" id="citation_plazak_2011_67dc993d30ab2">Plazak 2011</a>, as cited in <a href="#huron_2015" id="citation_huron_2015_67dc993d30ab4">Huron 2015</a>, 190). Parallels have also been found between the paralinguistic and tone quality expression of sadness where sadness tends to be conveyed through darker timbres in both spoken and musical contexts (<a href="#huron_2015" id="citation_huron_2015_67dc993d30ab6">Huron 2015</a>, 193). Such research suggests that drawing on one&rsquo;s experience of spoken voice is a fruitful avenue for analyzing emotive content of the sung voice.</p>

<p>[11] Indeed, previous musical analyses have drawn on this speaking-singing connection. For example, Richard Middleton outlines how rock singing can be viewed as a spectrum. At one extreme words govern the song, and the voice tends towards speech as it delivers the narrative (<a href="#middleton_2000" id="citation_middleton_2000_67dc993d30ab9">Middleton 2000</a>, 29). At the other extreme, words &ldquo;are absorbed into the musical flow, working as sound or gesture,&rdquo; and the voice becomes an instrument (<a href="#middleton_2000" id="citation_middleton_2000_67dc993d30abb">Middleton 2000</a>, 30). Singing, viewed as a stylized form of speech, may sit anywhere along this spectrum. Serge Lacasse explores this connection in his 2010 analysis of Sia&rsquo;s &ldquo;Breathe Me.&rdquo; Here, Lacasse approaches the sung voice as &ldquo;a stylized means of conveying emotion using, among other things, paralinguistic features borrowed from everyday speech&rdquo; (<a href="#lacasse_2010" id="citation_lacasse_2010_67dc993d30abd">Lacasse 2010</a>, 142). Lacasse outlines several levels on which links between the spoken and sung voice can be examined and explores how such emotional utterance in voice may play a key role in conveying emotion in song (143). </p>

<p>[12] This article will first define my two new parameters for analysis: the Affect Map and Cohesiveness. Next, my system for annotating and analyzing Tone Quality Features will be presented. Following this, an overview of the approach to textual analysis will be given. Finally, the analytical approach is applied to Kris Kristofferson&rsquo;s 1970 song &ldquo;Casey&rsquo;s Last Ride&rdquo; as a case study to demonstrate the potential for application.</p>

<h2>Defining the Parameters of Analysis</h2>
<p>[13] This section outlines the two tools used to discuss emotion within and between tone quality and text: the Affect Map and Cohesiveness (see Example 1). The Affect Map is discussed first because it includes a discussion of the emotional models which underpin this paper. These tools are inspired by diagrammatic vocabulary sets, an approach developed as part of Denis Smalley&rsquo;s analytical techniques for electroacoustic music (e.g., <a href="#smalley_1986" id="citation_smalley_1986_67dc993d30ad1">Smalley 1986</a> and <a href="#smalley_1997" id="citation_smalley_1997_67dc993d30ad3">1997</a>).</p>

<h3>The Affect Map</h3>
<p>[14] Before emotion per se is examined, it is important to consider the <i>locus</i> of emotion. In doing so, I draw on the locus of emotion as described by Evans and Schubert (<a href="#evans_and_schubert_2008" id="citation_evans_and_schubert_2008_67dc993d30ad6">2008</a>). This model is used since it provides an account of the relationship between loci of emotion that is grounded within music psychology&mdash;one of the disciplines that informs the approach proposed herein. According to Evans and Schubert, the locus of emotion refers to how listeners experience emotion in music&mdash;either by recognizing emotion expressed by the music, known as &ldquo;perceived&rdquo; or &ldquo;external&rdquo; locus of emotion; or through feeling a subjective response to the music, known as &ldquo;felt&rdquo; or &ldquo;internal&rdquo; locus of emotion. External and internal loci of emotion interact in a number of ways, but the mechanisms behind this interaction and the attribution of emotion to the external or internal loci require further investigation (<a href="#evans_and_schubert_2008" id="citation_evans_and_schubert_2008_67dc993d30ad9">Evans and Schubert 2008</a>). In this paper, I will focus on the external locus of emotion, discussing within the analysis emotions which may be <i>perceived</i> by the listener.</p>

<p>[15] Two main models tend to be used to understand emotion in music: the discrete model and the dimensional model (<a href="#eerola_and_vuoskoski_2013" id="citation_eerola_and_vuoskoski_2013_67dc993d30adb">Eerola and Vuoskoski 2013</a>, 317). The discrete model tends to focus on basic emotions, a small set of &ldquo;evolutionary emotions that have important functions when adapting the individual to events that have material consequences for the individual&rsquo;s well-being&rdquo; (<a href="#eerola_and_vuoskoski_2013" id="citation_eerola_and_vuoskoski_2013_67dc993d30add">Eerola and Vuoskoski 2013</a>, 310). Russell&rsquo;s oft-cited dimensional model (<a href="#russell_1980" id="citation_russell_1980_67dc993d30ae0">1980</a>) considers how emotion can be understood through two systems, valence (pleasure-displeasure) and arousal (activation-deactivation) (<a href="#eerola_and_vuoskoski_2011" id="citation_eerola_and_vuoskoski_2011_67dc993d30ae2">Eerola and Vuoskoski 2011</a>). Another dimensional mode proposed by Tellegen, Watson, and Clark (<a href="#tellegen_watson_and_clark_1999" id="citation_tellegen_watson_and_clark_1999_67dc993d30ae5">1999</a>) considers emotion in terms of arousal&mdash;calmness and tension&mdash;relaxation, and uses these systems to infer valence (<a href="#eerola_and_vuoskoski_2011" id="citation_eerola_and_vuoskoski_2011_67dc993d30ae7">Eerola and Vuoskoski 2011</a>). </p>

<p>[16] The dimensional models discussed above examine emotion from two dimensions only. However, some have argued that emotion is better understood through three dimensions. In their <a href="#schimmack_and_grob_2000" id="citation_schimmack_and_grob_2000_67dc993d30aeb">2000</a> paper, Schimmack and Grob proposed a model with three dimensions: tension arousal (tense-relaxed), energy arousal (awake-tired) and valence (pleasant-unpleasant). The similarities and differences of the discrete model and Schimmack and Grob&rsquo;s (<a href="#schimmack_and_grob_2000" id="citation_schimmack_and_grob_2000_67dc993d30aed">2000</a>) three-dimensional model was explored by Eerola and Vuoskoski (<a href="#eerola_and_vuoskoski_2011" id="citation_eerola_and_vuoskoski_2011_67dc993d30af0">2011</a>). Eerola and Vuoskoski found that participants were able to rate emotional musical stimuli consistently and accurately on both the discrete and dimensional models, suggesting that individuals can understand emotions well both in terms of basic emotions (happy, sad, etc.) and descriptors on a spectrum (very pleasant, moderately pleasant, etc.). However, they also found that participants were able to rate ambiguous emotions when using the dimensional model more accurately. The authors suggest that a hybrid model may be useful for music emotions research. Such a model:</p>

<blockquote><p><nobr>. . .</nobr> uses the components of a dimensional model (valence and arousal) to explain the underlying affect space, which is mainly physiologically driven. When the changes in these core affects are interpreted consciously, however, discrete emotion terminology is used to label the emotional experiences. In this way common discrete emotions can be regarded as attractors or hot spots in the affect space. (<a href="#eerola_and_vuoskoski_2011" id="citation_eerola_and_vuoskoski_2011_67dc993d30af2">Eerola and Vuoskoski 2011</a>, 41)</p></blockquote>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 2</b>. The Affect Map</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=1&nonav=true"><img border="1" alt="Example 2 thumbnail" src="spreadborough_ex02_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[17] Unlike emotions, which tend to be short-lived affective states with words that tend to &ldquo;imply an object (e.g., I love somebody, I am afraid of dogs)&rdquo; (<a href="#schimmack_and_grob_2000" id="citation_schimmack_and_grob_2000_67dc993d30b72">Schimmack and Grob 2000</a>, 328), moods are longer lived and mood words &ldquo;are not directed at objects (e.g., I am relaxed, I am tired)&rdquo; (<a href="#schimmack_and_grob_2000" id="citation_schimmack_and_grob_2000_67dc993d30b74">Schimmack and Grob 2000</a>, 328). Hunter and Schellenberg (<a href="#hunter_and_schellenberg_2010" id="citation_hunter_and_schellenberg_2010_67dc993d30b76">2010</a>) also note that mood in music is a more diffuse experience that is typically not directed at a target (as is the case for emotion). In this article, I propose the use of an &ldquo;Affect Map&rdquo; to account for both diffuse moods (e.g., when commenting on the mood of an entire musical section) and targeted emotions (e.g., when commenting on the emotion conveyed through specific Tone Quality Features in song) (<b>Example 2</b>).</p>

<p>[18] I use the term &ldquo;affect&rdquo; since it typically refers to an overall reaction that encompasses both moods and emotions. In music specifically, affect is used as a term for describing individuals&rsquo; responses to sound, although there is debate about how mood and emotion contribute to musical affect (<a href="#hunter_and_schellenberg_2010" id="citation_hunter_and_schellenberg_2010_67dc993d30b78">Hunter and Schellenberg 2010</a>, sec. 5.8). Since I wish to refer to both moods and emotions in my analysis, I adopt the term affect to describe the relationship between the two. No predefined taxonomy of emotions or moods is used in the Affect Map for two reasons. First, as summarized by Hunter and Schellenberg (<a href="#hunter_and_schellenberg_2010" id="citation_hunter_and_schellenberg_2010_67dc993d30b89">2010</a>), there is no single theory of what kinds of moods and emotions music evokes and conveys. Therefore, there is no widely agreed upon taxonomy on which to draw from the music psychology literature. Second, the Affect Map is not intended to provide a taxonomy of moods and emotions. It is designed to provide a framework through which one can document affect in tone quality analysis. Not tying the framework to a taxonomy, therefore, provides the flexibility of the framework to be applied in a descriptive way across a number of different contexts.</p>

<p>[19] The Affect Map provides a visual, dynamic representation of emotion and mood in light of the literature discussed above. A blank template is shown in Example 2A. Moods are denoted by squares and emotions are denoted by circles. Valence is denoted by the color which sits on a spectrum from white to black, and arousal tension and arousal energy lay along the <i>x</i> and <i>y</i> axis respectively. The Affect Map can be used to represent any number of emotions, as shown in Example 2B. The placement of the emotions along the arousal and valence scales are my own. They are intended to be indicative only&mdash;a demonstration of how emotions can be placed on the Affect Map. There are of course different levels of intensity of each emotion and the placement of emotions on the Affect Map can vary to demonstrate the varying levels of intensity. The placement of moods (demonstrated in Example 2C) can also vary along the scale. The placement of moods is also my own and derived from my personal experiences.</p>

<p>[20] Example 2C shows how the Affect Map may be used to represent emotions of happiness and tenderness, thus creating a mood of contentment. Happiness in this example is positive (pleasant valence), of moderate energy (moderate arousal tension), and quite alert (high arousal energy). Tenderness in this example is moderately positive (moderately pleasant valence), relaxed (low arousal tension), and quite sedate (lower arousal energy). Taken together, these two emotions create a mood of contentment&mdash;moderate valence, slightly elevated arousal energy, and low arousal tension. Of course, happiness and tenderness may be placed at different points on the three scales (there are different kinds of happiness and tenderness). The examples used here are intended to be illustrative only of how the Affect Map can be used, not prescriptive representations of the level of valence, arousal energy, and arousal tension that make up each mood and emotion.</p>

<h3>Cohesiveness </h3>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 3</b>. Cohesiveness</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=2&nonav=true"><img border="1" alt="Example 3 thumbnail" src="spreadborough_ex03_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[21] Cohesiveness, shown in <b>Example 3</b>, is a tool developed for the analytical technique presented in this paper. It allows the analyst to explore the synergies and conflicts in emotion conveyed through tone and text, and to consider the implications of this for the vocal line in general. In examining the relationship between tone and text, this work is situated within a long tradition of research on the interaction of words and music. Of particular relevance to this paper is the concept of word painting. In relation to popular vocal songs, the potential for musical features such as timbre and processing effects to be employed as a form of word painting have been explored. For example, Serge Lacasse has explored how &ldquo;the manipulation of voice through recording techniques can contribute to the mediation of<nobr>. . .</nobr>expressive moments&rdquo; (<a href="#lacasse_2010" id="citation_lacasse_2010_67dc993d30bea">Lacasse 2010</a>, 211). The analytical technique proposed in the present paper draws on this long tradition of music-text analysis by not only presenting a novel method for analyzing music (tone quality) but by also proposing a systematic mechanism through which one can examine both tone and text together&mdash;Cohesiveness.</p>

<p>[22] Cohesiveness is a tool to allow the simultaneous assessment of vocal and linguistic expression. For example, if one was to assess the vocal timbre and lyrics of Country Joe and the Fish&rsquo;s song &ldquo;The &lsquo;Fish&rsquo; Cheer/I-feel-like-I&rsquo;m-fixin&rsquo;-to-die rag,&rdquo; one may identify the tone quality as being positive and happy, and the lyrics as being negative and sad. This relationship may be described as misaligned in terms of Cohesiveness. It is possible then to extrapolate from this to say that such conflicting emotions create an unsettling mood. The emotional message is ambiguous, and the listener must continually reassess the tone and text to determine what message is being conveyed by the performer. </p>


<h2>Annotating and Analyzing Tone</h2>
<p>[23] This section presents a classification system, called the Tone Quality Features, for annotating and analyzing certain acoustic cues within a tone quality. The features identified for inclusion in the framework are based on a social semiotic perspective of voice quality. This perspective views the emotive power of voice quality as arising from the configuration of different vocal dimensions (e.g., a voice is never just low, but is also smooth and soft) (<a href="#van_leeuwen_1999" id="citation_van_leeuwen_1999_67dc993d30bec">van Leeuwen 1999</a>, 129). It also emphasizes the examination of sound not only in terms of what it &ldquo;expresses&rdquo; or &ldquo;represents,&rdquo; but also how it &ldquo;affects us&rdquo; (<a href="#van_leeuwen_1999" id="citation_van_leeuwen_1999_67dc993d30bee">van Leeuwen 1999</a>, 128). The tone quality features identified here are drawn from existing social semiotic approaches to voice quality (<a href="#van_leeuwen_1999" id="citation_van_leeuwen_1999_67dc993d30bef">van Leeuwen 1999</a>, <a href="#ngo_and_spreadborough_2021" id="citation_ngo_and_spreadborough_2021_67dc993d30bf2">Ngo and Spreadborough 2021</a>). I have expanded on these features by including a system for describing onsets, something which is not addressed in existing social semiotic approaches to voice quality. I have also provided an examination of the emotional implications for each Tone Quality Feature and developed a system for annotating Tone Quality Features. Each feature has been assigned a unique symbol which can be used in place of the linguistic description (for example, a breathy sustain is symbolized as <img src="symbol1.png">).<sup><a name="FN1REF" href="#FN1" id="footnote1">(1)</a></sup></p>

<p>[24] Being able to succinctly and consistently describe acoustic features of a tone quality has two benefits. First, such descriptions help to achieve clarity and efficiency in analysis. The ability to describe a musical feature makes its analysis quicker and clearer. For example, being able to say &ldquo;that pitch is C&rdquo; or &ldquo;that note is a crotchet&rdquo; affords clarity to the discussion of pitch and rhythm. This clarity is achievable because there exists a predetermined system of notating and discussing such elements as pitch and rhythm. Having a system to describe aspects of a tone&rsquo;s quality, then, also lends tone quality analysis a level of clarity which may not otherwise be available.</p>

<p>[25] Second, I also develop a system for discussing tone quality, which is a first step in analyzing how emotion is conveyed. For example, my previous research has suggested that, due to our lived experience of sounds, Tone Quality Features may be associated with particular emotions such as roughness and negative emotions (<a href="#spreadborough_2018" id="citation_spreadborough_2018_67dc993d30bf6">Spreadborough 2018</a>, chap.&nbsp;6). Before this link can be made, however, a systematic way of annotating and discussing these features is required. This is the goal of the Tone Quality Features.</p>

<p>[26] A number of distinct features make up tone quality. Example 1 demonstrates two components, sound quality and musical elements, separated by a broken line. The broken line indicates that musical elements and sound quality are not discrete, but they are dialectically related (<a href="#fairclough_2001" id="citation_fairclough_2001_67dc993d30c05">Fairclough 2001</a>, 234). For example, some of the features within the Tone Quality Features constitute &ldquo;musical elements.&rdquo; One example of this is dynamic. On the other hand, a feature such as breath constitutes sound quality. However, dynamic and breath remain in dialogue because it is easier to produce more breathy sounds at softer dynamics then at louder ones. It is for this reason that the features described below are not categorized into discrete, separate lists for sound quality and musical elements&mdash;because each feature, while discernible and definable in its own right, is in constant dialogue with other features and by extension so too are musical elements and sound qualities.</p>

<p>[27] In this paper, Tone Quality Features which could be considered musical elements have only been included where they can also contribute to sound quality (namely dynamics, range, and vibrato). Thus, in the Tone Quality Features I describe below, not all sound qualities are musical elements, but all musical elements contribute to sound qualities. It is for this reason that other musical elements such as tempo and duration are not included in this analytical approach.</p>

<h3>Level of Annotation and Analysis</h3>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 4</b>. The levels of a song considered in this paper</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=3&nonav=true"><img border="1" alt="Example 4 thumbnail" src="spreadborough_ex04_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[28] The level of annotation and analysis I apply to musical examples depends on the feature being analyzed. <b>Example 4</b> shows the different units of a song considered in this paper. Having a predefined level of analysis allows one to have a detailed representation of a piece while also drawing out salient musical points. In this paper, Tone Quality Features will be annotated at the level of the word. For words with multiple syllables, only the onset of the first syllable and only the termination of the last syllable will be annotated. Tone quality features will be analyzed at the level of the phrase. This level of annotation and analysis is shown in Example 4. The level at which tone quality is annotated and analyzed is shown by rectangles. </p>


<h3>Tone Quality Features</h3>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 5</b>. The Tone Quality Features and their graphic representations</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=4&nonav=true"><img border="1" alt="Example 5 thumbnail" src="spreadborough_ex05_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[29] <b>Example 5</b> shows Tone Quality Features explored in this section as well as their corresponding graphical representation. Each feature can be annotated by using either the scale or by a discrete symbol. For example, a tone quality may be very rough (sitting at the extreme rough end of the scale), very smooth (at the extreme smooth end of the scale), or somewhere in between. One can either annotate the feature by marking its position on the scale (e.g., to indicate very rough: <img src="symbol2.png">), or by utilizing one of three discrete symbols (e.g., very rough: <img src="symbol3.png">, very smooth: <img src="symbol4.png">, moderate: <img src="symbol.png">). Onsets are not represented on a scale but are represented in terms of discrete symbols. This is because I consider the four onset types given in Example 5 sufficient for capturing the variation in the tone quality of an onset.</p>

<p>[30] The Tone Quality Features are not considered absolute, fixed points. Rather they are contextual&mdash;whether that be relative to the conventions of a genre, a vocalist&rsquo;s unique tone quality, or variation within a single song. For this reason, before conducting analysis, a baseline (or equipoise) should be identified (Ngo and Spreadborough 2021). The discussion of Tone Quality Features within the analysis should be in reference to this equipoise.</p>

<p>[31] It is not only the configuration of a particular tone quality (e.g., how a single sound is annotated on each of the features in Example 5), but also the amount of variability within a feature from one word/phrase to the next that impacts emotion perception. High variability of features has been found to be associated with certain emotive states (e.g., <a href="#juslin_and_laukka_2003" id="citation_juslin_and_laukka_2003_67dc993d30ccb">Juslin and Laukka 2003</a>). Variability refers to the amount of irregularity in a sound. Assessments of irregularity are not made in relation to an absolute reference point, but rather in relation to the surrounding use of that feature. This is identifiable at the level of the word but is most obvious at the level of the phrase. For example, a tone quality that consistently employed vibrato within a phrase would not be considered irregular. However, one that varied from extreme plain to extreme vibrato between words would be considered irregular. Juslin and Laukka (<a href="#juslin_and_laukka_2003" id="citation_juslin_and_laukka_2003_67dc993d30cce">2003</a>) found that microstructural irregularity was associated with the basic emotions of anger, fear, and sadness (i.e., negative emotional states), while regularity was associated with happiness and tenderness (i.e., positive emotional states) (<a href="#juslin_and_laukka_2003" id="citation_juslin_and_laukka_2003_67dc993d30cd0">Juslin and Laukka 2003</a>, Table 11). Going beyond these basic emotions, I propose that irregularity could also be associated with nervousness and anticipation, which are not necessarily negative but are states of uncertainty. Therefore, high levels of variability would signify uncertainty, while low levels would signify certainty. In terms of the placement of variability on the Affect Map, extremely high levels of variability would be placed on the three dimensions as follows: more unpleasant (valence), either awake or tired (arousal energy), and more tense (arousal tension).</p>

<h4>Onset</h4>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 6</b>. A list of Tone Quality Features that relate to onset</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=5&nonav=true"><img border="1" alt="Example 6 thumbnail" src="spreadborough_ex06_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[32] Onset forms the initial part of the note and is important for the listener&rsquo;s ability to recognize timbre (see, for example, Saldanha and Coroso, as cited in <a href="#erickson_1975" id="citation_erickson_1975_67dc993d30d2f">Erickson 1975</a>, 61). I draw on three different classes of onset defined by Jo Estill (<a href="#mcdonald_klimek_obert_and_steinhauer_2005" id="citation_mcdonald_klimek_obert_and_steinhauer_2005_67dc993d30d31">McDonald Klimek, Obert, and Steinhauer 2005</a>, 2&ndash;4): glottal onset, aspirate onset, and simultaneous onset. In addition, I add one more kind of onset to this list based on Heidemann (<a href="#heidemann_2016" id="citation_heidemann_2016_67dc993d30d42">2016</a>): the creak onset. These four onsets are described in <b>Example 6</b>.</p>


<h4>Sustain</h4>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 7</b>. A list of Tone Quality Features that relate to sustain</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=6&nonav=true"><img border="1" alt="Example 7 thumbnail" src="spreadborough_ex07_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[33] Sustain forms the middle, and often the longest, part of the note. Because of its longer duration, there is ample opportunity for multiple Tone Quality Features to change and develop during the sustain. In developing the Tone Quality Features of sustain I draw primarily on theories of social semiotics of sound, specifically on the voice qualities outlined in van Leeuwen (<a href="#van_leeuwen_1999" id="citation_van_leeuwen_1999_67dc993d30d9f">1999</a>, 129&ndash;141). Using my own findings (<a href="#spreadborough_and_anton-mendez_2019" id="citation_spreadborough_and_anton-mendez_2019_67dc993d30da2">Spreadborough and Anton-Mendez 2019</a>, <a href="#spreadborough_2018" id="citation_spreadborough_2018_67dc993d30da4">Spreadborough 2018</a>), these features are expanded such that they may be used to identify emotional valence in tone quality. It is not the goal here to provide a set of independent, individually measurable characteristics of sound. Rather, all Tone Quality Features are dialectically related&mdash;a sound is never just breathy, it is always a combination of all available Tone Quality Features. The analytical techniques presented here, especially the real time annotations, are designed to account for this by capturing different configurations of tone qualities simultaneously. The aim of this approach is to examine different configurations of tone qualities within the voice. These Tone Quality Features are described in <b>Example 7</b>.</p>


<h4>Termination</h4>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 8</b>. A list of Tone Quality Features that relate to termination</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=7&nonav=true"><img border="1" alt="Example 8 thumbnail" src="spreadborough_ex08_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[34] Termination, another tone quality feature, forms the end of the note. The duration of a termination ranges from very short to very long. <b>Example 8</b> describes these possible terminations and explores their emotional associations. </p>


<h2>Analyzing Text</h2>
<p>[35] There are a range of approaches to text analysis in song. These range from explicit analysis of emotional words to more nuanced sentiment analysis utilizing theories such as Systemic Functional Linguistics (SFL) (e.g., <a href="#ngo_and_spreadborough_2021" id="citation_ngo_and_spreadborough_2021_67dc993d30dfe">Ngo and Spreadborough 2021</a>). In this paper, I do not adopt a formal textual framework for analysis. I take this approach because text analysis is independent of tone analysis. That is, one can take the tone analysis approach presented in this paper (Tone Quality Features, Affect Map, and Cohesiveness) and apply whatever textual analysis one wishes. Since the purpose of this paper is to present a system for annotating and analyzing tone, and a tool for comparing the emotionality of tone with the emotionality of text content, it is not necessary to mandate a form of text analysis. Indeed, the application of different text analysis systems (as has been explored in <a href="#ngo_and_spreadborough_2021" id="citation_ngo_and_spreadborough_2021_67dc993d30e00">Ngo and Spreadborough 2021</a>) and the analyses that result from such applications, provides ample opportunities for future research. In this paper, I assess the emotionality of text based on my experience as a native English speaker, primarily drawing on words that explicitly convey emotion, and that are emphasized in the musical phrase via their tone quality. </p>

<h2>Application</h2>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 9</b>. Timeline of the song &ldquo;Casey&rsquo;s Last Ride&rdquo; by Kris Kristofferson</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=8&nonav=true"><img border="1" alt="Example 9 thumbnail" src="spreadborough_ex09_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[36] Having laid out the methodology in the above sections, the analytical approach will here be demonstrated through an analysis of the first verse and the first chorus of Kris Kristofferson&rsquo;s &ldquo;Casey&rsquo;s Last Ride&rdquo; taken from Kristofferson&rsquo;s 1970 album <i>Kristofferson</i>. <b>Example 9</b> shows the song timeline, characters, structure, and lyrics. The analysis of verse one will be presented first, followed by the analysis of chorus one.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Audio-visual Example 1</b></p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=9&nonav=true"><img border="1" alt="Audio-visual Example 1 thumbnail" src="spreadborough_videoex1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to watch video)</font></p></fig>

<p>[37] The equipoise of the song occurs at line one of verse one (see Example 9, and hear this section in <b>Audio-visual Example 1</b> , 00:00&ndash;00:12). At this point, most of the Tone Quality Features sit within the midpoint of the scale. Onsets are mostly simultaneous. While some Tone Quality Features tend towards the extremes of the scale (termination, breath, and vibrato), there is little variability in these features&mdash;that is, there is a consistency of tone quality which makes this a good example of tone quality equipoise.</p>


<h3>Verse 1</h3>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 10</b>. An assessment of the emotion present in the lyrics of verse one, &ldquo;Casey&rsquo;s Last Ride&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=10&nonav=true"><img border="1" alt="Example 10 thumbnail" src="spreadborough_ex10_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[38] The narrator introduces Casey in verse one. The lyrics progress from a sense of depression to a sense of unease. The lyrics in phrase one suggest a more relaxed, tired, and unpleasant emotive state (see Example 10) as they outline Casey&rsquo;s complicit descent into the subway. This is shown in Example 10 where the Affect Map is used to represent the emotions in this verse. This configuration of arousal and valence is consistent with sadness. Phrase two moves to a more tense, awake, and moderately unpleasant emotionality (see <b>Example 10</b>) as the narrator describes Casey&rsquo; isolation and the silent desperation of his descent. Such a configuration might suggest a moderate fear. The mixture of sadness and fear present in part one creates a sense of depression&mdash;portraying Casey&rsquo;s understanding of the desperateness, yet helplessness, of his situation. </p>

<p>[39] Phrase three conveys a lyrical message that is mostly tense, awake, and moderately unpleasant, which is typically associated with fear. This is evoked by the use of highly emotive words which relate to death such as &ldquo;poison&rdquo; and &ldquo;dying&rdquo; as well as words that signify deprivation such as &ldquo;never felt the rain.&rdquo; Phrase four returns to sadness, but this time it is more tense, awake, and unpleasant than in phrase one. The movement of fear to more intense sadness creates a mood of unease in part two. The lyrics point to Casey knowing of the danger he is in, but suggest an inability to do anything to change the situation, as emphasized by the phrase &ldquo;clicking of the turnstile&rdquo; and &ldquo;rattle of his chains&rdquo;; the evocation of these quotidian sounds suggests that Casey is continuing in his established patterns. </p>

<p>[40] The tone quality of this verse has been annotated in real time using the Tone Quality Features (see Audio-visual Example 1). As with the assessment of emotion in lyrics above, an analysis of tone quality using real-time analysis reveals that verse one can be split into two equal parts consisting of lines 1&ndash;4 and 5&ndash;8. This delineation can be observed through each of the categories of Tone Quality Features: onset, sustain, and termination. </p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 11</b>. Glottal and creak onsets in the first verse of &ldquo;Casey&rsquo;s Last Ride.&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=11&nonav=true"><img border="1" alt="Example 11 thumbnail" src="spreadborough_ex11_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[41] Onsets in part one are mostly aspirate and simultaneous (see <b>Example 11</b>). By contrast, the onsets in part two are much more varied. In part two, glottal and creak onsets play a greater role than part one, especially around lines 5&ndash;7. This increased use of glottal and creak onsets is shown in Example 11. Note that in verse one aspirate onsets do occur but only on words which would typically have an aspirate onset anyway (e.g., words beginning with &ldquo;s&rdquo; and &ldquo;f&rdquo;). For this reason, aspirate onsets are not annotated nor analyzed for their emotionality since they are considered to be by-products of the pronunciation of lyrics. This is also the case for simultaneous onsets which are not annotated or analyzed in Example 11 since they are considered to be most neutral and also by-products of lyric pronunciation. </p>

<p>[42] A change in lyrical content accompanies this change in onset in part two. Whereas part one alludes to a monotonous, isolating experience of life, part two refers directly to death&mdash;either metaphorical or literal. It is on words that make references to death that glottal and creak onsets can be heard. </p>

<p>[43] Phrase 3 is the first time a glottal onset is heard in part two. While the word it occurs on (breathin&rsquo;) is not a direct reference to death itself, the words which precede it, &ldquo;The poison air,&rdquo; cast &ldquo;breathin&rsquo;&rdquo; in a negative light. It is the act of breathing this poison air that signifies death. Phrase 3 contains four more glottal onsets on the words &ldquo;dirty,&rdquo; &ldquo;dying,&rdquo; &ldquo;never,&rdquo; and &ldquo;rain&rdquo; (Example 11). Each time, these onsets draw out the lyrical message of death and stagnation. Glottal onsets bookend the phrase &ldquo;dirty smell of dying,&rdquo; drawing out the negative message of this phrase. Similarly, glottal onsets also bookend &ldquo;never felt the rain,&rdquo; which highlights the message of stagnation. In phrase 4, the glottal onsets on &ldquo;never&rdquo; and &ldquo;ignores&rdquo; serve to further draw attention to the deadly stagnation of the poison air by bookending the phrase &ldquo;ignores the fatal echoes.&rdquo; Before examining the second half of phrase 4, let&rsquo;s first pause to consider the impact of these glottal onsets on emotional perception. </p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 12</b>. Assessing the onsets in part two of verse one against the Affect Map</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=12&nonav=true"><img border="1" alt="Example 12 thumbnail" src="spreadborough_ex12_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[44] The glottal onsets in part two signify an emotional state that is tense, mostly awake, and moderately unpleasant (<b>Example 12</b>). This may be perceived as indicative of anger. The regular use of glottal onsets in part two (compared with part one) creates an overall mood of defiance. Casey reacts angrily to the lyrical message of death in part two, he is defiant, and, in this defiance, there is hope that his situation may yet change. However, the second half of phrase 4 colors this message with a different emotion and mood. </p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 13</b>. Annotation of Tone Quality Features which are exemplars of sustain in verse one</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=13&nonav=true"><img border="1" alt="Example 13 thumbnail" src="spreadborough_ex13_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p> <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 14</b>. Assessing the sustain of verse one against the Affect Map</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=14&nonav=true"><img border="1" alt="Example 14 thumbnail" src="spreadborough_ex14_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>


<p>[45] The second half of phrase 4 contains both a glottal and a creak onset (Example 11). The glottal onset on &ldquo;clickin&rsquo;&rdquo; appears to perpetuate this sense of defiance. However, the placement of this glottal onset is different than in other phrases (occurring very early in the line), and it falls on a word which does not appear to convey a message of death and stagnation. The proceeding creak onset on &ldquo;rattle&rdquo; may shed some light on this. This creak onset signifies a mostly relaxed, tired, and unpleasant emotive state. This may be perceived as indicative of sadness. The use of a single creak onset and the resulting sense of sadness creates an overall mood of hopelessness (Example 12). This sense of hopelessness is further heightened when we consider the previous glottal onset. Compared to the rest of the verse, line 8 has high variability of onsets both in kind (creak + glottal) and placement (glottal at the start of the line). Such high variability is associated with negative emotional states. In this way, Casey&rsquo;s defiance is betrayed by the onsets in line 8. Has Casey&rsquo;s resolve been rattled? Does the knowledge of his impending fate penetrate his defiance, just as the irregularity of line 8 penetrates through the texture of the song? </p>

<p>[46] The emotional message conveyed through onset is reinforced through the sustain. Part one of the verse is quite steady across the Tone Quality Features of sustain (<b>Example 13</b>). The tone is consistently clear and plain. The ends of each line tend to become softer and lower, and tension and roughness oscillate between low and medium. There is moderate nasality which is indicative of negative emotional states. However, taken with the steady presentation of the other Tone Quality Features, overall sustain in part one is mostly relaxed, awake, and pleasant (<b>Example 14</b>). This is not indicative of any particular emotive state, but it does create a mood of stability. </p>

<p>[47] The sustain in the second half of the verse, like the onsets, paints a different picture (Example 13). Suddenly, tension becomes present in phrases three and four. The level of roughness also varies quite suddenly and obviously in the second half of phrase four. A greater use of the upper range is apparent here too, especially in line six. Nasality remains relatively consistent. However, the potential negative connotations of moderate nasality in part one are now realized in part two with increasing variability in the other features. The presentation of the features at their more extreme ends and the increasing variability within part two both suggest an emotive state that is more tense, awake, and unpleasant (Example 14). This may be indicative of anger (especially given the plain, clear delivery), and may contribute to the mood of defiance suggested by the onsets. Like onset, the final line becomes gradually more lax, low, non-nasal and soft (Example 13), which contributes to the perception that Casey&rsquo;s emotional state has become mostly relaxed, tired, and unpleasant (Example 14). This is indicative of sadness and hopelessness (Example 14).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 15</b>. Terminations in the first verse of &ldquo;Casey&rsquo;s Last Ride.&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=15&nonav=true"><img border="1" alt="Example 15 thumbnail" src="spreadborough_ex15_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[48] Termination is the least varied of the Tone Quality Features. Terminations remain mostly strong throughout, with only three instances of weaker terminations in phrases 2 and 4 (<b>Example 15</b>). These weaker terminations occur at important structural points within the verse, on lines 4 and 8, which contribute to the two-part structure of verse one (Example 15). The tapering termination at the end of the verse is particularly interesting. Tapering terminations can signify negative emotions which may be more relaxed, tired, and unpleasant. The tapering termination at the end of phrase 4, then, is in line with the mood and emotion conveyed through onset and sustain. This reinforces the emotional message conveyed through tone quality: in verse one Casey has been through a journey of control, defiance, and finally hopelessness. </p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 16</b>. Using cohesiveness to assess the state of synergy of emotion conveyed through tone and text in verse one of &ldquo;Casey&rsquo;s Last Ride&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=16&nonav=true"><img border="1" alt="Example 16 thumbnail" src="spreadborough_ex16_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and see the rest)</font></p></fig>

<p>[49] The overall message delivered in the vocal line in part one of verse one is mostly aligned (<b>Example 16</b>). Tone quality features in this section do not tend towards the extreme of any emotion, but rather create a sense of steadiness. This moderate tone does not conflict with the text through which a general sense of depression is created. Thus, the tone/text relationship in the first half of the verse creates an affirming message for the listener: it is easy to access and understand the emotionality of the vocal line.</p>


<p>[50] The second half of the verse, on the other hand, presents a slightly different tone/text relationship (Example 16). The lyrics in the second half create a sense of unease. The tone quality, however, moves from a sense of defiance in lines 5&ndash;7 to a sense of hopelessness in line 8. While ending the verse with a tone quality which suggests hopelessness does create a sense of unease, in general the tone and text remain only somewhat aligned. The listener must reflect on tone and text to understand the implications of the unease and defiance in lines 5&ndash;7 (has Casey broken free of the depression in part one?), and must also assess the meaning of the suddenly aligned message at the end of unease and hopelessness (did Casey give in to the depression which surrounded him in part one?). </p>

<h3>Chorus 1</h3>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 17</b>. An assessment of the emotion present in the lyrics of chorus one, &ldquo;Casey&rsquo;s Last Ride&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=17&nonav=true"><img border="1" alt="Example 17 thumbnail" src="spreadborough_ex17_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[51] The narrator introduces The Woman in chorus one. Example 9 shows the lyrics for this section. The lyrics switch to a first-person voice as The Woman pleads with Casey to stay with her. The lyrics of phrases 1, 3, and 4 suggest an emotional state that is mostly relaxed, moderately tired, and mostly unpleasant. This is shown in <b>Example 17</b> where the Affect Map is used to represent the emotions in this chorus. It is in these phrases that The Woman makes her pleas to Casey&mdash;she has missed him and now that he is here, can&rsquo;t he stay just a little longer? This plea is not explicit, but rather it is conveyed implicitly throughout the phrases. This implicitness contributes to the more relaxed, tired emotionality of these phrases&mdash;the emotion is subdued and under the surface. The lyrics are also more unpleasant as they suggest that the relationship never used to be this distant. This configuration of arousal and valence is generally consistent with sadness. </p>


<p>[52] The lyrics of phrase 2, however, convey a different message. Here, the lyrics also suggest an emotional state that is relaxed and tired, conveying the emotional message implicitly. Yet, this phrase is more pleasant due to the use of words such as kiss, and smile, as well as the implication of closeness to Casey. This configuration of valence and arousal might be considered consistent with tenderness: The Woman still loves Casey even if he is making her sad. This mixture of sadness and tenderness creates an overall sense of despair (Example 17).</p>


<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Audio-visual Example 2</b></p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=18&nonav=true"><img border="1" alt="Audio-visual Example 2 thumbnail" src="spreadborough_videoex2_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to watch video)</font></p></fig>

<p>[53] The tone quality of this chorus in real time is annotated in <b>Audio-visual Example 2</b>. Aspirate and simultaneous onsets are used exclusively throughout this chorus except for phrase 4. Glottal and creak onsets appear in this phrase (<b>Example 18</b>). Similar to the analysis of onset above, aspirate and simultaneous onsets are not annotated since they tend to be byproducts of the pronunciation of lyrics. The use of such onsets does not suggest any highly charged emotional state. Rather, the tone is moderately tense, awake, and pleasant, creating a mood of stability (<b>Example 19</b>). Against this aural backdrop, the use of glottal and creak onsets in phrase 4 is quite salient. </p>

 <table width=800><tr><td valign='top' width=50%><p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 18</b>. Glottal and creak onsets in the first verse of &ldquo;Casey&rsquo;s Last Ride.&rdquo;</p><p class='fullwidth' style="text-align: center;"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=19&nonav=true"><img border="1" alt="Example 18 thumbnail" src="spreadborough_ex18_small.png"></a></p><p class='fullwidth' style="text-align: center"><font size="2">(click to enlarge)</font></p></td><td width=50></td><td valign='top' width=50%><p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 19</b>. Assessing the onsets in chorus one against the Affect Map</p><p class='fullwidth' style="text-align: center;"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=20&nonav=true"><img border="1" alt="Example 19 thumbnail" src="spreadborough_ex19_small.png"></a></p><p class='fullwidth' style="text-align: center"><font size="2">(click to enlarge)</font></p></td></tr></table>
<p>[54] This change of onset is also accompanied by a change in lyrical message. In the first three phrases The Woman is speaking in declarative statements. In phrase four, The Woman poses a question for the first time. The question begins almost as a demand with the strong, assertive glottal onset on &ldquo;Casey,&rdquo; but ends as a beg with the creak onset on the word &ldquo;only.&rdquo; This sudden questioning and variation in onset increases the salience of phrase 4. The glottal onset may signify a mostly tense, awake, and moderately unpleasant emotional state (Example 19). Such a configuration may suggest anger: The Woman is aggressive in her demand for Casey to stay. The creak onset, however, subverts this emotional message. The slightly more relaxed and tired arousal of this onset is more consistent with fear&mdash;it is at this point that The Woman tempers her message with the use of the word &ldquo;only&rdquo; (Example 19). The variability in onsets, although small, is salient and heightens the sense of the negative mood created in this chorus. Taken together, onsets in chorus one create a mood of unease. </p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 20</b>. Annotation of roughness, dynamic, range, and termination for chorus one of &ldquo;Casey&rsquo;s Last Ride.&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=21&nonav=true"><img border="1" alt="Example 20 thumbnail" src="spreadborough_ex20_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[55] The sustain and termination reflect this message too. The entire chorus is almost always plain, breathy, and non-nasal, but variation can be heard in other vocal features (see Audio-visual Example 2). Beginning in phrase 2, variations in range, dynamic, and roughness are heard. Here, the word &ldquo;just&rdquo; is stronger and higher than the vocal quality in the previous line (<b>Example 20</b>). However, these variations are short lived, with a return to the low, soft vocal quality on the following words, &ldquo;a kiss&rdquo; (Example 20). But the delivery of &ldquo;a kiss&rdquo; is not as smooth as the preceding vocal quality has been. While this is not the first-time roughness has become present in this otherwise soft, low voice, it is the first time that roughness has been preceded by any other variation in sustain. Indeed, the words &ldquo;just a kiss&rdquo; are accentuated by the unusually weak termination on the words &ldquo;she said.&rdquo; </p>

<p>[56] Phrases 3 and 4 also exhibit variations in sustain and termination. Phrase 3 begins with the personal pronoun &ldquo;I&rdquo; being delivered at a higher pitch then before. But as the phrase progresses, the sustain becomes lower and softer again (Example 20). The delivery of the final words &ldquo;to please you&rdquo; returns to the low, weak sustain. This is underscored by the termination with which the final word is delivered. Phrase four begins much like the previous; the weaker termination on the words &ldquo;she said&rdquo; followed by the stronger, higher delivery of &ldquo;Casey&rdquo; suggests an assertiveness (Example 20). However, this is short lived as the final words &ldquo;only stay a while&rdquo; are delivered with a consistent roughness, persisting (for the first time) nearly the entire length of the phrase. </p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 21</b>. Assessing the sustain and termination in chorus one against the Affect Map.</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=22&nonav=true"><img border="1" alt="Example 21 thumbnail" src="spreadborough_ex21_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[57] Throughout the chorus, sustain and termination create an emotional message that is mostly relaxed, tired, and unpleasant (<b>Example 21</b>). This configuration is consistent with sadness (Example 21). The combination of consistency in breath, nasality, and vibrato, combined with relatively high variability in roughness, dynamic, range, and termination, heighten the negativity of this emotion, creating a mood of pain.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 22</b>. Using cohesiveness to assess the state of synergy of emotion conveyed through tone and text in chorus one of &ldquo;Casey&rsquo;s Last Ride.&rdquo;</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="spreadborough_examples.php?id=23&nonav=true"><img border="1" alt="Example 22 thumbnail" src="spreadborough_ex22_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[58] The overall message delivered in the vocal line in chorus one is mostly aligned (<b>Example 22</b>). Tone quality features suggest low arousal and negative valence, creating a mood of pain. On the whole this does not conflict with the text through which a general sense of despair is evident. Thus, the tone/text relationship in chorus one creates an affirming message for the listener. The emotionality of the vocal line is easy to access and understand. </p>


<p>[59] However, there are instances where vocal quality and lyrics are misaligned (Example 22). In particular, the lyrics &ldquo;just a kiss&rdquo; and &ldquo;just to please you,&rdquo; which might be considered positive emotional messages, are delivered with a negative tone. While brief, these small instances of misalignment are salient. This creates a more ambiguous emotional message, prompting the listener to reassess the tone/text relationship in order to ascertain the overall message. The result is that at times the emotional message is not always obvious. Rather, this emotional message unfolds over time, making the listener work to interpret the message on a phrase by phrase, word by word basis. Ultimately, this serves to heighten the emotional message. The listener, uncertain of what is happening, struggles through the verse just as The Woman struggles through her final encounter with Casey. </p>

<h3>Contrasting verses and choruses</h3>
<p>[60] There is a noticeable contrast between the tone quality of verse one, which relates to Casey, and that of chorus one, which relates to The Woman. Overall, verse one is abrasive, while chorus one is anguished. There are several explanations for this contrast. </p>

<ol>
	<li>Casey always acts, while The Woman always speaks. Casey&rsquo;s actions are central to his story. The listener observes Casey moving through a hard, rough world, a reality that is manifested in his tone quality. The Woman, on the other hand, exists in bittersweet memory which is signified by the soft and fervent tone quality. </li>
	<li>Casey is the present, while The Woman is the past. This dichotomy is established as early as the first few lines&mdash;Casey is following and seeing. This present is uncertain and dangerous, and this is reflected in the tone quality that is generally indicative of high arousal, unpleasant emotive states (and further underscored by variations in the two parts of the verse). The Woman, on the other hand, is the past&mdash;she is not saying, but has said. The past is fixed, and so too then are the negative events of the past (The Woman not being able to make Casey stay). This sense of helplessness is reflected in the tone quality and the emotional vulnerability is heightened by changing cohesiveness in the text/tone relationship between the chorus in general and key phrases in particular. </li>
	<li>Casey is death, while The Woman is life. Literal and metaphorical death is a salient lyrical theme in verse one, as the listener observes Casey&rsquo;s isolating and lonely experience. Chorus one, however, is shaped by The Woman&rsquo;s connection to Casey (seeing, speaking, kissing). The Woman is life immortalized&mdash;her place in memory means that she cannot be touched by the harsh, physical realities of the present world, including death. She anchors Casey to the world of the living, calling for Casey to stay, if only for a while. </li>
</ol>

<p>[61] In both tone and text, Casey and The Woman sit at opposite ends of the spectrum. This divide between the characters heightens their individual messages. Once intimately connected, the characters are now separated from one and other, and their narratives express this loneliness in contrasting ways. This contrast both in text and in tone drives the song forward.</p>

<h2>Conclusion</h2>
<p>[62] The goal of this paper is to present a new approach to analyzing the sung voice. This is achieved by presenting a new framework for analyzing tone quality through the Tone Quality Features and associated tools (the Affect Map and Cohesiveness). This paper also offers a method of considering the emotionality of text alongside that of tone. The analytical approach proposed in this paper is not intended to be prescriptive. Instead, my goal is to provide a consistent framework to annotate, analyze, and describe tone quality and its relationship with text. Others, in applying this same framework, may arrive at different conclusions about emotion and mood in tone quality and text. This is not uncommon in music analysis. Indeed, debating different conclusions drawn from the application of the same framework is a regular occurrence&mdash;for example, different interpretations may be drawn from the application of Schenkerian analysis to the same piece. Many of the Tone Quality Features here, specifically those use to describe sustain, are adopted from the social semiotics of sound proposed by van Leeuwen (<a href="#van_leeuwen_1999" id="citation_van_leeuwen_1999_67dc993d3148f">1999</a>). This is based primarily on the acoustic experience of sound. In future work, how the Tone Quality Features can be extended to account for technologically mediated sound experience is an important avenue for research. </p>

<p>[63] The main implications for this approach relate to the annotation and analysis of the voice in popular vocal songs. Additionally, this paper draws on psychology and social semiotics to offer a systematic method of assessing emotionality of tones and for integrating this into analysis. In this way, I present a framework on which future research can build in a variety of ways, including through musicology, multimodality, social semiotics, and psychology.</p>

<!-------------------------------- END Article Body -------------------------------------------->

	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Author Info -------------------------------------------->

	
<hr>

	<p><a name="AUTHORNOTE1"></a>
	
	Kristal Spreadborough<br>
	University of Melbourne<br>Melbourne Connect (Building 290), Level 8<br>700 Swanston Street<br>Carlton, VIC, 3053<br>Australia<br><a href="mailto:kristal.spreadborough@unimelb.edu.au">kristal.spreadborough@unimelb.edu.au</a><br>	
</p>
	
       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Works Cited List -------------------------------------------->

	
	<hr>
	
	<h3><a name="WorksCited">Works Cited</a></h3>
	
	<div id="citediv_campbell_and_greated_2001" class="flyoverdiv">Campbell, Murray, and Clive Greated. 2001. &ldquo;Loudness.&rdquo; In <i>Grove Music Online</i>. <a href='https://doi.org/10.1093/gmo/9781561592630.article.17030'>https://doi.org/10.1093/gmo/9781561592630.article.17030</a>. Accessed December 15, 2020.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="campbell_and_greated_2001"></a>Campbell, Murray, and Clive Greated. 2001. &ldquo;Loudness.&rdquo; In <i>Grove Music Online</i>. <a href='https://doi.org/10.1093/gmo/9781561592630.article.17030'>https://doi.org/10.1093/gmo/9781561592630.article.17030</a>. Accessed December 15, 2020.</p><div id="citediv_carter_2001" class="flyoverdiv">Carter, Tim. 2001. &ldquo;Word-Painting.&rdquo; <i>Oxford Music Online</i>. <a href='https://doi.org/10.1093/gmo/9781561592630.article.30568'>https://doi.org/10.1093/gmo/9781561592630.article.30568</a>. Accessed August 24, 2018.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="carter_2001"></a>Carter, Tim. 2001. &ldquo;Word-Painting.&rdquo; <i>Oxford Music Online</i>. <a href='https://doi.org/10.1093/gmo/9781561592630.article.30568'>https://doi.org/10.1093/gmo/9781561592630.article.30568</a>. Accessed August 24, 2018.</p><div id="citediv_eerola_and_vuoskoski_2011" class="flyoverdiv">Eerola, Tuomas, and Jonna K. Vuoskoski. 2011. &ldquo;A Comparison of the Discrete and Dimensional Models of Emotion in Music.&rdquo; <i>Psychology of Music</i> 39 (1): 18&ndash;49. <a href='https://doi.org/10.1177/0305735610362821'>https://doi.org/10.1177/0305735610362821</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="eerola_and_vuoskoski_2011"></a>Eerola, Tuomas, and Jonna K. Vuoskoski. 2011. &ldquo;A Comparison of the Discrete and Dimensional Models of Emotion in Music.&rdquo; <i>Psychology of Music</i> 39 (1): 18&ndash;49. <a href='https://doi.org/10.1177/0305735610362821'>https://doi.org/10.1177/0305735610362821</a>.</p><div id="citediv_eerola_and_vuoskoski_2013" class="flyoverdiv">Eerola, Tuomas, and Jonna K. Vuoskoski. 2013. &ldquo;A Review of Music and Emotion Studies: Approaches, Emotion Models, and Stimuli.&rdquo; <i>Music Perception</i> 30 (3): 307&ndash;40. <a href='https://doi.org/10.1525/MP.2012.30.3.307'>https://doi.org/10.1525/MP.2012.30.3.307</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="eerola_and_vuoskoski_2013"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2013. &ldquo;A Review of Music and Emotion Studies: Approaches, Emotion Models, and Stimuli.&rdquo; <i>Music Perception</i> 30 (3): 307&ndash;40. <a href='https://doi.org/10.1525/MP.2012.30.3.307'>https://doi.org/10.1525/MP.2012.30.3.307</a>.</p><div id="citediv_erickson_1975" class="flyoverdiv">Erickson, Robert. 1975. <i>Sound Structure in Music</i>. University of California Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="erickson_1975"></a>Erickson, Robert. 1975. <i>Sound Structure in Music</i>. University of California Press.</p><div id="citediv_evans_and_schubert_2008" class="flyoverdiv">Evans, Paul, and Emery Schubert. 2008. &ldquo;Relationships between Expressed and Felt Emotions in Music.&rdquo; <i>Musicae Scientiae</i> 12 (1): 75&ndash;99. <a href='https://doi.org/10.1177/102986490801200105'>https://doi.org/10.1177/102986490801200105</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="evans_and_schubert_2008"></a>Evans, Paul, and Emery Schubert. 2008. &ldquo;Relationships between Expressed and Felt Emotions in Music.&rdquo; <i>Musicae Scientiae</i> 12 (1): 75&ndash;99. <a href='https://doi.org/10.1177/102986490801200105'>https://doi.org/10.1177/102986490801200105</a>.</p><div id="citediv_fairclough_2001" class="flyoverdiv">Fairclough, Norman. 2001. &ldquo;The Discourse of New Labour: Critical Discourse Analysis.&rdquo; In <i>Discourse as Data: A Guide for Analysis</i>, ed. Margaret Wetherell, Stephanie J.A. Taylor and Simeon J. Yates, 229&ndash;66. Sage Publishing.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="fairclough_2001"></a>Fairclough, Norman. 2001. &ldquo;The Discourse of New Labour: Critical Discourse Analysis.&rdquo; In <i>Discourse as Data: A Guide for Analysis</i>, ed. Margaret Wetherell, Stephanie J.A. Taylor and Simeon J. Yates, 229&ndash;66. Sage Publishing.</p><div id="citediv_frith_1998" class="flyoverdiv">Frith, Simon. 1998. <i>Performing Rites: On the Value of Popular Music</i>. Harvard University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="frith_1998"></a>Frith, Simon. 1998. <i>Performing Rites: On the Value of Popular Music</i>. Harvard University Press.</p><div id="citediv_haynes_and_cooke_2001" class="flyoverdiv">Haynes, Bruce, and Peter Cooke. 2001. &ldquo;Pitch.&rdquo; In <i>Grove Music Online</i>. <a href='https://doi.org/10.1093/gmo/9781561592630.article.40883'>https://doi.org/10.1093/gmo/9781561592630.article.40883</a>. Accessed December 15, 2020.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="haynes_and_cooke_2001"></a>Haynes, Bruce, and Peter Cooke. 2001. &ldquo;Pitch.&rdquo; In <i>Grove Music Online</i>. <a href='https://doi.org/10.1093/gmo/9781561592630.article.40883'>https://doi.org/10.1093/gmo/9781561592630.article.40883</a>. Accessed December 15, 2020.</p><div id="citediv_heidemann_2016" class="flyoverdiv">Heidemann, Kate. 2016. &ldquo;A System for Describing Vocal Timbre in Popular Song.&rdquo; <i>Music Theory Online</i> 22 (1). <a href='https://doi.org/10.30535/mto.22.1.2'>https://doi.org/10.30535/mto.22.1.2</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="heidemann_2016"></a>Heidemann, Kate. 2016. &ldquo;A System for Describing Vocal Timbre in Popular Song.&rdquo; <i>Music Theory Online</i> 22 (1). <a href='https://doi.org/10.30535/mto.22.1.2'>https://doi.org/10.30535/mto.22.1.2</a>.</p><div id="citediv_hunter_and_schellenberg_2010" class="flyoverdiv">Hunter, Patrick G., and E. Glenn Schellenberg. 2010. &ldquo;Music and Emotion.&rdquo; In <i>Music Perception</i>, ed. Mari Riess Jones, Richard R. Fay, and Arthur N. Popper, 129&ndash;64. Springer Handbook of Auditory Research, vol. 36. Springer. <a href='https://doi.org/10.1007/978-1-4419-6114-3_5'>https://doi.org/10.1007/978-1-4419-6114-3_5</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="hunter_and_schellenberg_2010"></a>Hunter, Patrick G., and E. Glenn Schellenberg. 2010. &ldquo;Music and Emotion.&rdquo; In <i>Music Perception</i>, ed. Mari Riess Jones, Richard R. Fay, and Arthur N. Popper, 129&ndash;64. Springer Handbook of Auditory Research, vol. 36. Springer. <a href='https://doi.org/10.1007/978-1-4419-6114-3_5'>https://doi.org/10.1007/978-1-4419-6114-3_5</a>.</p><div id="citediv_huron_2015" class="flyoverdiv">Huron, David. 2015. &ldquo;The Other Semiotic Legacy of Charles Sanders Peirce: Ethology and Music-Related Emotion.&rdquo; In <i>Music, Analysis, Experience: New Perspectives in Musical Semiotics</i>, ed. Constantino Maeder and Mark Reybrouck, 185&ndash;208. Leuven University Press. <a href='https://doi.org/10.2307/j.ctt180r0s2.17'>https://doi.org/10.2307/j.ctt180r0s2.17</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="huron_2015"></a>Huron, David. 2015. &ldquo;The Other Semiotic Legacy of Charles Sanders Peirce: Ethology and Music-Related Emotion.&rdquo; In <i>Music, Analysis, Experience: New Perspectives in Musical Semiotics</i>, ed. Constantino Maeder and Mark Reybrouck, 185&ndash;208. Leuven University Press. <a href='https://doi.org/10.2307/j.ctt180r0s2.17'>https://doi.org/10.2307/j.ctt180r0s2.17</a>.</p><div id="citediv_juslin_and_laukka_2003" class="flyoverdiv">Juslin, Patrik N., and Petri Laukka. 2003. &ldquo;Communication of Emotions in Vocal Expression and Music Performance: Different Channels, Same Code?&rdquo; <i>Psychological Bulletin</i> 129 (5): 770&ndash;814. <a href='https://doi.org/10.1037/0033-2909.129.5.770'>https://doi.org/10.1037/0033-2909.129.5.770</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="juslin_and_laukka_2003"></a>Juslin, Patrik N., and Petri Laukka. 2003. &ldquo;Communication of Emotions in Vocal Expression and Music Performance: Different Channels, Same Code?&rdquo; <i>Psychological Bulletin</i> 129 (5): 770&ndash;814. <a href='https://doi.org/10.1037/0033-2909.129.5.770'>https://doi.org/10.1037/0033-2909.129.5.770</a>.</p><div id="citediv_lacasse_2010" class="flyoverdiv">Lacasse, Serge. 2010. &ldquo;Slave to the Supradiegetic Rhythm: A Microrhythmic Analysis of Creaky Voice in Sia's 'Breathe Me'.&rdquo; In <i>Musical Rhythm in the Age of Digital Reproduction</i>, ed. Anne Danielsen, 141&ndash;58. Routledge. <a href='https://doi.org/10.4324/9781315596983-11'>https://doi.org/10.4324/9781315596983-11</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lacasse_2010"></a>Lacasse, Serge. 2010. &ldquo;Slave to the Supradiegetic Rhythm: A Microrhythmic Analysis of Creaky Voice in Sia's 'Breathe Me'.&rdquo; In <i>Musical Rhythm in the Age of Digital Reproduction</i>, ed. Anne Danielsen, 141&ndash;58. Routledge. <a href='https://doi.org/10.4324/9781315596983-11'>https://doi.org/10.4324/9781315596983-11</a>.</p><div id="citediv_lavan_et_al_2019" class="flyoverdiv">Lavan, Nadine, A. Mike Burton, Sophie K. Scott, and Carolyn McGettigan. 2019. &ldquo;Flexible Voices: Identity Perception from Variable Vocal Signals.&rdquo; <i>Psychonomic Bulletin & Review</i> 26: 90&ndash;102. <a href='https://doi.org/10.3758/s13423-018-1497-7'>https://doi.org/10.3758/s13423-018-1497-7</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lavan_et_al_2019"></a>Lavan, Nadine, A. Mike Burton, Sophie K. Scott, and Carolyn McGettigan. 2019. &ldquo;Flexible Voices: Identity Perception from Variable Vocal Signals.&rdquo; <i>Psychonomic Bulletin & Review</i> 26: 90&ndash;102. <a href='https://doi.org/10.3758/s13423-018-1497-7'>https://doi.org/10.3758/s13423-018-1497-7</a>.</p><div id="citediv_laver_1980" class="flyoverdiv">Laver, John. 1980. <i>The Phonic Description of Voice Quality</i>. Cambridge University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="laver_1980"></a>Laver, John. 1980. <i>The Phonic Description of Voice Quality</i>. Cambridge University Press.</p><div id="citediv_lomax_1968" class="flyoverdiv">Lomax, Alan. 1968. <i>Folk Song Style and Culture: A Staff Report on Cantometrics</i>. American Association for the Advancement of Science.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lomax_1968"></a>Lomax, Alan. 1968. <i>Folk Song Style and Culture: A Staff Report on Cantometrics</i>. American Association for the Advancement of Science.</p><div id="citediv_mcdonald_klimek_obert_and_steinhauer_2005" class="flyoverdiv">McDonald Klimek, Mary, Kerrie B. Obert, Kimberly Steinhauer, and Think Voice International. 2005. <i>Estill Voice Training, Level Two: Example Combinations for Six Voice Qualities</i>. Estill Voice Training Systems International.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="mcdonald_klimek_obert_and_steinhauer_2005"></a>McDonald Klimek, Mary, Kerrie B. Obert, Kimberly Steinhauer, and Think Voice International. 2005. <i>Estill Voice Training, Level Two: Example Combinations for Six Voice Qualities</i>. Estill Voice Training Systems International.</p><div id="citediv_middleton_2000" class="flyoverdiv">Middleton, Richard. 2000. &ldquo;Rock Singing.&rdquo; In <i>The Cambridge Companion to Singing</i>, ed. John  Potter, 28&ndash;41. Cambridge University Press. <a href='https://doi.org/10.1017/CCOL9780521622257.004'>https://doi.org/10.1017/CCOL9780521622257.004</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="middleton_2000"></a>Middleton, Richard. 2000. &ldquo;Rock Singing.&rdquo; In <i>The Cambridge Companion to Singing</i>, ed. John  Potter, 28&ndash;41. Cambridge University Press. <a href='https://doi.org/10.1017/CCOL9780521622257.004'>https://doi.org/10.1017/CCOL9780521622257.004</a>.</p><div id="citediv_moylan_2015" class="flyoverdiv">Moylan, William. 2015. <i>The Art of Recording: Understanding and Crafting the Mix</i>. 2nd ed. Focal Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="moylan_2015"></a>Moylan, William. 2015. <i>The Art of Recording: Understanding and Crafting the Mix</i>. 2nd ed. Focal Press.</p><div id="citediv_ngo_and_spreadborough_2021" class="flyoverdiv">Ngo, Thu, and Kristal Spreadborough. 2021. &ldquo;Exploring a Systemic Functional Semiotics Approach to Understanding Emotional Expression in Singing Performance: Implications for Music Education.&rdquo; <i>Research Studies in Music Education</i> (December). <a href='https://doi.org/10.1177/1321103X211034694'>https://doi.org/10.1177/1321103X211034694</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="ngo_and_spreadborough_2021"></a>Ngo, Thu, and Kristal Spreadborough. 2021. &ldquo;Exploring a Systemic Functional Semiotics Approach to Understanding Emotional Expression in Singing Performance: Implications for Music Education.&rdquo; <i>Research Studies in Music Education</i> (December). <a href='https://doi.org/10.1177/1321103X211034694'>https://doi.org/10.1177/1321103X211034694</a>.</p><div id="citediv_paul_and_huron_2010" class="flyoverdiv">Paul, Brandon, and David Huron. 2010. &ldquo;An Association between Breaking Voice and Grief-Related Lyrics in Country Music.&rdquo; <i>Empirical Musicology Review</i> 5 (2): 27&ndash;35. <a href='https://doi.org/10.18061/1811/46747'>https://doi.org/10.18061/1811/46747</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="paul_and_huron_2010"></a>Paul, Brandon, and David Huron. 2010. &ldquo;An Association between Breaking Voice and Grief-Related Lyrics in Country Music.&rdquo; <i>Empirical Musicology Review</i> 5 (2): 27&ndash;35. <a href='https://doi.org/10.18061/1811/46747'>https://doi.org/10.18061/1811/46747</a>.</p><div id="citediv_plazak_2011" class="flyoverdiv">Plazak, Joseph. 2011. &ldquo;Instrumental irony and the perception of musical sarcasm&rdquo;. PhD Thesis. Ohio State University.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="plazak_2011"></a>Plazak, Joseph. 2011. &ldquo;Instrumental irony and the perception of musical sarcasm&rdquo;. PhD Thesis. Ohio State University.</p><div id="citediv_poyatos_1992" class="flyoverdiv">Poyatos, Fernando. 1992. &ldquo;The Audible-Visual Approach to Speech as Basic to Nonverbal Communication Research.&rdquo; In <i>Advances in Nonverbal Communication: Sociocultural, Clinical, Esthetic and Literary Perspectives</i>, ed. Fernando Poyatos, 41&ndash;58. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/z.60.08poy'>https://doi.org/10.1075/z.60.08poy</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="poyatos_1992"></a>Poyatos, Fernando. 1992. &ldquo;The Audible-Visual Approach to Speech as Basic to Nonverbal Communication Research.&rdquo; In <i>Advances in Nonverbal Communication: Sociocultural, Clinical, Esthetic and Literary Perspectives</i>, ed. Fernando Poyatos, 41&ndash;58. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/z.60.08poy'>https://doi.org/10.1075/z.60.08poy</a>.</p><div id="citediv_poyatos_1993" class="flyoverdiv">Poyatos, Fernando. 1993. <i>Paralanguage: A Linguistic and Interdisciplinary Approach to Interactive Speech and Sound</i>. Amsterdam Studies in the Theory and History of Linguistic Science. Series IV, Current Issues in Linguistic Theory. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/cilt.92'>https://doi.org/10.1075/cilt.92</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="poyatos_1993"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1993. <i>Paralanguage: A Linguistic and Interdisciplinary Approach to Interactive Speech and Sound</i>. Amsterdam Studies in the Theory and History of Linguistic Science. Series IV, Current Issues in Linguistic Theory. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/cilt.92'>https://doi.org/10.1075/cilt.92</a>.</p><div id="citediv_poyatos_2002" class="flyoverdiv">Poyatos, Fernando. 2002. <i>Nonverbal Communication Across Disciplines</i>. Volume II: Paralanguage, Kinesics, Silence, Personal and Environmental Interaction. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/z.ncad2'>https://doi.org/10.1075/z.ncad2</a></div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="poyatos_2002"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2002. <i>Nonverbal Communication Across Disciplines</i>. Volume II: Paralanguage, Kinesics, Silence, Personal and Environmental Interaction. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/z.ncad2'>https://doi.org/10.1075/z.ncad2</a></p><div id="citediv_rossing_1990" class="flyoverdiv">Rossing, Thomas D. 1990. <i>The Science of Sound</i>. Addison-Wesley Publishing Company.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="rossing_1990"></a>Rossing, Thomas D. 1990. <i>The Science of Sound</i>. Addison-Wesley Publishing Company.</p><div id="citediv_russell_1980" class="flyoverdiv">Russell, James A. 1980. &ldquo;A Circumplex Model of Affect.&rdquo; <i>Journal of Personality and Social Psychology</i> 39 (6): 1161&ndash;78. <a href='https://doi.org/10.1037/h0077714'>https://doi.org/10.1037/h0077714</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="russell_1980"></a>Russell, James A. 1980. &ldquo;A Circumplex Model of Affect.&rdquo; <i>Journal of Personality and Social Psychology</i> 39 (6): 1161&ndash;78. <a href='https://doi.org/10.1037/h0077714'>https://doi.org/10.1037/h0077714</a>.</p><div id="citediv_schimmack_and_grob_2000" class="flyoverdiv">Schimmack, Ulrich, and Alexander Grob. 2000. &ldquo;Dimensional Models of Core Affect: A Quantitative Comparison by Means of Structural Equation Modeling.&rdquo; <i>European Journal of Personality</i> 14 (4): 325&ndash;45. <a href='https://doi.org/10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I'>https://doi.org/10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="schimmack_and_grob_2000"></a>Schimmack, Ulrich, and Alexander Grob. 2000. &ldquo;Dimensional Models of Core Affect: A Quantitative Comparison by Means of Structural Equation Modeling.&rdquo; <i>European Journal of Personality</i> 14 (4): 325&ndash;45. <a href='https://doi.org/10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I'>https://doi.org/10.1002/1099-0984(200007/08)14:4<325::AID-PER380>3.0.CO;2-I</a>.</p><div id="citediv_smalley_1986" class="flyoverdiv">Smalley, Denis. 1986. &ldquo;Spectro-morphology and Structuring Processes.&rdquo; In <i>The Language of Electroacoustic Music</i>, ed. Simon Emmerson, 61&ndash;93. Palgrave Macmillan. <a href='https://doi.org/10.1007/978-1-349-18492-7_5'>https://doi.org/10.1007/978-1-349-18492-7_5</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="smalley_1986"></a>Smalley, Denis. 1986. &ldquo;Spectro-morphology and Structuring Processes.&rdquo; In <i>The Language of Electroacoustic Music</i>, ed. Simon Emmerson, 61&ndash;93. Palgrave Macmillan. <a href='https://doi.org/10.1007/978-1-349-18492-7_5'>https://doi.org/10.1007/978-1-349-18492-7_5</a>.</p><div id="citediv_smalley_1997" class="flyoverdiv">Smalley, Denis. 1997. &ldquo;Spectromorphology: Explaining Sound-Shapes.&rdquo; <i>Organised Sound</i> 2 (2): 107&ndash;26. <a href='https://doi.org/10.1017/S1355771897009059'>https://doi.org/10.1017/S1355771897009059</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="smalley_1997"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1997. &ldquo;Spectromorphology: Explaining Sound-Shapes.&rdquo; <i>Organised Sound</i> 2 (2): 107&ndash;26. <a href='https://doi.org/10.1017/S1355771897009059'>https://doi.org/10.1017/S1355771897009059</a>.</p><div id="citediv_spreadborough_2018" class="flyoverdiv">Spreadborough, Kristal L. 2018. &ldquo;Voices Within Voices: Developing a New Analytical Approach to Vocal Timbre by Examining the Interplay of Emotionally Valenced Vocal Timbres and Emotionally Valenced Lyrics.&rdquo; PhD Thesis, The University of New England, Armidale, Australia. <a href='https://doi.org/10.6084/m9.figshare.7636886.v1'>https://doi.org/10.6084/m9.figshare.7636886.v1</a>. </div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="spreadborough_2018"></a>Spreadborough, Kristal L. 2018. &ldquo;Voices Within Voices: Developing a New Analytical Approach to Vocal Timbre by Examining the Interplay of Emotionally Valenced Vocal Timbres and Emotionally Valenced Lyrics.&rdquo; PhD Thesis, The University of New England, Armidale, Australia. <a href='https://doi.org/10.6084/m9.figshare.7636886.v1'>https://doi.org/10.6084/m9.figshare.7636886.v1</a>. </p><div id="citediv_spreadborough_and_anton-mendez_2019" class="flyoverdiv">Spreadborough, Kristal. L., and Ines Anton-Mendez. 2019. &ldquo;It&rsquo;s Not What You Sing, It&rsquo;s How You Sing It: How the Emotional Valence of Vocal Timbre Influences Listeners&rsquo; Emotional Perception of Words.&rdquo; <i>Psychology of Music</i> 47 (3): 407&ndash;19. <a href='https://doi.org/10.1177/0305735617753996'>https://doi.org/10.1177/0305735617753996</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="spreadborough_and_anton-mendez_2019"></a>Spreadborough, Kristal. L., and Ines Anton-Mendez. 2019. &ldquo;It&rsquo;s Not What You Sing, It&rsquo;s How You Sing It: How the Emotional Valence of Vocal Timbre Influences Listeners&rsquo; Emotional Perception of Words.&rdquo; <i>Psychology of Music</i> 47 (3): 407&ndash;19. <a href='https://doi.org/10.1177/0305735617753996'>https://doi.org/10.1177/0305735617753996</a>.</p><div id="citediv_tellegen_watson_and_clark_1999" class="flyoverdiv">Tellegen, Auke, David Watson, and Lee Anna Clark. 1999. &ldquo;On the Dimensional and Hierarchical Structure of Affect.&rdquo; <i>Psychological Science</i> 10 (4): 297&ndash;303. <a href='https://doi.org/10.1111/1467-9280.00157'>https://doi.org/10.1111/1467-9280.00157</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="tellegen_watson_and_clark_1999"></a>Tellegen, Auke, David Watson, and Lee Anna Clark. 1999. &ldquo;On the Dimensional and Hierarchical Structure of Affect.&rdquo; <i>Psychological Science</i> 10 (4): 297&ndash;303. <a href='https://doi.org/10.1111/1467-9280.00157'>https://doi.org/10.1111/1467-9280.00157</a>.</p><div id="citediv_titze_1989" class="flyoverdiv">Titze, Ingo R. 1989. &ldquo;Physiologic and Acoustic Differences between Male and Female Voices.&rdquo; <i>The Journal of the Acoustical Society of America</i> 85 (4): 1699&ndash;1707. <a href='https://doi.org/10.1121/1.397959'>https://doi.org/10.1121/1.397959</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="titze_1989"></a>Titze, Ingo R. 1989. &ldquo;Physiologic and Acoustic Differences between Male and Female Voices.&rdquo; <i>The Journal of the Acoustical Society of America</i> 85 (4): 1699&ndash;1707. <a href='https://doi.org/10.1121/1.397959'>https://doi.org/10.1121/1.397959</a>.</p><div id="citediv_van_leeuwen_1999" class="flyoverdiv">van Leeuwen, Theo. 1999. <i>Speech, Music, Sound</i>. Palgrave Mcmillian. <a href='https://doi.org/10.1007/978-1-349-27700-1'>https://doi.org/10.1007/978-1-349-27700-1</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="van_leeuwen_1999"></a>van Leeuwen, Theo. 1999. <i>Speech, Music, Sound</i>. Palgrave Mcmillian. <a href='https://doi.org/10.1007/978-1-349-27700-1'>https://doi.org/10.1007/978-1-349-27700-1</a>.</p><div id="citediv_wescott_1992" class="flyoverdiv">Wescott, Roger W. 1992. &ldquo;Auditory Communication: Non-Verbal, Pre-Verbal, and Co-Verbal.&rdquo; In <i>Advances in Nonverbal Communication: Sociocultural, Clinical, Esthetic and Literary Perspectives</i>, ed. Fernando Poyatos, 25&ndash;40. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/z.60.07wes'>https://doi.org/10.1075/z.60.07wes</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="wescott_1992"></a>Wescott, Roger W. 1992. &ldquo;Auditory Communication: Non-Verbal, Pre-Verbal, and Co-Verbal.&rdquo; In <i>Advances in Nonverbal Communication: Sociocultural, Clinical, Esthetic and Literary Perspectives</i>, ed. Fernando Poyatos, 25&ndash;40. John Benjamins Publishing Company. <a href='https://doi.org/10.1075/z.60.07wes'>https://doi.org/10.1075/z.60.07wes</a>.</p><div id="citediv_wilson_2011" class="flyoverdiv">Wilson, Maura L. 2011. &ldquo;Examining the Effects of Variation in Emotional Tone of Voice on Spoken Word Recognition.&rdquo; MA Thesis, Cleveland State University. <a href='https://engagedscholarship.csuohio.edu/etdarchive/569/'>https://engagedscholarship.csuohio.edu/etdarchive/569/</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="wilson_2011"></a>Wilson, Maura L. 2011. &ldquo;Examining the Effects of Variation in Emotional Tone of Voice on Spoken Word Recognition.&rdquo; MA Thesis, Cleveland State University. <a href='https://engagedscholarship.csuohio.edu/etdarchive/569/'>https://engagedscholarship.csuohio.edu/etdarchive/569/</a>.</p><div id="citediv_wishart_1996" class="flyoverdiv">Wishart, Trevor. 1996. <i>On Sonic Art. A new and rev. ed</i>. Edited by Simon Emmerson. Harwood Academic Publishers. <a href='https://doi.org/10.4324/9781315077895'>https://doi.org/10.4324/9781315077895</a>.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="wishart_1996"></a>Wishart, Trevor. 1996. <i>On Sonic Art. A new and rev. ed</i>. Edited by Simon Emmerson. Harwood Academic Publishers. <a href='https://doi.org/10.4324/9781315077895'>https://doi.org/10.4324/9781315077895</a>.</p>
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

		
<!-------------------------------- Footnotes List -------------------------------------------->

		
	<hr>
	
	<h3><a name="Footnotes">Footnotes</a></h3>
	
	<p><a name="FN1">1.</a> Some labels used in the Tone Quality Features resemble those used by phoneticians to describe phonemes, the sounds of a language. In particular, aspirate and glottal are terms used to classify phonemes. While there may be some overlap between the terms used here and phonetics (after all, singing may be considered a stylised form of speaking, and therefore may draw on many of the same processes of vocal production), this does not mean that they are synonymous or that tone quality will be determined exclusively by the properties of the phoneme being sung. The potential overlap between the phonetic requirements and the Tone Quality Features will be taken into account in the analyses. Additionally, and in line with the social semiotic approach taken here, analysis is not undertaken at the level of the phoneme but at the level of the word and phrase.<br><a href="#FN1REF">Return to text</a></p><div id="fndiv1" class="flyoverdiv">Some labels used in the Tone Quality Features resemble those used by phoneticians to describe phonemes, the sounds of a language. In particular, aspirate and glottal are terms used to classify phonemes. While there may be some overlap between the terms used here and phonetics (after all, singing may be considered a stylised form of speaking, and therefore may draw on many of the same processes of vocal production), this does not mean that they are synonymous or that tone quality will be determined exclusively by the properties of the phoneme being sung. The potential overlap between the phonetic requirements and the Tone Quality Features will be taken into account in the analyses. Additionally, and in line with the social semiotic approach taken here, analysis is not undertaken at the level of the phoneme but at the level of the word and phrase.</div>	
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- FOOTER -------------------------------------------->

	<hr>
<h3>Copyright Statement</h3>
<p><h4>Copyright &copy; 2022 by the Society for Music Theory. All rights reserved.</h4></p>
<p class="small">[1] Copyrights for individual items published in  <i>Music Theory Online</i> (<i>MTO</i>) 
are held by their authors. Items appearing in  <i>MTO</i> may be saved and stored in electronic or paper form, and may be shared among individuals for purposes of 
scholarly research or discussion, but may  <i>not</i>  be republished in any form, electronic or print, without prior, written permission from the author(s), and advance 
notification of the editors of  <i>MTO.</i></p>
<p class="small">[2] Any redistributed form of items published in  <i>MTO</i> must include the following information in a form appropriate to the medium in which the items are 
to appear: </p>
<blockquote>
<p class="small">This item appeared in  <i>Music Theory Online</i> in [VOLUME #, ISSUE #] on [DAY/MONTH/YEAR]. It was authored by [FULL NAME, EMAIL ADDRESS], with whose written 
permission it is reprinted here.</p>
</blockquote>
<p class="small">[3] Libraries may archive issues of  <i>MTO</i> in electronic or paper form for public access so long as each issue is stored in its entirety, and no access fee 
is charged. Exceptions to these requirements must be approved in writing by the editors of  <i>MTO,</i> who will act in accordance with the decisions of the Society 
for Music Theory. </p>
<p class="small">This document and all portions thereof are protected by U.S. and international copyright laws. Material contained herein may be copied and/or distributed for research 
purposes only. </p>
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

		
		

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 


<div style="width:55%;float:right"><a href="https://societymusictheory.org">
<img alt="SMT" longdesc="Society for Music Theory" src="https://mtosmt.org/gifs/smtlogo_black.png" width="180"></a></div>
	
<div>
<p style='font-size:1.1rem'>Prepared by Fred Hosken, Editorial Assistant  


<br>
		
			<br>Number of visits:  

		6255		
	</p><br><br>
</i>		

</div>
</div>
</article>
</body>
</html>

