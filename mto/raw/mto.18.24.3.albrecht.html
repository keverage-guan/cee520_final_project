 
 

<!-------------------------------- HEADER -------------------------------------------->

      
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> 
<head>

<title> MTO 24.3: Albrecht, Expressive Meaning and the Empirical Analysis of Musical Gesture</title>

<link rel="SHORTCUT ICON" href="https://www.mtosmt.org/gifs/favicon.ico">
<link rel="stylesheet" href="https://www.mtosmt.org/scripts/colorbox.css">
<link rel=StyleSheet href="https://www.mtosmt.org/scripts/mto-tufte.css" type="text/css" media=all>
<link rel="stylesheet" href="//code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

<script src="https://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">_uacct = "UA-968147-1"; urchinTracker();</script>

<script type="text/javascript" src="https://www.mtosmt.org/scripts/expandingMenu.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/dropdownMenu.js"></script>
<!--<script language="JavaScript" type="text/javascript" src="https://www.mtosmt.org/scripts/AC_QuickTime.js"></script>-->
<!--<script type="text/javascript" src="https://www.mtosmt.org/scripts/examples.js"></script>-->
<script type="text/javascript" src="https://www.mtosmt.org/scripts/hover.js"></script>  
<script src="https://code.jquery.com/jquery-1.10.2.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
<script src="https://www.mtosmt.org/scripts/colorbox-master/jquery.colorbox.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/jQueryRotate.2.2.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script>
MathJax.Hub.Config({
    TeX: { noErrors: { disabled: true } }
});
</script>

  <script>
   $(function () {
      $(document).tooltip({
        position: { my: "center bottom-10", at: "center top", },
    content: function () {
              return $(this).prop('title');
          }
      });
  });
  </script>

  <style>
    .ui-tooltip {
      color: #3a3a3a;
      font: 300 14px/20px "Lato", "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
      max-width: 600px;
      box-shadow: 0 0 7px gray;
    }
    ol.mto-alpha {
        list-style: lower-alpha none outside;
    }
   ol.mto-alpha li {
       margin-bottom: 0.75em;
       margin-left: 2em;
       padding-left: 0.5em;
    }
  </style>

    <script language="Javascript">
        $(document).ready(function() {
            $(".mp3").colorbox({iframe:true, internalWidth:360, width:400, internalHeight:100, rel:'mp3', height:150, opacity:0.1, onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });
            $(".youtube").colorbox({iframe:true, innerWidth:640, innerHeight:390, opacity:0.1, rel:'youtube', onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });

      $("a[id^=footnote]").each(function(){
        var fnnum = $(this).attr('id').substring(8);
	var foot_me = '#fndiv'+fnnum;
        $("#footnote" + fnnum).attr('title', $(foot_me).html());

        });


        $("a[id^=citation]").each(function(){
         var separatorPos = $(this).attr('id').lastIndexOf('_');
         var linkid = $(this).attr('id');
         var citeref = $(this).attr('id').substring(8,separatorPos);
         var cite_me = '#citediv'+citeref;
         $("#" + linkid).attr('title', $(cite_me).html());

        });
    });

    </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-968147-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-968147-1');
</script>


<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 

<meta name="citation_title" content="Expressive Meaning and the Empirical Analysis of Musical Gesture: The Progressive Exposure Method and the Second Movement of Beethoven&#8217;s <i>Path&eacute;tique</i> Sonata">

    <meta name="citation_author" content="D., Albrecht, Joshua">
      
<meta name="citation_publication_date" content="2018/09/01">
<meta name="citation_journal_title" content="Music Theory Online">
<meta name="citation_volume" content="24">
<meta name="citation_issue" content="3">

</head>

<body>
<div class="bannertop">
	<a id="smt-link" alt="Society for Music Theory" href="https://www.societymusictheory.org">&nbsp;</a>
</div>
		
		<div style = "height:160px; width:900px; background-image: url('../../gifs/banner_blue_grey_900px.png'); background-repeat: no-repeat; background-position: 0px 0px"></div>
		
<!-------------------------------- MENU -------------------------------------------->

    
<div class="dropdown_menu">

<ul class="fullwidth" id="ddm">
    <li><a href="https://www.mtosmt.org/index.php">MTO Home</a>
    </li>
    <li><a href="https://www.mtosmt.org/issues/mto.24.30.4/toc.30.4.html">Current Issue</a>    </li>
    <li><a href="https://www.mtosmt.org/issues/issues.php"
    	onmouseover="mopen('m3')" 
        onmouseout="mclosetime()">Previous Issues</a>
        <div id="m3" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/index-author.php">By Author</a>
	        <a href="https://www.mtosmt.org/issues/issues.php">By Volume&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
	</li>
	
    <li><a href="https://www.mtosmt.org/docs/authors.html.php"
    	onmouseover="mopen('m4')" 
        onmouseout="mclosetime()">For Authors</a>
        <div id="m4" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/mto-editorial-policy.html">MTO Editorial Policy</a>
	      <a href="https://www.mtosmt.org/docs/mto-style-guidelines.html">MTO Style Guidelines</a>
	      <a href="https://www.mtosmt.org/docs/how-to-submit-an-article-to-mto.html">How to Submit an Article</a>
	      <a href="https://www.mtosmt.org/ojs">Submit Article Online</a>
	      <a href="https://www.mtosmt.org/docs/reviewers.html">Book Review Guidelines</a>
        </div>
	</li>

 <!--   <li><a href="https://www.mtosmt.org/docs/authors.html">Submit</a>
	</li> -->
	
    <li><a href="https://www.mtosmt.org/mto-jobs.php"
    	onmouseover="mopen('m6')" 
        onmouseout="mclosetime()">Jobs</a>
        <div id="m6" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/mto-jobs.php">Current Job Listings</a>
	        <a href="https://www.mtosmt.org/mto-job-post.php">Submit Job Listing</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/docs/diss-index.php"
    	onmouseover="mopen('m7')" 
        onmouseout="mclosetime()">Dissertations</a>
        <div id="m7" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/diss-index.php">All Dissertations</a>
	        <a href="https://www.mtosmt.org/docs/diss-index.php?new=true">New Dissertations</a>
	        <a href="https://www.mtosmt.org/mto-diss-post.php">List Your Dissertation</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/about.html">About</a>
	</li>
<!--    <li><a href="https://www.mtosmt.org/mto_links.html">Journals</a>  
	</li> -->
    <li><a href="https://societymusictheory.org">SMT</a>
	</li>
   <!-- <li><a href="https://societymusictheory.org/announcement/contest-new-mto-logo-2024-02"><span style="color:yellow">Logo Design Contest</span></a>
	</li>-->

</ul>

</div>


<!-------------------------------- TITLE -------------------------------------------->

    <article>

<div id="content">
<a name="Beginning"></a>
			
	<h1 style="width:900px; margin-top:1em">Expressive Meaning and the Empirical Analysis of Musical Gesture: The Progressive Exposure Method and the Second Movement of Beethoven&#8217;s <i>Path&eacute;tique</i> Sonata<sup><a name="FN0REF" href="#FN0" id="footnote0">*</a></sup> </h1>
	<div style="width:900px">
				</div>

	
				<h2><span style="font-weight: 400"><font size="5"><a style="color:black" href="#AUTHORNOTE1">Albrecht, Joshua D.</a></font></span></h2><br><br><p><font size='4'>KEYWORDS: emotion, expression, meaning, gesture, topics, empirical, Beethoven, <i>Path&eacute;tique</i> Sonata, progressive exposure method</font></p><p><font size='4'>ABSTRACT: Many investigations of the expressive meaning of musical works rely only on the musical interpretations and intuitions of the author. While invaluable, theorists&#8217; analyses are often biased or contradict one another. This paper presents a novel empirical approach to analyzing musical expression, in which the interpretations of individual theorists are balanced with listener reception in a broader audience, in this case a group of 110 music students from two universities. This new paradigm, which I have termed &ldquo;the progressive exposure method,&rdquo; presents a larger excerpt in shorter discrete segments. An exploratory case study illustrates the progressive exposure method through an analysis of the expressive meaning of the second movement of Beethoven&#8217;s <i>Path&eacute;tique </i>Sonata. When the results are amalgamated, a diachronic portrait emerges of cognitively complex emotions blended together as they unfold throughout the movement. This article provides readers with a <a target='_new' href='http://societymusictheory.org:3838/Albrecht_24.3/'>hands-on, interactive tool</a> for examining all of the results of the study. By presenting short musical gestures to listeners, a bottom-up, data-driven analysis of the expressive meaning of musical gestures and topics in the movement is possible. The consequent analytical results intersect in unique ways with more traditional theoretical and analytical practices, illustrating original applications of empirical methods to existing theories of musical expression as a means of providing converging evidence for those theories. Specifically, the results of this intersubjective analysis are discussed in light of theories of musical meaning by Hatten, Meyer, Narmour, Huron, and Margulis, and the results provide a new opportunity to directly and empirically testing a number of these authors&#8217; hypotheses.</font></p><p><small>DOI: 10.30535/mto.24.3.1</small></p>			
	<div style='width:800px'><div style='float:right; font-size:1.2rem;'><a href="http://mtosmt.org/issues/mto.18.24.3/mto.18.24.3.albrecht.pdf">PDF text </a> | <a href="http://mtosmt.org/issues/mto.18.24.3/albrecht_examples.pdf">PDF examples </a></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div>
			<div style="float:left; font-size:1.1rem;"><i>Received April 2018</i></div>
		<div style="width:850px">
	<div style="text-align:center; font-size: 1.1rem; margin-bottom:2em;margin-top:4em;margin-right:auto;margin-left:auto;width:870px">
		Volume 24, Number 3, September 2018 <br> Copyright &#0169; 2018 Society for Music Theory	</div>
	</div>

<hr style="width:850px"><br>
<section>
<!------------------------------- ARTICLE BODY (begin) -------------------------------------->


<h2>A Sample Expressive Analysis and the Problem of Intersubjectivity</h2>

<p>[1.1] In his review of recent developments in topic theory, Nicholas McKay (<a href="#mckay_2007" id="citation_mckay_2007_67dc99ab85e03">2007</a>, 159) states that, &#8220;formal analysis is, by its very nature, disinclined towards&#8212;if not incapable of&#8212;reading expressive intentions encoded in music&#8217;s gestures or voices.&#8221; While the point may be overstated, it is certainly the case that in the era of music theory as an academic discipline most formal analysis has not focused on decoding the expressive meanings of the music it analyzes. Why should this be? One of music&#8217;s most immediate characteristics is its ability to express emotion, an attribute of music recognized by the entire spectrum of listeners, whether musically trained or not. Juslin and Laukka (<a href="#juslin_and_laukka_2004" id="citation_juslin_and_laukka_2004_67dc99ab85e0b">2004</a>), in a survey of 141 listeners, report that a remarkable 100% of respondents believed that music can express emotion, with 76% of listeners reporting that they believed music expressed emotions often. Similarly, one of the most commonly stated goals professional musicians have in pursuing a career in music is to provide &#8220;a means to generate positive emotional experiences mostly for one&#8217;s own satisfaction&#8221; (<a href="#persson_2001" id="citation_persson_2001_67dc99ab85e10">Persson 2001</a>, 277). Not only are analysts who ignore the expressive meaning of music in danger of misrepresenting the experience of listening to music and so doing a disservice to their readers, but they also are in danger of telling incomplete stories about the music they analyze.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 1</b>. Measures 29&ndash;44 of Beethoven <i>Path&eacute;tique</i> Sonata, II</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=0&nonav=true"><img border="1" alt="Example 1 thumbnail" src="albrecht_ex1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[1.2] Emotional expression is not a central goal for all styles of music. For some music, however, to ignore its expressive meaning is to miss a big part of what makes it work. Consider, for example, Beethoven&#8217;s <i>Path&eacute;tique</i> Sonata, a work that stands out from Beethoven&#8217;s other early piano sonatas, both for being a uniquely powerful example of musical <i>pathos</i> and for formal and harmonic innovation.<sup><a name="FN1REF" href="#FN1" id="footnote1">(1)</a></sup> The expressive power of the sonata was immediately recognized by its contemporaries and it has remained a perennial favorite. <b>Example 1</b> shows mm. 29&#8211;44 from the second movement, including the rondo&#8217;s second refrain, the beginning of the second episode, and a modulation to the key of the episode&#8217;s submediant. What might an analysis of the expressive meaning of this excerpt look like?</p>

<p>[1.3] First, I hear the refrain as a lovely, bittersweet melody supported by a gently rocking accompaniment. Set in an unchanging <i>piano</i> dynamic and centered around middle C, the melody is serene and contemplative on the surface. I find that one of the most noteworthy elements of the melody is the persistent use of cross-barline leaps. Beyond simply suggesting compound melody, the leaps seem to me to carry poignant expressive overtones, regularly opening up sudden space, both literally and expressively. As one example, the tritone descending leap of m. 35 rends the otherwise calm final descent of the refrain with a discordant note of longing, capped off by a delayed resolution on the downbeat of m. 37. The hint of unrest signaled in the refrain surfaces instantly in the second episode. The calm <nobr><span style= 'letter-spacing:-1px'>A<span style='font-family: Arial Unicode MS, Lucida Sans Unicode;'>&#x266d;</span><span></nobr> major is immediately displaced by the marked parallel minor, while the rhythm also immediately intensifies by replacing the gentle rocking accompaniment with agitated repeated triplet-sixteenth notes. Moreover, the rich texture thins out and is coupled with a higher tessitura, marked with a drop to an even quieter <i>pianissimo</i>, the combination of which signifies to my ear that the now explicit grief is being forcefully bottled up.</p>

<p>[1.4] Although the anguished melodic tritone reappears in mm. 38, this time it is answered by a distinctly new voice with a different character counterpointed agaiperfect nst it in the bass&#8212;one that almost bounces in a staccato-like way with a playful chromatic-lower neighbor before counteracting the soprano&#8217;s upward tritone leap with an upward fourth. The right hand&#8217;s plaintive melody sounds again, but this time without the upward tritone leap, followed by a modified answer in the left hand. The transformation of the melody is coupled with a thickening of the texture, punctuated with dramatic <i>szforzandi</i>, in what I hear as a victorious transformation. While the agitated triplets continue, the harmonies outline a string of applied dominant seventh chords, resulting in a strong modulation to the submediant (notated as &#8220;E major&#8221; in the score). Cumulatively, I hear this episode as expressing a quiet internalized grief being discovered and shared by a second voice and then transformed through that experience into a glorious resolution. The exultation of the cadential arrival is, however, colored by the agitation of the muddy texture and insistent triplet rhythm.</p>

<p>[1.5] What is the value of this kind of expressive analysis of the music&#8217;s structures? Although often written with feints toward objective language, it is important to remember that expressive analyses typically reflect one person&#8217;s interpretation of the music&#8217;s expressive meaning. There are always many ways one might analyze a particular musical piece, even with more &#8220;objective&#8221; elements of musical structure, and it is not hard to find a spectrum of perspectives and strong disagreements about the same music. Even if there is nearly universal agreement that this music is emotionally expressive, one might imagine the problem of analytical consensus would be even greater when discussing what exactly the expressive meaning of this music is. After all, what right do I have to make claims about how others might hear the expressive meaning of this piece?</p>

<p>[1.6] Ultimately, any analysis should serve the music, both capturing aspects of how the reader already hears the music and opening up viable new paths for understanding it. One useful metric for evaluating the contribution of an analysis is the degree to which it is consistent with a communally defined sense of musical meaning, either retrospectively or prospectively (or both). Appealing to a communally defined sense of meaning has been the approach of most recent analytical approaches to expressive meaning, evident in those writers loosely comprising topic theory and narrative theory. The typical approach is to argue that the interpretations given are essentially intersubjective in nature, meaning that <i>historically informed</i> audiences would generally perceive the meanings outlined in the analysis.</p>

<p>[1.7] For example, Hatten (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab85f4e">2004</a>, 6) defends his analyses of the expressive meaning of musical gestures and topics by saying that, &#8220;in the face of postmodernism, I maintain that the &lsquo;aesthetic&rsquo; is no illusion.&nbsp;.&nbsp;.&nbsp;. I maintain that we still have access to <i>relatively objective</i> (by which I mean <i>intersubjectively defensible</i>) historical meanings.&#8221; Allanbrook (<a href="#allanbrook_1986" id="citation_allanbrook_1986_67dc99ab85f51">1986</a>, 2&ndash;3) also argues that analysts can identify specific expressive meanings of musical structures shared by typical listeners: &#8220;[Composers were] in possession of something we can call an expressive vocabulary .&nbsp;.&nbsp;. [that] provides a tool for analysis which can mediate between the [works] and our individual responses to them.&nbsp;.&nbsp;.&nbsp;. By recognizing a characteristic style, [the analyst] can identify a configuration of notes and rhythms as having a particular stance.&nbsp;.&nbsp;.&nbsp;. In short he [<i>sic</i>] can articulate within certain limits the shared response a particular passage will evoke.&#8221; This tactic represents the most common strategy, either explicit or implicit, in defending assessments of the emotional meanings of the identified gestures as intersubjectively defensible, or broadly agreed upon by listeners competent in the style.</p>

<p>[1.8] Appeals to intersubjective meaning notwithstanding, expressive analyses are typically still the product of one person generalizing their impressions of the music&#8217;s expressive meanings to some vague notion of &#8220;intersubjectivity.&#8221; However convincing an analysis is, it is inherently problematic for a single writer to claim that their views reflect a truly intersubjective understanding of a work. By definition, any &#8220;intersubjective&#8221; analysis is going to involve a group of subjects and a common stimulus. When contemporary music theorists make intersubjective claims, they tend to be arguing that their analysis approximates the experience&#8212;or potential experience&#8212;of some group of contemporary musically sophisticated listeners.</p>

<p>[1.9] In this article, I will treat the question of intersubjective evaluations of expressive meaning of music directly. Rather than trying to argue abstractly that my expressive reading of the second movement of Beethoven&#8217;s <i>Path&eacute;tique</i> Sonata must reflect some notion of intersubjective perception, I will create an analysis that is literally inter-subject generated. My approach will approximate the community of &#8220;musically sophisticated listeners&#8221; by recruiting over one-hundred undergraduate music majors. By collecting the pertinent data about how listeners perceive the emotional meaning of this work, I can sidestep the philosophically difficult task of logically defending my perceptions as reflective of a broad community and instead let the data generate a bottom-up picture of intersubjective expressive meaning in the movement.</p>

<p>[1.10] My method will be centered around a novel approach I call the <i>progressive exposure method</i>, in which listeners progressively hear and rate the emotional expression of short excerpts from the movement. Although my interest is in examining the expressive meaning of musical gestures, my methodology attempts to remain neutral by minimizing assumptions about what constitutes relevant gestures before analysis. Automatically slicing the recording up into short segments allows both for the relative isolation of musical gestures, and for the data themselves to suggest what the relevant gestures are in a bottom-up manner. I have chosen to present the excerpts in random order in this study to eliminate maturation and fatigue effects. Data collected are then amalgamated into a diachronic portrait, in which individual observations are stitched together to build one narrative analysis tracing unfolding emotions over the course of the movement.  The literal multi-subject analysis is then compared to the above analysis, along with other analyses produced by several contemporary theorists.</p>

<p>[1.11] Intersubjectively analyzing the movement using an empirical methodology also provides new opportunities for testing longstanding theories of musical expression.<sup><a name="FN2REF" href="#FN2" id="footnote2">(2)</a></sup> Many of these theoretical claims take the form of hypotheses that could, in principle, be tested empirically. Relatively recent developments in statistics, methodology, and computing now make it possible to test claims that have historically remained untested. At the same time, it is important to remember that empirical tests do not essentialize theoretical claims, as if some empirical test of data in an isolated study could somehow be said to &#8220;verify&#8221; or &#8220;refute&#8221; a theory. Collecting a database of expressive evaluations of the movement, however, provides the ability to put theoretical ideas in dialogue with listener perceptions in an empirical domain to look for converging evidence. I will use the data to directly test a number of hypotheses from the theories of Meyer (<a href="#meyer_1956" id="citation_meyer_1956_67dc99ab85f63">1956</a>), Hatten (<a href="#hatten_1994" id="citation_hatten_1994_67dc99ab85f65">1994</a>, <a href="#hatten_2004" id="citation_hatten_2004_67dc99ab85f67">2004</a>), Narmour (<a href="#narmour_1990" id="citation_narmour_1990_67dc99ab85f68">1990</a>, <a href="#narmour_1992" id="citation_narmour_1992_67dc99ab85f6a">1992</a>), Huron (<a href="#huron_2006" id="citation_huron_2006_67dc99ab85f6c">2006</a>), and Margulis (<a href="#margulis_2013" id="citation_margulis_2013_67dc99ab85f6e">2013</a>). A number of hypotheses from these theories will be directly tested.</p>


<h2>Methodological considerations</h2>

<p>[2.1] Before exploring the method and results of the study, I would like to examine some of the methodological issues underlying any empirical investigation of expressive meaning in music.<sup><a name="FN3REF" href="#FN3" id="footnote3">(3)</a></sup> One question revolves around the distinction between emotions <i>induced,</i> or personally felt in the listener in response to the music, and emotions <i>perceived</i> by the listener, or recognized as expressed by the music. In many circumstances, we might imagine these emotions are fairly similar. However, this may not always be the case. For example, a listener might perceive a particular song as expressing happiness, but if the song is associated with negative autobiographical memories (perhaps connected to a failed relationship), it may evoke sadness in the listener. It is even possible that the distance between perceived and felt emotion may influence the degree to which music is heard as ironic or sarcastic.</p>

<p>[2.2] Although both induced and perceived emotion are important elements of musical expression, there are significant differences between them.<sup><a name="FN4REF" href="#FN4" id="footnote4">(4)</a></sup> For the purposes of this study, therefore, I will focus on perceived emotion.<sup><a name="FN5REF" href="#FN5" id="footnote5">(5)</a></sup> This is not to deny that felt emotion is an important component of the experience and likely influences perceived emotion. Rather, this is a pragmatic consideration; my goal is to try as much as possible to isolate the question under study and avoid skewing the results with other confounding factors. Also, because the study was conducted in a laboratory environment, it is likely that listeners&#8217; felt emotions in response to music were significantly reduced.</p>

<p>[2.3] For this study, I developed a new measurement paradigm called the <i>progressive exposure method</i>. In this paradigm, a long excerpt is divided into discrete segments. The segments used in the progressive exposure method can be of any duration deemed appropriate by the researcher; segment lengths should be long enough for participants to be able to make a judgment about the emotion of the segment, but short enough to not host several dramatic changes of emotion. For this study, I was interested in the expressive implications of short musical gestures, and how various different musical parameters are combined in different segments to create emergent meaning.<sup><a name="FN6REF" href="#FN6" id="footnote6">(6)</a></sup> For the second movement of Beethoven&#8217;s <i>Path&eacute;tique</i>, five-second segments seemed to be about the right length to capture most gestures, including a little bit of musical context, without incorporating too many different gestures in the same segment.</p>

<p>[2.4] Another relevant concern for empirical studies that involve listening to music is the selection of a recording. There are a large number of commercially available recordings of the <i>Path&eacute;tique</i> Sonata, raising the question of which recording to select.  While the interpretive decisions performers make in encoding emotional expression is a worthwhile topic of study, recall that the focus of this study is on listeners&rsquo; perception of expressive meaning.<sup><a name="FN7REF" href="#FN7" id="footnote7">(7)</a></sup> One way to normalize the effect of performance would be to use a computer to generate a MIDI performance. However, the result would be a mechanical realization of the work with greatly reduced expressive potential. A better approach would be to select an interpretation that is not &#8220;extreme&#8221; in its realization; a recording that reflects the interpretive decisions of a large proportion of the performers of a work might represent a sort of &#8220;mean&#8221; of the &#8220;population&#8221; of recordings.<sup><a name="FN8REF" href="#FN8" id="footnote8">(8)</a></sup> To choose a recording that was not too extreme in interpretation, two trained researchers were given instructions to independently listen to each of the recordings of the movement on compact disc in music library of the Ohio State University, a total of 23 recordings, and select some that seemed average in its expressive decisions. Once these selections were made, the researchers came to a mutual conclusion about which was most average.</p>


<p>[2.5] The selected performance was by John O&#8217;Conor and appeared on the album <i>Breathe<sup>&reg;</sup>: relaxing piano for lovers</i> (<a href="#o&#8217;conor_2008" id="citation_o&#8217;conor_2008_67dc99ab85f7d">O&#8217;Conor 2008</a>). As an aside, it is noteworthy that the most middle-of-the-road performance would be from a CD compilation of the type that proliferated during the first decade of the twenty-first century, in which the most marketed feature of the music is not the composer or performer, but on how useful the music is for creating some sort of non-musical social effect. The length of the recording was 4&#8217;47&#8221;. As mentioned above, this recording was divided into five-second segments for use with the progressive exposure method. To avoid abrupt onsets and offsets, a 500 ms fade-in and fade-out were applied to each segment, and to mitigate the effect of arbitrary boundaries, two collections of segments were generated. The first used a 0&#8221; offset and the second used a 2.5&#8221; offset. Even though the segments were 5&#8221; in length, this approach allows for a dovetailed 2.5&#8221; resolution of data, providing a more detailed examination of how emotion unfolds throughout the movement, and allowing every 2.5&#8221; of the movement to be heard in two different excerpts.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table 1</b>. Fifteen emotion terms derived from a content analysis of 592 discrete comments (totaling 453 of the 592 comments), along with the number or responses that were classified as belonging to each category in parentheses</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=1&nonav=true"><img border="1" alt="Table 1 thumbnail" src="albrecht_tab1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[2.6] Finally, any empirical study of musical emotion must settle on a choice of emotion categories to examine. Empirical music emotion studies tend to use one of only a few approaches to selecting emotion terms.<sup><a name="FN9REF" href="#FN9" id="footnote9">(9)</a></sup> Rather than using any of the existing approaches wholesale, or relying on my own intuitions of musical emotion categories and risk jeopardizing the intersubjective nature of my investigation, I opted to use an empirical approach to developing a list of discrete emotion terms. I recruited four doctoral students in music theory and music composition and one applied music professor from Ohio State University&#8217;s music department to listen to a selection of five-second excerpts from the movement and freely describe what emotions they thought the passage expressed. To encourage the participants to speak at length, they spoke freely while I recorded their comments on a laptop. The free responses of the five participants were divided into discrete comments, resulting in 592 discrete comments. These comments were subjected to an informal content analysis by two independent researchers, who grouped comments together that were similar and provided each group with a label descriptive of the contents of the group. Categories with similar labels between the two researchers were combined, and categories with similar content but different labels were amalgamated. A number of additional categories were discarded, because they either had small representation or the comments referred more to musical structures than to emotion. The resulting fifteen emotion categories are shown in <b>Table 1</b>, along with how many discrete comments were considered to fit into each category. Several comments could not easily be grouped, but the table reflects 453 out of 592 comments (77%). While many terms common to music and emotion studies were included, such as happy/joyful, sad/depressed/tragic, or calm/serene, there were also a number of terms that are less commonly tested. Dark, weighty, carefree, and striving/yearning are all infrequently used terms but were deemed to be reflective of the expressive content of the movement. These fifteen terms were used in the analysis of expressive meaning in the movement.</p>

<h2>Empirical Study of Expressive Meaning</h2>

<h3>Some Preliminary Detail</h3>

<p>[3.1] Using these fifteen emotion terms (Table 1), an intersubjective empirical study was conducted using the progressive exposure method to capture a diachronic portrait of perceived emotional expression in the second movement of the <i>Path&eacute;tique</i> Sonata. I recruited 110 participants, 51 undergraduate music majors from the participant pool at Ohio State University, and 59 undergraduate music majors from Westminster Choir College. The mean age for participants was 22.1 years (standard deviation [sd] = 6.4), and the mean number of years of musical training was 14.3 (sd = 6.2). The recordings used were 112 five-second segments in two offset groups of 56 each (0&#8221; and 2.5&#8221;) spanning the entire duration of the 4&#8217;47&#8221; John O&#8217;Conor recording. Participants were assigned randomly to one of the two offset groups.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 2</b>. A screenshot of  the interface used in the empirical study. Participants listened to each segment first and then adjusted the slider for each of the three emotion categories assigned</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=2&nonav=true"><img border="1" alt="Example 2 thumbnail" src="albrecht_ex2_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[3.2] Participants listened to all 56 five-second segments from their offset group in random order and rated the extent to which each excerpt &#8220;conveyed or expressed&#8221; each of the fifteen emotion categories.<sup><a name="FN10REF" href="#FN10" id="footnote10">(10)</a></sup> Additionally, participants heard five randomly selected segments a second time as a test for within-participant reliability, resulting in 61 total excerpts per participant. Unfortunately, the task was too long for one participant, so the fifteen emotion categories were divided into five groups of three emotions each. Participants were randomly assigned to one of the five emotion groups. An example of the interface is given in <b>Example 2</b>.</p>

<h3>Intersubjective reliability</h3>

<p>[4.1] In order to evaluate the expressive ratings of the various participants as a group of listeners, some way of assessing all of the responses as roughly equivalent is needed. This is typically accomplished through averaging responses. One criticism of this kind of empirical analysis of expressive meaning might be that listeners experience music in highly personalized ways, and so it is overly reductionistic or misleading to average results together, or that personal judgments are themselves unreliable. Before averaging together the intersubjective data gathered from the affective analysis, it is helpful to ask the more fundamental question: To what extent does a community of listeners actually agree about the expressive meaning of this movement? To test the degree to which participants were personally consistent (intra-participant reliability) and the degree to which all participants provided similar responses (inter-participant reliability), a fairly in-depth analysis of reliability metrics was conducted on the responses. To summarize the findings in the Appendix, although there was naturally some variation in the responses, participants were widely consistent in evaluating the expressive meaning of the segments, lending confidence to considering the responses collected as part of a shared response from a community of listeners. A full description of the results from the reliability tests can be found in the <a href="#appendix">Appendix</a>.</p>

<p>[4.2] However, not all expressive categories were equally reliable. As a result of this assessment, four emotion categories were discarded from further analysis. In the first case, cheeky/sassy was deemed not appropriate for this movement.<sup><a name="FN11REF" href="#FN11" id="footnote11">(11)</a></sup> Secondly, sincerity/truthful, important/serious, and emotional/moody all provided low measures of within- and between-participant reliability. Post-experiment interviews suggested that these three compound affective categories were either not well defined and confusing to participants, or combined two different emotion categories that resulted in different strategies from different participants. Moreover, many of these categories were expressively neutral, and so might have been treated differently by different participants.<sup><a name="FN12REF" href="#FN12" id="footnote12">(12)</a></sup> Again, further details can be found in the <a href="#appendix">Appendix</a>.</p>

<h3>Sample expressive analysis</h3>

<p>[5.1] In order to examine how the community of participants understood the expressive meaning of the movement, an intersubjective analysis of the movement was conducted. Individual responses were amalgamated and averaged to form a diachronic portrait depicting ways in which each emotion unfolds over the course of the movement. For the purposes of analysis, the data were normalized across subject-scale, by measuring responses in terms of standard deviations away from the mean for that emotional category for that participant. This decision was made to compensate for differences in the ways that different participants might use the scale, and for differences in the ways the scale is used for each category.<sup><a name="FN13REF" href="#FN13" id="footnote13">(13)</a></sup> High ratings for an emotion are not absolutely high, but high in relation to other segments for that emotion.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 3</b>. Expressive analysis of mm. 34&ndash;44 of Beethoven&rsquo;s <i>Path&eacute;tique</i> Sonata, second movement</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=3&nonav=true"><img border="1" alt="Example 3 thumbnail" src="albrecht_ex3_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[5.2] The entire set of participant evaluation data in the study is accessible through the provided <a target="_new" href="http://societymusictheory.org:3838/Albrecht_24.3/">interactive tool</a>. A static image corresponding to the following discussion, for those who do not wish to use the tool, is provided in <b>Example 3</b>, which combines elements from the single emotion and multiple emotions explorer.<sup><a name="FN14REF" href="#FN14" id="footnote14">(14)</a></sup> To investigate individual emotion ratings, select the &#8220;single emotion explorer&#8221; and choose the emotion category you are interested in. In this display, scores are represented as normalized, or as standard deviations from the mean, so 0 is the average rating for that emotion and +1 is one standard deviation higher than the average for that emotion. Each box represents ratings for the segment heard directly under the box, which can be heard by clicking on the boxplot. The median of the responses for each segment is displayed as the line in the middle of the box. The box itself encompasses 50% of the responses, and the lines that extend beyond the box show the entire range of scores, with any statistical outliers shown as points outside of the lines. Connecting orange lines show the mean rating for each segment. To explore several emotion categories, click on the &#8220;multiple emotions explorer.&#8221; Here, you can select whichever emotion categories you are interested in comparing. Connecting lines show the mean rating for each segment. Upon opening the <a target="_new" href="http://societymusictheory.org:3838/Albrecht_24.3/">interactive tool</a>, the excerpt spanning mm. 34&#8211;44 is highlighted, which mirrors most of the excerpt reproduced in Example 1, although the range of the excerpt displayed can be controlled through changing the values of the slider. You can listen to any of the 5&#8221; segments by clicking on its data point on the graph, or the entire excerpt displayed by clicking on &#8220;Play Excerpt.&#8221; To start, only six of the eleven emotion categories are displayed.</p>

<p>[5.3] One benefit of the progressive exposure method is the opportunity to track how the interleaved data connect to trace the development of any emotion category over the course of the excerpt. However, because the data are still discrete (rather than continuous), it is possible to examine exactly which surface features or musical gestures are correlated with these expressive changes. For example, notice that the ratings for unsettled/anxious show a local peak corresponding to the suspension on the downbeat of measure 36. When the suspension is resolved, unsettled/anxious ratings decrease, consistent with traditional notions of the emotional effect of suspension figures. The same localized peak occurs simultaneously for weighty, sad/depressed/tragic, and suspense/anticipation, not shown in this example.</p>

<p>[5.4] At measure 37, when the music moves directly to the parallel minor, the texture thins considerably, the tessitura moves higher, and the rhythm gets noticeably faster with driving and repetitive triplet-sixteenth notes, all of the positively valenced expressive categories decrease while ratings for dark and unsettled/anxious increase.<sup><a name="FN15REF" href="#FN15" id="footnote15">(15)</a></sup> Notice, however, that lonely ratings do not significantly change at measure 37, indicating that these changes to the musical surface do not strongly influence that dimension, perhaps because other musical dimensions may counterbalance the effect of mode on lonely ratings. The musical gesture that <i>is</i> correlated with a change to lonely ratings, however, involves a second voice in a different range with different character (more staccato) entering the texture at measure 38 and again at measure 40.<sup><a name="FN16REF" href="#FN16" id="footnote16">(16)</a></sup></p>

<p>[5.5] Finally, consider the end of this passage. At this point, the texture thickens substantially as four-note chords low in the left hand produce a muddier texture. At the same time, the register opens up, the agitated rhythms continue, and the harmony shifts to the major mode through a string of applied harmonies. This move is highlighted by a series of punctuated <i>sforzandi</i>, accenting the contrast. Notice, consistent with traditional associations of mode, that happy/joyful and contentment ratings increase significantly with the modulation while lonely and dark ratings decrease. Tellingly, calm/serene ratings, which had been highly correlated with happy/joyful ratings to this point, continue to remain low while unsettled/anxious ratings remain relatively high. This can likely be explained by the persistence of the triplet-sixteenth notes and the loud <i>sforzandi</i>. Despite the modulation to the major mode, carefree ratings (not pictured in Example 3) also remain below average in this excerpt, consistent with a general trend throughout the movement for significantly lower carefree ratings for passages with triplet-sixteenth rhythms rather than sixteenth notes.<sup><a name="FN17REF" href="#FN17" id="footnote17">(17)</a></sup></p>

<p>[5.6] The intersubjective expressive analysis for this excerpt interacts with my own intuitions about the movement (paragraphs [1.3-1.5]) in interesting ways. At a basic level, the data map squarely onto traditional expressive connotations of mode. The refrain and the modulation to the submediant elicits higher positive emotions and lower negative emotions than the beginning of the episode, and vice versa. The refrain exhibits high levels of contentment and calm/serene ratings, but also shows high ratings for lonely and dark, consistent with my perception of an uneasy, bittersweet mixture of emotions&#8212;a surface calm with darker undertones. However, my perception that the otherwise calm descent was interrupted by the descending tritone leap in m. 35 does not receive any support from the data. The explicit unrest of the episode, on the other hand, signaled by the increase of rhythmic motion and persistent repetitions is clearly reflected in the precipitous rise in unsettled/anxious ratings and drop in calm/serene ratings. Likewise, my perception of the new &#8216;voice&#8217; entering the texture in m. 38 and 40 is mirrored by a corresponding drop in lonely ratings. Another benefit of using this sort of approach is the way in which expressive categories can blend together to create subtle mixtures of emotional expression.<sup><a name="FN18REF" href="#FN18" id="footnote18">(18)</a></sup> In addition to the complex bittersweet nature of the refrain, another potent example of complex emotional blending comes at the end of the excerpt (mm. 42&#8211;44). This passage was analyzed as expressing high levels of happy/joyful and calm/serene at the same time as it elicits high lonely ratings, perhaps suggesting a complex expressive mix that is happy but still unsettled&#8212;perhaps a sort of edgy, manic happiness.</p>

<h3>Parallel passages</h3>

<p>[6.1] This movement of the <i>Path&eacute;tique</i> provides a unique opportunity to investigate the effect of parallel musical passages with a fairly high degree of ecological validity.<sup><a name="FN19REF" href="#FN19" id="footnote19">(19)</a></sup> While the progressive exposure method is not like a real listening environment in its presentation of unordered short segments, it nevertheless presents a sort of imperfect middle ground between the two goals of experimental control and ecological validity. In this rondo movement, the theme returns four times after the initial presentation. However, each time the theme returns, there are slight variations. While almost all of the musical parameters remain the same (melodic contour, harmonic progression, rhythmic and melodic accent patterns, etc.), slight compositional differences permit the analysis of the effect of small changes to one or two parameters in real musical situations. For example, the second statement of the theme is the same as the first with only minor exceptions: the melody is transposed up one octave and there is a slightly thicker texture with the addition of an extra inner voice. The fourth statement of the theme returns to the original melodic tessitura, but uses the faster sixteenth-triplet accompaniment. In the final statement of the theme, the higher register, thicker texture, and faster accompaniment are combined. By collapsing all ratings for any given emotional dimension across each statement, direct comparisons can be made between the refrains and hypotheses can be tested.</p>

<p>[6.2] The third statement of the theme even offers a sort of &#8220;control group&#8221; of segments by repeating the first statement exactly. In a real listening environment, repetition is always musically significant, even if repeated material is exactly the same as earlier material.<sup><a name="FN20REF" href="#FN20" id="footnote20">(20)</a></sup> In this study, however, each five-second segment is played in random order. The result of random ordering is that participants have little ability to tell from where in the movement a given segment is derived. Therefore, the exact repetition of the original theme serves as a sort of control group, and the expectation is that there will be no statistically significant differences between ratings for the first and third statements of the theme.</p>

<p>[6.3] In her book on repetition in music, Margulis (<a href="#margulis_2013" id="citation_margulis_2013_67dc99ab85fc3">2013</a>, 173) wonders: &#8220;Are repetitions of the theme in a rondo, for example, expressively cumulative, such that later iterations assume a memory not only for the theme, but also for its performance the first time around?&#8221; Because this study&#8217;s methodology explicitly scrambles segment order, there is an interesting way of approaching this question. Ordering can refer to three different things: 1) The way that Beethoven encoded ordering effects into his composition; e.g., refrain 5 is clearly composed differently than refrain 1. 2) The way that O&#8217;Conor encoded ordering effects into his performance; refrain 1 and refrain 3 are technically literal repeats compositionally, but because refrain 3 was performed after refrain 1, O&#8217;Conor may have performed with different types of microtiming and microdymanic subtleties. 3) The way that listeners hear the music sequentially; even were the movement to be performed precisely by a computer, we would expect refrain 3 to be heard slightly differently from refrain 1, in consequence of its position after episode 1. In most empirical studies, it is completely impossible to disentangle the effects of the above three ordering effects, because participants hear the music in real time. Consequently, it is difficult to know the extent to which participants&#8217; hearing of the music is influenced by temporality; it may be that listeners always perceive music as more intense emotionally because they expect a dramatic progression, or it may be that listeners always level off their emotional intensity due to the limitations of attention spans. Because excerpts are heard in random order, this study effectively eliminates listening order and tests only compositional and performative ordering. In a sense, we might say that the random ordering of the progressive exposure method allows for a more controlled examination of compositional and performative decisions of ordering.</p>

<p>[6.4] Other theorists&#8217; analyses of the emotional qualities of this movement can also be tested. For example, Hatten (<a href="#hatten_1994" id="citation_hatten_1994_67dc99ab85fc5">1994</a>, 207) claims this movement is associated with &#8220;assurance or reassurance&#8221; and Sisman (<a href="#sisman_1994" id="citation_sisman_1994_67dc99ab85fc7">1994</a>, 85) describes the movement as &#8220;consoling or healing.&#8221; Both of these expressive characteristics are consistent with the development of expressive meaning over time&#8212;a &#8220;reassuring&#8221; or &#8220;healing&#8221; emotional quality in the movement might parallel a progression from higher ratings of negatively valenced emotion and lower ratings of positive-valenced emotions in the beginning of the movement to the opposite at the end of the movement. Because of the methodology&#8217;s use of random ordering, then, we can test a hypothesis in which cumulative effects of compositional decisions on perceived emotion produce decreases in negatively valenced affects and increases in positively valenced affects across the movement.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 4</b>. Average ratings for each of the five statements of the theme for sad/depressed/tragic, carefree, and weighty dimensions averaged over each segment comprising the statement</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=4&nonav=true"><img border="1" alt="Example 4 thumbnail" src="albrecht_ex4_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[6.5] For the purposes of discussion, I&#8217;d like to highlight just three expressive categories (<b>Example 4</b>), although means for all emotions by theme statement are provided in Table 3. First, there is a significant decrease in sad/depressed/tragic ratings over the movement, both between the first and fourth theme and the first and fifth theme (<i>p</i> &lt; .0001 in both cases). Likewise, carefree ratings show a significant increase over the movement, between the first and second theme (<i>p</i> = .01) and the first and fifth theme (<i>p</i> &lt; .0001). Notice that the effect of higher register on carefree ratings is not significantly different (<i>p</i> = .89) than the effect of faster rhythms. The effect of higher register and faster rhythms combined, however, evidenced in Theme 5, results in significantly higher carefree ratings. Weighty ratings for faster rhythms in Theme 4, however, are not significantly different (<i>p</i> = .11) than the original statement of the theme. On the other hand, higher register significantly lowers weighty ratings (<i>p</i> &lt; .0001).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table 2</b>. Group means (standard deviations) for expressive dimensions averaged over each of the five statements of the theme</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=5&nonav=true"><img border="1" alt="Table 2 thumbnail" src="albrecht_tab2_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[6.6] Additionally, as can be seen in <b>Table 2</b>, there is a significant increase in happy/joyful ratings between Theme 1 and all three of the other themes (<i>p</i> &lt; .0001 for all three), and there are significant decreases in dark ratings from the first to fourth and fifth themes (<i>p</i> &lt; .0001 in both cases) and lonely ratings from the first to fourth and fifth themes <i>p</i> &lt; .0001 for both). As expected, none of the eleven expressive categories display a significant difference between the first and third themes. These results are not only consistent with Margulis&#8217;s implied hypothesis that there are cumulative expressive effects of theme restatements throughout a rondo movement, but they are also consistent with Sisman&#8217;s and Hatten&#8217;s interpretation of a process of reassuring, consolation, or healing over the course of the movement, evidenced by decreasing negatively valenced emotions and increasing positively valenced emotions over the course of the movement. On the other hand, calm/serene and contentment ratings are significantly lower and unsettled/anxious ratings are significantly higher at the end of the movement. These ratings are likely tied to increased rhythmic activity, but these changes do not seem to support Sisman&#8217;s and Hatten&#8217;s interpretations of the expressive character in the movement.</p>


<h3>&#8220;Extreme&#8221; emotion ratings</h3>

<p>[7.1] Since Meyer (<a href="#meyer_1956" id="citation_meyer_1956_67dc99ab85fdb">1956</a>, <a href="#meyer_1967" id="citation_meyer_1967_67dc99ab85fdd">1967</a>) hypothesized that stronger emotions would be evoked from passages that are less predictable, musical expectation has played a central role in theories of how music communicates emotion.<sup><a name="FN21REF" href="#FN21" id="footnote21">(21)</a></sup> By measuring participant responses as standard deviations from the average response, we can examine what we might call &#8220;extreme ratings,&#8221; or ratings that are more than one standard deviation away from that emotion&#8217;s mean. If the theory that deviations from strong musical expectations lead to increased emotional expression (Meyer <a href="#meyer_1956" id="citation_meyer_1956_67dc99ab85fe1">1956</a> and <a href="#meyer_1967" id="citation_meyer_1967_67dc99ab85fe3">1967</a>; Narmour <a href="#narmour_1990" id="citation_narmour_1990_67dc99ab85fe4">1990</a> and <a href="#narmour_1992" id="citation_narmour_1992_67dc99ab85fe6">1992</a>; <a href="#huron_2006" id="citation_huron_2006_67dc99ab85fe8">Huron 2006</a>), one would expect to see more extreme ratings in sections of the <i>Path&eacute;tique</i> in which the latent probabilities of continuation in the music are less clear, or where the actual continuation of the music is more surprising.</p>

<p>[7.2] In rondo movements, it is often the case that episodes are the most musically unpredictable and harmonically adventurous, whereas refrains tend to be more predictable.<sup><a name="FN22REF" href="#FN22" id="footnote22">(22)</a></sup> Under this assumption, an application of the theories put forward by Meyer, Narmour, and Huron would hypothesize an uneven distribution of extreme ratings, such that episode and coda passages would elicit more extreme ratings (ratings more than one standard deviation from the mean) than refrain passages. This hypothesis is directly testable with the data collected here.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table 3</b>. Extreme ratings  by formal section</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=6&nonav=true"><img border="1" alt="Table 3 thumbnail" src="albrecht_tab3_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[7.3] For each segment, the number of extreme ratings, whether positive or negative, was tallied for each expressive dimension and the segment was classified as either refrain or non-refrain (i.e., episode, coda, or retransition). In this movement, there are three refrain passages, two episodes each with a retransition, and one coda. The results from this tally are shown in <b>Table 3</b>. Counting all of the extreme ratings collapsed across categories, the three refrain passages resulted in 1,398 extreme ratings in 152.5 seconds of excerpts, or an average of 9.17 extreme ratings per second. In the two episodes and coda passage, there are a total of 2,297 extreme ratings in 140 seconds, a significantly higher average of 16.41 extreme ratings per second.<sup><a name="FN23REF" href="#FN23" id="footnote23">(23)</a></sup> These results are consistent with the hypothesis that less predictable formal sections&#8212; in this case episode and coda sections in Rondo form&#8212; evoke stronger emotion ratings.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 5</b>. Expressive analysis of measures 20&ndash;29 of Beethoven&rsquo;s <i>Path&eacute;tique</i> Sonata, II</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=7&nonav=true"><img border="1" alt="Example 5 thumbnail" src="albrecht_ex5_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[7.4] Indeed, the passages with the most extreme ratings are the two retransitions, passages that serve to delay the expected resolution back to tonic and the main theme. This finding is also consistent with Meyer&#8217;s theory (<a href="#meyer_1956" id="citation_meyer_1956_67dc99ab85ff3">1956</a>, <a href="#meyer_1967" id="citation_meyer_1967_67dc99ab85ff4">1967</a>) that delaying expected resolution gives rise to increased emotional response. The passage with the highest density of extreme ratings in the movement happens during the first retransition, measures 20-29, viewable through the <a target="_new" href="http://societymusictheory.org:3838/Albrecht_24.3_5/">interactive data exploration tool</a>. The measures in question, along with ratings for happy/joyful, carefree, contentment, unsettled/anxious, weighty, and dark are displayed immediately in <b>Example 5</b>, although other emotion categories and longer excerpts also be explored in the tool. The shown passage elicited 517 extreme ratings, averaging 14.77 extreme ratings per second, but the single segment that elicited the most extreme ratings in the entire movement (with 98), is the excerpt corresponding to measures 23&#8211;24. Although there is technically harmonic support in this excerpt, the dominant harmony is struck before the excerpt begins, and so without hearing the harmonic context attacked, listeners only hear a single melodic line. In this rendition, the performer adds a noticeable amount of rubato. The melodic line chromatically surrounds the dominant pitch in a low register at a low dynamic level, a moment of high tension before the expected resolution. This moment, more than perhaps any other in this rendition of the movement, exemplifies Meyer&#8217;s (<a href="#meyer_1967" id="citation_meyer_1967_67dc99ab85ff6">1967</a>) first category of deviation from implication that enhances emotional arousal, in which an outcome that is clearly implied (tonic resolution from the dominant chord aligning with a return of the theme) is maximally delayed (through chromatic play around the dominant pitch emphasized with rubato).<sup><a name="FN24REF" href="#FN24" id="footnote24">(24)</a></sup></p>

<h3>Modeling the expressive meaning of musical gestures</h3>

<p>[8.1] Finally, the perceptual data collected in this study provide an opportunity to build a theory of musical gesture in this movement from the bottom up by correlating particular musical structures with perceived expressive meaning. Again, this is not a new concept, but although several theories have been proposed for how different musical gestures combine in an emergent way to take on complex expressive meaning, these ideas have received very little empirical testing. For example, Agawu (<a href="#agawu_1991" id="citation_agawu_1991_67dc99ab85ffa">1991</a>, 15) draws an analogy between language and music to illustrate that it is not specific structures of music that have fixed meanings, but rather the relationships between them.<sup><a name="FN25REF" href="#FN25" id="footnote25">(25)</a></sup> Likewise, according Hatten (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab8600d">2004</a>, 220), the meaning that adheres to music is not simply a matter of identifying topics and moving on, but rather it emergently arises out of the interplay and combination of topics.<sup><a name="FN26REF" href="#FN26" id="footnote26">(26)</a></sup> For Hatten, various musical gestures do not have absolute meaning, but they have meanings that are contingent on how they are combined with other musical gestures. For example, falling melodic contours might be thought of as abnegation, relaxation, or several other meanings depending on other mitigating musical factors, like mode, dynamic, etc.<sup><a name="FN27REF" href="#FN27" id="footnote27">(27)</a></sup> Again, it is the combination of particular musical gestures in the set that create emergent meaning rather than essentialized meanings: after all, quiet dynamics are not always calm and minor mode music is not always sad.<sup><a name="FN28REF" href="#FN28" id="footnote28">(28)</a></sup></p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table 4</b>. The sixteen musical gesture parameters used as measured predictor variables in a regression analysis of the data from the movement</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=8&nonav=true"><img border="1" alt="Table 4 thumbnail" src="albrecht_tab4_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[8.2] In order to engage with the above theories of emergent meaning arising from a set of musical gestures, the empirical data were analyzed in a bottom-up way to take into account not only many surface-level musical elements, but also the interactions between these elements. The statistical method of multiple regression provides an appropriate analytical tool for this purpose. Multiple regression works by looking for correlations between several predictor variables (musical features of segments) and the output (emotion ratings for the segments). In order to conduct the regression analysis, sixteen musical elements were analyzed for each five-second segment, which served as predictors of the participants&#8217; ratings. These sixteen predictor variables, common parameters associated with musical expression, are shown in <b>Table 4</b>, along with the way these variables were encoded.<sup><a name="FN29REF" href="#FN29" id="footnote29">(29)</a></sup></p>

<p>[8.3] By using regression to analyze how the movement&#8217;s musical gestures are related to inter-participant evaluations of perceived emotion, a model can be built for how each emotion is expressed through interactions between musical gestures in the movement. This model can be used to test previous theories of how musical gestures are used to convey emotion. For example, in various places Hatten identifies upward melodic direction with &#8220;yearning&#8221; and downward motion with &#8220;resignation&#8221; (<a href="#hatten_1994" id="citation_hatten_1994_67dc99ab86016">1994</a>, 57), harmonic dissonance (especially the diminished seventh) with anguish or grief (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab8601a">2004</a>, 15), increased dissonance and turns to the minor mode with increasing agitation (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab8601e">2004</a>, 16), and the pastoral topic&#8217;s simplicity with slow harmonic rhythms, simple melodic contours, compound meter, and the major mode (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab86022">2004</a>, 56).</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table 5</b>. Regression models based on the analysis and perceived emotional expression of each five-second segment</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=9&nonav=true"><img border="1" alt="Table 5 thumbnail" src="albrecht_tab5_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[8.4] The results of the regression model for each emotion dimension are presented in <b>Table 5</b>, showing the musical gestures that combined as a set to be significantly predictive of listener evaluations of emotional expression.<sup><a name="FN30REF" href="#FN30" id="footnote30">(30)</a></sup> First, observe that many of the musical parameters are aligned with intuitive notions of how emotion is expressed in Romantic music. For example, sad/depressed/tragic is correlated with the minor mode, slow surface rhythms, thin textures, and lower pitches. Happy/joyful is correlated with the major mode, higher pitches, and faster rhythms. Less commonly tested emotions also correspond with intuitions. Weighty is correlated with lower pitches, more tendency tones, louder dynamics, and dense textures. Lonely is correlated with thin textures, slow rhythms, lower pitches, and the minor mode. Unsettled/anxious is correlated with staccato articulations, fast rhythms, the minor mode, dense harmonies, and crescendos. Relating these models to Hatten&#8217;s gestural theories above is less straightforward, although several similarities tentatively seem to hold.<sup><a name="FN31REF" href="#FN31" id="footnote31">(31)</a></sup></p>

<p>[8.5] Second, in looking at the correlations in Table 5, it is important to remember that the musical parameters listed in the center column reflect emergent meanings from a complex interaction of musical parameters that are correlated with emotional expression for the movement, rather than absolute meanings. For example, although calm/serene is correlated with the major mode, it is correlated with the major mode in situations in which the music <i>also</i> includes legato articulations, faster surface rhythms, faster harmonic tempo, lower pitches, less dense textures, diminuendo, common melodic successions, and a lack of tendency tones. The correlation between calm/serene and the major mode breaks down when the major-mode excerpts use staccato articulations, thick textures, and chords with tendency tones, as in the &#8220;E major&#8221; cadence in the second episode (see Example 3). In this passage (mm. 43&#8211;44), although the cadence is unambiguously in a major key, calm/serene ratings are significantly lower than average, even <i>extremely</i> low (see &#8220;extreme&#8221; ratings section above). Therefore, it is important to remember that in large measure these models truly point to musical <i>gestures</i> that are composed of combinations of the musical parameters provided in the table.</p>

<h2>Summary of results</h2>

<p>[9.1] So, what is the value of <i>this kind</i> of expressive analysis of the music&#8217;s structures, one that is empirical and intersubjective in nature? The first observation, which may perhaps come as something of a surprise, is that <i>in general</i> we can trust undergraduate students&#8217; understanding of expressive meaning in music, at least when taken as a large enough group. Though there are certainly individual differences between students, and though certainly some student responses proved unreliable (see Appendix), as a whole participant groups of undergraduate music majors converge on an intersubjective understanding of musical gestures that can be generalized to a broader community of listeners. These responses were robust enough to generate a narrative analysis of expressive meaning consistent with prior theorists&#8217; analyses, to detect expressive differences between distinct formal sections, to identify moments of heightened expression related to musical expectation, to significantly differentiate between parallel passages with subtle musical differences, and to build complex models of the emergent expressive meaning of musical gestures consisting of combinations of musical parameters. The robustness of the results suggests that this kind of analysis may be a profitable way to investigate expressive meaning in larger repertoires, and that the analyses of experts can be brought into dialogue with a more crowd-sourced understanding of expressive meaning.</p>

<p>[9.2] A related point is that this empirical analytical approach allows for the opportunity to test important theories that have not been thoroughly tested. Of course, not all theories should be tested with intersubjective data of perceptions of expressive meaning. However, many of the theories examined in this paper have made claims about how listeners <i>in general</i> will hear music and think about the expressive implications of that music. If these theories capture meaningful aspects of music listening, then we should expect that collected data will be consistent with the outcomes hypothesized. In this article, the outcomes of this study were consistent with important theories proposed by Meyer (<a href="#meyer_1956" id="citation_meyer_1956_67dc99ab8603a">1956</a>), Narmour (<a href="#narmour_1990" id="citation_narmour_1990_67dc99ab8603c">1990</a>, <a href="#narmour_1992" id="citation_narmour_1992_67dc99ab8603e">1992</a>), and Huron (<a href="#huron_2006" id="citation_huron_2006_67dc99ab8603f">2006</a>), who hypothesized that less predictable music should elicit stronger emotional reactions.</p>

<p>[9.3] Even theories that do not form explicit empirically testable hypotheses make claims about intersubjective perceptions of expressive meaning of musical gestures. By actually collecting the pertinent data, these claims can be tested to determine if communities of actual listeners hear the expressive implications of musical gestures suggested by these theories. For example, the progressive exposure method with random ordering provides a unique opportunity to isolate the differences between compositional and performative decisions between repeated passages. The results were consistent with an expressive progression from the beginning to the end of the movement, consistent with Sisman&#8217;s and Hatten&#8217;s interpretations of the movement. Also, the empirical results are largely consistent with topic theory or a theory of musical gesture, although caution should be advised in reading complex topical or tropological interpretations from broad statistical correlation. Finally, through a multiple regression analysis, a model can be built that explicitly defines correlations between specific musical gestures and perceived emotional expression in the analyzed music.</p>

<p>[9.4] I do not find it surprising that this paradigm provided results that were consistent with most of the prior theoretical claims tested. It is encouraging that empirical approaches provide converging evidence with theoretical approaches in building knowledge about music. But beyond simply bolstering prior claims, I find the new insights provided by this type of empirical investigation exciting. For example, beyond simply finding correlations between surface musical elements and perceived emotion consistent with prior ideas, the models in section 8 suggest new combinations of effects for further investigation. It is even possible that new avenues of expression might discovered. By examining emotions one at a time, rather than asking for participants to identify the most prominent emotion of a passage, this approach also allows for investigating subtle mixtures of emotion. This method also appears to be sensitive to detecting moments of uncertainty and complexity in music by pointing out those areas of intense emotionality. Future research could be used to model more subtle formal boundaries (like ambiguous phrase endings) using perceived emotion data, or conversely to model perceptions of emotion using complexity measures like cross entropy.</p>

<p>[9.5] However, while these initial analyses provide a useful starting point for dialoguing about the relationship between the theory of gesture and empirical evidence in support of gesture, these results should not be accepted wholesale. Every research paradigm has strengths and drawbacks, and empirical approaches are particularly susceptible to particular types of misunderstandings. First, care should be taken in trying to overly generalize the results of the gestural analysis; discussing gesture in general in the classical style is very different from discussing how gesture is used in one specific movement.<sup><a name="FN32REF" href="#FN32" id="footnote32">(32)</a></sup> We should not assume that there is only one language or one set of devices for expressing particular emotions in music in a given style, and one should not overly generalize about an entire style from the analysis of one movement.</p>

<p>[9.6] Moreover, the results of this study reflect the context of the respondents. It cannot be emphasized enough that while the progressive exposure method is an effective way to tie perceptual responses directly to short musical gestures, one casualty of the approach is any kind of longer musical context. Much of a passage&#8217;s expressive impact must be understood within the context of the preceding music. There would undoubtedly be differences in some of the ratings if the passages were heard within their proper context. Even so, Tillman and Bigand (<a href="#tillman_and_bigand_1996" id="citation_tillman_and_bigand_1996_67dc99ab86043">1996</a>) found that small chunks of music played in backwards order did not affect the perceived expressiveness of the music for selections for Bach and Mozart, and Bigand et al. (<a href="#bigand_et_al_2005" id="citation_bigand_et_al_2005_67dc99ab86046">2005</a>) found that listeners can accurately recognize emotions in classical music in as little as one second, suggesting that enough of the expressive meaning of the music is sufficiently encoded at a low level of structure to not invalidate this study. At the same time, as a well-known work, many listeners reported in post-experiment interviews that they recognized the work, and this prior knowledge undoubtedly brings with it some kind of context surrounding the isolated excerpts and complex cultural connotations that certainly affect the results to some degree. It is important to remember that there is a cultural and social component to these findings that reflects the reality of twenty-first century music major undergraduates in the United States. Beethoven&#8217;s contemporaries may not have heard the music in quite the same way&#8212;but this is exactly the point! Expression is a cultural construct in response to particular musical gestures.</p>

<p>[9.7] Nevertheless, I believe this kind of intersubjective empirical analysis of music offers genuine value to the analytical enterprise. One of the most important goals of music analysis is to construct convincing narratives about music that reveal new insights about the music or direct our attention to important elements of the music that might otherwise have gone unnoticed. Truly compelling stories weave together disparate strands from different perspectives. When widely divergent methodologies provide converging evidence for the same theoretical position, the story told is more convincing.</p>

<p>[9.8] Empirical methods of analysis offer a different set of advantages and suffer from a different set of drawbacks than more traditional methods of analysis. One of the greatest benefits offered by empirical methods is the opportunity to counterbalance an analyst&#8217;s individual biases with the perspectives of a large group of listeners. This is certainly easier to do in more substantial ways than is typically possible when the accountability of data is not present. When the results of empirical studies are consistent with longstanding theories of musical expression, the converging evidence lends greater credence to the theories.</p>





<!-------------------------------- END Article Body -------------------------------------------->

       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	

<!-- appendix -->

<hr>

<h3><a name="appendix">Appendix</a>: Reliability Metrics</h3>

<p>[A.1] To test the degree to which participants were personally consistent (intra-participant reliability) and the degree to which all participants provided similar responses (inter-participant reliability), a number of metrics were examined.</p>

<p style="text-align:center">Intra-participant reliability</p>

<p>[A.2] There are two ways in which responses that a particular participant provides might be unreliable. In the first instance, participants may simply not provide reliable responses in general, regardless of emotion category. This may reveal a problem with a particular participant&#8217;s responses&#8212;perhaps they were haphazard in their answers or distracted. In the second instance, participants might be reliable in general, but may unreliably evaluate a particular emotion category. This may reveal a problem with a category, perhaps because that category is confusing or because the participant did not understand the label.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example A1</b>. Histogram showing intra-participant correlations for each participant-scale. 76 participant-scales had correlations lower than +.25, and so were eliminated from further analysis</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=10&nonav=true"><img border="1" alt="Example A1 thumbnail" src="albrecht_exA1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[A.3] Because a participant might be reliable in general but unreliable in relation to a particular emotion category, each participant-scale was analyzed separately for intra-participant reliability. With 110 participants and 3 emotion categories per participant, there were 330 total participant-scales. To check for reliability, participants provided two responses for 5 randomly selected segments for each emotion category. Correlations were calculated between the set of initial and second responses for each participant-scale. A histogram showing all 330 correlations is provided in <b>Example A1</b>. An <i>a priori</i> elimination criterion was set for a +.4 correlation, meaning that participant-scales that were less consistent than this standard would be eliminated. However, after examining the data, this standard seemed too strict, as it would result in the elimination of 100 participant-scales. Therefore, the decision was made <i>a posteriori</i> to move the elimination criterion to +.25, resulting in the elimination of 76 participant-scales.</p>

<fig>
 <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table A1</b>. Means (standard deviations) of intra-participant reliability for each affective category averaged across participant-scale</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=11&nonav=true"><img border="1" alt="Table A1 thumbnail" src="albrecht_tabA1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p> <p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table A2</b>. The mean  inter-participant correlations for all participant-scales below +.25 correlation</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="albrecht_examples.php?id=12&nonav=true"><img border="1" alt="Table A2 thumbnail" src="albrecht_tabA2_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></fig>

<p>[A.4] Note that correlations between -.5 and +.5 reveal a low level of consistency between responses. Interestingly, the emotion categories most heavily represented in this range are not evenly distributed. Of the 71 participant-scales with correlations between -.5 and +.5, dark, emotional/moody, and sincerity/truthful were most highly represented with 22 participant-scales. To further investigate the difference in reliability between emotion categories, individual participant-scale correlations were averaged across category. The results are given in <b>Table A1</b>. The categories with the lowest average correlation were emotional/moody (mean = +.448; sd = .61) and sincerity/truthful (mean = +.362, sd = .50).</p>

<p>[A.5] Correlation averages were unable to be calculated for cheeky/sassy due to a mathematical property of correlations in which they are unable to be directly averaged without Fisher&#8217;s z-transformation (<a href="#silver_and_dunlap_1987" id="citation_silver_and_dunlap_1987_67dc99ab860d2">Silver and Dunlap 1987</a>). This transformation maps -1 onto -&infin;  and +1 onto +&infin;. Because correlations for three of the participant-scales for cheeky/sassy were exactly +1, averages were unable to be calculated. Post-experiment interviews revealed that many participants thought that the cheeky/sassy scale was inappropriate for the movement, and therefore rated that scale with the lowest possible rating for nearly every excerpt. This resulted in consistent 0 ratings, resulting in a +1 correlation. For these reasons, cheeky/sassy was discarded from further consideration for the remainder of the analysis.</p>

<p style="text-align:center">Inter-participant reliability</p>

<p>[A.6] In addition to testing intra-participant reliability, inter-participant reliability metrics also provide insights into the success of the various emotion categories. Low inter-participant reliability is more acceptable than low intra-participant reliability, however, as individual differences in listener ratings should be respected. Nevertheless, low inter-participant reliability may signal that participants misunderstood directions, were inattentive, or were operating under differing definitions for different emotion categories.</p>

<p>[A.7] After 76 participant-scales with low intra-participant reliability were eliminated, inter-participant correlations were calculated for the remaining scales. This was done by correlating the 56 ratings for each participant-scale with the 56 ratings for all other participant-scales for the same emotion and offset condition, and the correlations were averaged together using Fischer&#8217;s z-transformation. As before, all participant-scales averaging a correlation below +.25 with the other participant-scales were examined. The results for each participant-scale that met this criterion are shown in Table A2. The participant-scales are identified with their emotion category, their offset group, and the mean inter-participant correlation.</p>


<p>[A.8] As is evident from <b>Table A2</b>, the categories that were most inconsistently used between participants were sincerity/truthful, emotional/moody, and important/serious.<sup><a name="FN33REF" href="#FN33" id="footnote33">(33)</a></sup> These scales also demonstrated low intra-participant reliability and many of these scales had already been eliminated by that exclusion criterion. For example, only 15 participant-scales remained for important/serious, 12 for sincerity/truthful, and 10 for emotional/moody. Demonstrating low inter-participant reliability in addition to low intra-participatng reliability, these three scales were discarded from further consideration.</p>

       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Author Info -------------------------------------------->

    
<hr>

	<p><a name="AUTHORNOTE1"></a>
	
	Albrecht, Joshua D.<br>
	The University of Mary Hardin-Baylor<br>Music Department<br>900 College St.<br>Belton, TX 76513<br><a href="mailto:jalbrecht@umhb.edu">jalbrecht@umhb.edu</a><br>	
</p>

       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	

<!-------------------------------- Works Cited List -------------------------------------------->

    
	<hr>
	
	<h3><a name="WorksCited">Works Cited</a></h3>
	
	<div id="citediv_agawu_1991" class="flyoverdiv">Agawu, Kofi. 1991. <i>Playing with Signs.</i> Princeton University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="agawu_1991"></a>Agawu, Kofi. 1991. <i>Playing with Signs.</i> Princeton University Press.</p><div id="citediv_allanbrook_1986" class="flyoverdiv">Allanbrook, Wye Jamison. 1986. <i>Rhythmic Gesture in Mozart: Le Nozze di Figaro and Don Giovanni</i>. University of Chicago Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="allanbrook_1986"></a>Allanbrook, Wye Jamison. 1986. <i>Rhythmic Gesture in Mozart: Le Nozze di Figaro and Don Giovanni</i>. University of Chicago Press.</p><div id="citediv_bigand_et_al_2005" class="flyoverdiv">Bigand, Emmanuel, Sandrine Vieillard, Fran&ccedil;ois Madurell, Jeremy Marozeau, and A. Daquet. 2005. &#8220;Multidimensional Scaling of Emotional Responses to Music: The effect of Musical Expertise and of the Duration of the Excerpts.&#8221; <i>Cognition and Emotion </i>19 (8): 1113&ndash;39.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="bigand_et_al_2005"></a>Bigand, Emmanuel, Sandrine Vieillard, Fran&ccedil;ois Madurell, Jeremy Marozeau, and A. Daquet. 2005. &#8220;Multidimensional Scaling of Emotional Responses to Music: The effect of Musical Expertise and of the Duration of the Excerpts.&#8221; <i>Cognition and Emotion </i>19 (8): 1113&ndash;39.</p><div id="citediv_blood_and_zatorre_2001" class="flyoverdiv">Blood, Anne, and Robert Zatorre. 2001. &#8220;Intensely Pleasurable Responses to Music Correlate With Activity in Brain Regions Implicated in Reward and Emotion.&#8221; <i>Proceedings of the National Academy of Sciences</i> 98: 118&#8211;23.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="blood_and_zatorre_2001"></a>Blood, Anne, and Robert Zatorre. 2001. &#8220;Intensely Pleasurable Responses to Music Correlate With Activity in Brain Regions Implicated in Reward and Emotion.&#8221; <i>Proceedings of the National Academy of Sciences</i> 98: 118&#8211;23.</p><div id="citediv_caplin_1998" class="flyoverdiv">Caplin, William E. 1998. <i>Classical Form: A Theory of Formal Functions for the Instrumental Music of Haydn, Mozart, and Beethoven. </i>Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="caplin_1998"></a>Caplin, William E. 1998. <i>Classical Form: A Theory of Formal Functions for the Instrumental Music of Haydn, Mozart, and Beethoven. </i>Oxford University Press.</p><div id="citediv_cole_2001" class="flyoverdiv">Cole, Malcolm S. 2001. &#8220;Rondo.&#8221; In <i>The New Grove Dictionary of Music and Musicians. </i>2nd edition, ed. Stanley Sadie and John Tyrell, 21: 649&#8211;56. Macmillan.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="cole_2001"></a>Cole, Malcolm S. 2001. &#8220;Rondo.&#8221; In <i>The New Grove Dictionary of Music and Musicians. </i>2nd edition, ed. Stanley Sadie and John Tyrell, 21: 649&#8211;56. Macmillan.</p><div id="citediv_crowder_1985" class="flyoverdiv">Crowder, Robert G. 1985. &#8220;Perception of the Major/Minor Distinction II: Experimental Investigations.&#8221; <i>Psychomusicology</i> 5: 3&#8211;24.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="crowder_1985"></a>Crowder, Robert G. 1985. &#8220;Perception of the Major/Minor Distinction II: Experimental Investigations.&#8221; <i>Psychomusicology</i> 5: 3&#8211;24.</p><div id="citediv_davies_1994" class="flyoverdiv">Davies, Stephen. 1994. <i>Musical Meaning and Expression</i>. Cornell University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="davies_1994"></a>Davies, Stephen. 1994. <i>Musical Meaning and Expression</i>. Cornell University Press.</p><div id="citediv_de_la_motte-haber_1968" class="flyoverdiv">de la Motte-Haber, Helga. 1968. <i>Ein Beitrag zur Klassifikation musikalischer Rhythmen</i>. Arno Volk Verlag..</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="de_la_motte-haber_1968"></a>de la Motte-Haber, Helga. 1968. <i>Ein Beitrag zur Klassifikation musikalischer Rhythmen</i>. Arno Volk Verlag..</p><div id="citediv_eerola_2016" class="flyoverdiv">Eerola, Tuomas. 2016. &#8220;Expectancy-Violation and Information-Theoretic Models of Melodic Complexity.&#8221; <i>Empirical Musicology Review, </i>11 (1): 2&ndash;17.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="eerola_2016"></a>Eerola, Tuomas. 2016. &#8220;Expectancy-Violation and Information-Theoretic Models of Melodic Complexity.&#8221; <i>Empirical Musicology Review, </i>11 (1): 2&ndash;17.</p><div id="citediv_ekman_1992" class="flyoverdiv">Ekman, Paul. 1992. &#8220;An Argument for Basic Emotions.&#8221; <i>Cognition &amp; Emotion</i> 6:<i> </i>169&#8211;200.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="ekman_1992"></a>Ekman, Paul. 1992. &#8220;An Argument for Basic Emotions.&#8221; <i>Cognition &amp; Emotion</i> 6:<i> </i>169&#8211;200.</p><div id="citediv_gabriel_1978" class="flyoverdiv">Gabriel, Clive. 1978. &#8220;An Experimental Study of Deryck Cooke&#8217;s Theory of Music and Meaning.&#8221; <i>Psychology of Music</i> 6: 13&#8211;20.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="gabriel_1978"></a>Gabriel, Clive. 1978. &#8220;An Experimental Study of Deryck Cooke&#8217;s Theory of Music and Meaning.&#8221; <i>Psychology of Music</i> 6: 13&#8211;20.</p><div id="citediv_gabrielsson_and_lindstr&ouml;m_2010" class="flyoverdiv">Gabrielsson, Alf, and Erik Lindstr&ouml;m. 2010. &#8220;The Role of Structure in the Musical Expression of Emotions.&#8221; In <i>The Handbook of Music and Emotion: Theory, Research, Applications</i>,<i> </i>ed. Patrik N. Juslin, and John A. Sloboda, 367&#8211;400. Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="gabrielsson_and_lindstr&ouml;m_2010"></a>Gabrielsson, Alf, and Erik Lindstr&ouml;m. 2010. &#8220;The Role of Structure in the Musical Expression of Emotions.&#8221; In <i>The Handbook of Music and Emotion: Theory, Research, Applications</i>,<i> </i>ed. Patrik N. Juslin, and John A. Sloboda, 367&#8211;400. Oxford University Press.</p><div id="citediv_gabrielsson_2002" class="flyoverdiv">Gabrielsson, Alf. 2002. &#8220;Emotion Perceived and Emotion Felt: Same or Different?&#8221; <i>Musicae Scientiae, </i>5<i> </i>(1 supplement): 123&#8211;47.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="gabrielsson_2002"></a>Gabrielsson, Alf. 2002. &#8220;Emotion Perceived and Emotion Felt: Same or Different?&#8221; <i>Musicae Scientiae, </i>5<i> </i>(1 supplement): 123&#8211;47.</p><div id="citediv_hatten_1994" class="flyoverdiv">Hatten, Robert S. 1994. <i>Musical Meaning in Beethoven: Markedness, Correlation, Interpretation</i>. Indiana University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="hatten_1994"></a>Hatten, Robert S. 1994. <i>Musical Meaning in Beethoven: Markedness, Correlation, Interpretation</i>. Indiana University Press.</p><div id="citediv_hatten_2004" class="flyoverdiv">Hatten, Robert S. 2004. <i>Interpreting Musical Gestures, Topics, and Tropes: Mozart, Beethoven, Schubert.</i> Indiana Univerisity Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="hatten_2004"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2004. <i>Interpreting Musical Gestures, Topics, and Tropes: Mozart, Beethoven, Schubert.</i> Indiana Univerisity Press.</p><div id="citediv_heinlein_1928" class="flyoverdiv">Heinlein, Christian Paul. 1928. &#8220;The Affective Characters of the Major and Minor Modes in Music.&#8221; <i>Journal of Comparative Psychology</i> 8: 101&#8211;42.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="heinlein_1928"></a>Heinlein, Christian Paul. 1928. &#8220;The Affective Characters of the Major and Minor Modes in Music.&#8221; <i>Journal of Comparative Psychology</i> 8: 101&#8211;42.</p><div id="citediv_hepokoski_and_darcy_2006" class="flyoverdiv">Hepokoski, James, and Warren Darcy. 2006. <i>Elements of Sonata Theory: Norms, Types, and Deformations in the Late Eighteenth-Century Sonata. </i>Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="hepokoski_and_darcy_2006"></a>Hepokoski, James, and Warren Darcy. 2006. <i>Elements of Sonata Theory: Norms, Types, and Deformations in the Late Eighteenth-Century Sonata. </i>Oxford University Press.</p><div id="citediv_hevner_1936" class="flyoverdiv">Hevner, Kate. 1936. &#8220;Experimental Studies of the Elements of Expression in Music.&#8221; <i>American Journal of Psychology</i> 48: 246&#8211;68.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="hevner_1936"></a>Hevner, Kate. 1936. &#8220;Experimental Studies of the Elements of Expression in Music.&#8221; <i>American Journal of Psychology</i> 48: 246&#8211;68.</p><div id="citediv_huron_2006" class="flyoverdiv">Huron, David. 2006. <i>Sweet Anticipation: Music and the Psychology of Expectation. </i>The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="huron_2006"></a>Huron, David. 2006. <i>Sweet Anticipation: Music and the Psychology of Expectation. </i>The MIT Press.</p><div id="citediv_juslin_and_laukka_2004" class="flyoverdiv">Juslin, Patrik N., and Petri Laukka. 2004. &#8220;Expression, Perception, and Induction of Musical Emotions: A Review and a Questionnaire Study of Everyday Listening.&#8221; <i>Journal of New Music Research</i> 33: 217&#8211;38.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="juslin_and_laukka_2004"></a>Juslin, Patrik N., and Petri Laukka. 2004. &#8220;Expression, Perception, and Induction of Musical Emotions: A Review and a Questionnaire Study of Everyday Listening.&#8221; <i>Journal of New Music Research</i> 33: 217&#8211;38.</p><div id="citediv_juslin_and_lindstr&oulm;m_2011" class="flyoverdiv">Juslin, Patrik N., and Erik Lindstr&ouml;m. 2011. &#8220;Musical Expression of Emotions: Modeling Listeners&#8217; Judgments of Composed and Performed Features.&#8221; Special Issue: Music and Emotion. <i>Music Analysis </i>29 (1&#8211;3): 334&#8211;64.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="juslin_and_lindstr&oulm;m_2011"></a>Juslin, Patrik N., and Erik Lindstr&ouml;m. 2011. &#8220;Musical Expression of Emotions: Modeling Listeners&#8217; Judgments of Composed and Performed Features.&#8221; Special Issue: Music and Emotion. <i>Music Analysis </i>29 (1&#8211;3): 334&#8211;64.</p><div id="citediv_juslin_and_sloboda_2010" class="flyoverdiv">Juslin, Patrik N., and John A. Sloboda, ed. 2010. <i>The Handbook of Music and Emotion: Theory, Research, Applications.</i> Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="juslin_and_sloboda_2010"></a>Juslin, Patrik N., and John A. Sloboda, ed. 2010. <i>The Handbook of Music and Emotion: Theory, Research, Applications.</i> Oxford University Press.</p><div id="citediv_kaminska_and_woolf_2000" class="flyoverdiv">Kaminska, Zofia, and Jennifer Woolf. 2000. &#8220;Melodic Line and Emotion: Cooke&#8217;s Theory Revisited.&#8221; <i>Psychology of Music </i>28: 133&#8211;53.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="kaminska_and_woolf_2000"></a>Kaminska, Zofia, and Jennifer Woolf. 2000. &#8220;Melodic Line and Emotion: Cooke&#8217;s Theory Revisited.&#8221; <i>Psychology of Music </i>28: 133&#8211;53.</p><div id="citediv_kendall_and_carterette_1990" class="flyoverdiv">Kendall, Roger A., and Edward C. Carterette. 1990. &#8220;The Communication of Musical Expression.&#8221; <i>Music Perception: An Interdisciplinary Journal </i>8 (2): 129&#8211;63.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="kendall_and_carterette_1990"></a>Kendall, Roger A., and Edward C. Carterette. 1990. &#8220;The Communication of Musical Expression.&#8221; <i>Music Perception: An Interdisciplinary Journal </i>8 (2): 129&#8211;63.</p><div id="citediv_kivy_1980" class="flyoverdiv">Kivy, Peter. 1980. <i>The Corded Shell: Reflections on Musical Expressions. </i>Princeton University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="kivy_1980"></a>Kivy, Peter. 1980. <i>The Corded Shell: Reflections on Musical Expressions. </i>Princeton University Press.</p><div id="citediv_lartillot_and_toiviainen_2007" class="flyoverdiv">Lartillot, Olivier, and Petri Toiviainen. 2007. &#8220;A MATLAB toolbox for musical feature extraction from audio.&#8221; <i>Proceedings of the 10th International Conference on Digital Audio Effects (DAFx-01-08)</i>. Bordeaux, France.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="lartillot_and_toiviainen_2007"></a>Lartillot, Olivier, and Petri Toiviainen. 2007. &#8220;A MATLAB toolbox for musical feature extraction from audio.&#8221; <i>Proceedings of the 10th International Conference on Digital Audio Effects (DAFx-01-08)</i>. Bordeaux, France.</p><div id="citediv_margulis_2013" class="flyoverdiv">Margulis, Elizabeth H. 2013. <i>On Repeat: How Music Plays the Mind. </i>Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="margulis_2013"></a>Margulis, Elizabeth H. 2013. <i>On Repeat: How Music Plays the Mind. </i>Oxford University Press.</p><div id="citediv_mckay_2007" class="flyoverdiv">McKay, Nicolas. 2007. &#8220;On Topics Today.&#8221; <i>Zeitschrift der Gesellschaft f&uuml;r Musiktheorie</i> 4 (1&ndash;2): 159&#8211;83.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="mckay_2007"></a>McKay, Nicolas. 2007. &#8220;On Topics Today.&#8221; <i>Zeitschrift der Gesellschaft f&uuml;r Musiktheorie</i> 4 (1&ndash;2): 159&#8211;83.</p><div id="citediv_meyer_1956" class="flyoverdiv">Meyer, Leonard B. 1956. <i>Emotion and Meaning in Music. </i>University of Chicago Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="meyer_1956"></a>Meyer, Leonard B. 1956. <i>Emotion and Meaning in Music. </i>University of Chicago Press.</p><div id="citediv_meyer_1967" class="flyoverdiv">Meyer, Leonard B. 1967. <i>Music, the Arts, and Ideas. </i>University of Chicago Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="meyer_1967"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1967. <i>Music, the Arts, and Ideas. </i>University of Chicago Press.</p><div id="citediv_narmour_1990" class="flyoverdiv">Narmour, Eugene. 1990. <i>The Analysis and Cognition of Basic Musical Structures: The Implication-Realization Model. </i>University of Chicago Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="narmour_1990"></a>Narmour, Eugene. 1990. <i>The Analysis and Cognition of Basic Musical Structures: The Implication-Realization Model. </i>University of Chicago Press.</p><div id="citediv_narmour_1992" class="flyoverdiv">Narmour, Eugene. 1992. <i>The Analysis and Cognition of Melodic Complexity: The Implication-Realization Model. </i>University of Chicago Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="narmour_1992"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 1992. <i>The Analysis and Cognition of Melodic Complexity: The Implication-Realization Model. </i>University of Chicago Press.</p><div id="citediv_o&#8217;conor_2008" class="flyoverdiv">O&#8217;Conor, John. 2008. <i>Breathe<sup>&reg;</sup>: relaxing piano for lovers. </i>Telarc B0010DJ1YM.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="o&#8217;conor_2008"></a>O&#8217;Conor, John. 2008. <i>Breathe<sup>&reg;</sup>: relaxing piano for lovers. </i>Telarc B0010DJ1YM.</p><div id="citediv_persson_2001" class="flyoverdiv">Persson, Roland S. 2001. &#8220;The Subjective World of the Performer.&#8221; In <i>Music and Emotion: Theory and Research</i>, ed. Patrik N. Juslin, and John A. Sloboda,  275&#8211;89. Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="persson_2001"></a>Persson, Roland S. 2001. &#8220;The Subjective World of the Performer.&#8221; In <i>Music and Emotion: Theory and Research</i>, ed. Patrik N. Juslin, and John A. Sloboda,  275&#8211;89. Oxford University Press.</p><div id="citediv_repp_1997" class="flyoverdiv">Repp, Bruno. 1997. &#8220;The Aesthetic Quality of a Quantitatively Average Music Performance: Two Preliminary Experiments.&#8221; <i>Music Perception: An Interdisciplinary Journal </i>14 (4): 419&#8211;44.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="repp_1997"></a>Repp, Bruno. 1997. &#8220;The Aesthetic Quality of a Quantitatively Average Music Performance: Two Preliminary Experiments.&#8221; <i>Music Perception: An Interdisciplinary Journal </i>14 (4): 419&#8211;44.</p><div id="citediv_robinson_2005" class="flyoverdiv">Robinson, Jenefer. 2005.<i> Deeper than Reason: Emotion and Its Role in Literature, Music, and Art.</i> Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="robinson_2005"></a>Robinson, Jenefer. 2005.<i> Deeper than Reason: Emotion and Its Role in Literature, Music, and Art.</i> Oxford University Press.</p><div id="citediv_robinson_and_hatten_2012" class="flyoverdiv">Robinson, Jenefer and Robert S. Hatten. 2012. &#8220;Emotions in Music.&#8221; <i>Music Theory Spectrum </i>34 (2): 71&#8211;106.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="robinson_and_hatten_2012"></a>Robinson, Jenefer and Robert S. Hatten. 2012. &#8220;Emotions in Music.&#8221; <i>Music Theory Spectrum </i>34 (2): 71&#8211;106.</p><div id="citediv_russell_1980" class="flyoverdiv">Russell, James A. 1980. &#8220;A Circumplex Model of Affect.&#8221; <i>Journal of Personality and Social Psychology</i> 59: 899&#8211;915. </div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="russell_1980"></a>Russell, James A. 1980. &#8220;A Circumplex Model of Affect.&#8221; <i>Journal of Personality and Social Psychology</i> 59: 899&#8211;915. </p><div id="citediv_sapp_2007" class="flyoverdiv">Sapp, Craig. 2007. &#8220;Comparative Analysis of Multiple Musical Performances.&#8221; In <i>Proceedings of the Eighth International Conference on Music Information Retrieval. </i>September 23rd&#8211;27th, 2007, Vienna, Austria.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sapp_2007"></a>Sapp, Craig. 2007. &#8220;Comparative Analysis of Multiple Musical Performances.&#8221; In <i>Proceedings of the Eighth International Conference on Music Information Retrieval. </i>September 23rd&#8211;27th, 2007, Vienna, Austria.</p><div id="citediv_sapp_2008" class="flyoverdiv">Sapp, Craig. 2008. &#8220;Hybrid Numeric/Rank Similarity Metrics for Music Performance Studies.&#8221; In <i>Proceedings of the Ninth International Conference on Music Information Retrieval</i>. September 14th&#8211;18th, 2008, Drexel University, Philadelphia, PA.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sapp_2008"></a><span class='sans'>&mdash;&mdash;&mdash;&mdash;&mdash;</span>. 2008. &#8220;Hybrid Numeric/Rank Similarity Metrics for Music Performance Studies.&#8221; In <i>Proceedings of the Ninth International Conference on Music Information Retrieval</i>. September 14th&#8211;18th, 2008, Drexel University, Philadelphia, PA.</p><div id="citediv_scherer_and_oshinsky_1977" class="flyoverdiv">Scherer, Klaus R., and James S. Oshinsky. 1977. &#8220;Cue Utilization in Emotion Attribution from Auditory Stimuli.&#8221; <i>Motivation and Emotion</i> 1: 331&#8211;46.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="scherer_and_oshinsky_1977"></a>Scherer, Klaus R., and James S. Oshinsky. 1977. &#8220;Cue Utilization in Emotion Attribution from Auditory Stimuli.&#8221; <i>Motivation and Emotion</i> 1: 331&#8211;46.</p><div id="citediv_silver_and_dunlap_1987" class="flyoverdiv">Silver, N. Clayton, and William P. Dunlap. 1987. &#8220;Averaging correlation coefficients: Should Fischer&#8217;s z-transformation be used?&#8221; <i>Journal of Applied Psychology</i> 72: 146&#8211;48.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="silver_and_dunlap_1987"></a>Silver, N. Clayton, and William P. Dunlap. 1987. &#8220;Averaging correlation coefficients: Should Fischer&#8217;s z-transformation be used?&#8221; <i>Journal of Applied Psychology</i> 72: 146&#8211;48.</p><div id="citediv_sisman_1994" class="flyoverdiv">Sisman, Elaine. 1994. &#8220;Pathos and the <i>Path&eacute;tique</i>: Rhetorical Stance in Beethoven&#8217;s C-Minor Sonata, Op. 13.&#8221; <i>Beethoven Forum </i>3:<i> </i>81&#8211;105.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sisman_1994"></a>Sisman, Elaine. 1994. &#8220;Pathos and the <i>Path&eacute;tique</i>: Rhetorical Stance in Beethoven&#8217;s C-Minor Sonata, Op. 13.&#8221; <i>Beethoven Forum </i>3:<i> </i>81&#8211;105.</p><div id="citediv_sloboda_1991" class="flyoverdiv">Sloboda, John A. 1991. &#8220;Music Structure and Emotional Response: Some Empirical Findings.&#8221; <i>Psychology of Music</i> 19 (2): 110&#8211;20.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="sloboda_1991"></a>Sloboda, John A. 1991. &#8220;Music Structure and Emotional Response: Some Empirical Findings.&#8221; <i>Psychology of Music</i> 19 (2): 110&#8211;20.</p><div id="citediv_tagg_2006" class="flyoverdiv">Tagg, Philip. 2006. <i>&#8220;</i>Music, Moving Images, Semiotics, and the Democratic Right to Know.&#8221; In <i>Music and Manipulation. On the Social Uses and Social Control of Music</i>, ed. S. Brown, and U. Volgsten, 163&#8211;86. Berghahn Books.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="tagg_2006"></a>Tagg, Philip. 2006. <i>&#8220;</i>Music, Moving Images, Semiotics, and the Democratic Right to Know.&#8221; In <i>Music and Manipulation. On the Social Uses and Social Control of Music</i>, ed. S. Brown, and U. Volgsten, 163&#8211;86. Berghahn Books.</p><div id="citediv_tillman_and_bigand_1996" class="flyoverdiv">Tillman, Barbara, and Emmanuel Bigand. 1996. &#8220;Does Formal Musical Structure Affect Perception of Musical Expressiveness?&#8221; <i>Psychology of Music </i>24 (1): 3&#8211;17.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="tillman_and_bigand_1996"></a>Tillman, Barbara, and Emmanuel Bigand. 1996. &#8220;Does Formal Musical Structure Affect Perception of Musical Expressiveness?&#8221; <i>Psychology of Music </i>24 (1): 3&#8211;17.</p><div id="citediv_watson_1942" class="flyoverdiv">Watson, K. Brantley. 1942. &#8220;The Nature and Measurement of Musical Meanings.&#8221; <i>Psychological Monographs</i> 54: 1&#8211;43.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="watson_1942"></a>Watson, K. Brantley. 1942. &#8220;The Nature and Measurement of Musical Meanings.&#8221; <i>Psychological Monographs</i> 54: 1&#8211;43.</p><div id="citediv_wiggins_m&uuml;llensiefen_and_pearce_2010" class="flyoverdiv">Wiggins, Geraint A., Daniel M&uuml;llensiefen, and Marcus T. Pearce. 2010. &#8220;On the non-existence of music: Why music theory is a figment of the imagination.&#8221; <i>Musicae Scientiae</i>, Discussion Forum 5: 231&ndash;55.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="wiggins_m&uuml;llensiefen_and_pearce_2010"></a>Wiggins, Geraint A., Daniel M&uuml;llensiefen, and Marcus T. Pearce. 2010. &#8220;On the non-existence of music: Why music theory is a figment of the imagination.&#8221; <i>Musicae Scientiae</i>, Discussion Forum 5: 231&ndash;55.</p><div id="citediv_zentner_grandjean_and_scherer_2008" class="flyoverdiv">Zentner, Marcel R., Didier Grandjean, and Klaus R. Scherer. 2008. &#8220;Emotions Evoked by the Sound of Music: Characterization, Classification, and Measurement.&#8221; <i>Emotion </i>8:<i> </i>494&#8211;521. </div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="zentner_grandjean_and_scherer_2008"></a>Zentner, Marcel R., Didier Grandjean, and Klaus R. Scherer. 2008. &#8220;Emotions Evoked by the Sound of Music: Characterization, Classification, and Measurement.&#8221; <i>Emotion </i>8:<i> </i>494&#8211;521. </p>
       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	<!-------------------------------- Footnotes List -------------------------------------------->

    	
	<hr>
	
	<h3><a name="Footnotes">Footnotes</a></h3>
	
	           <p><a name="FN0">*</a> I would like to thank Sharon Morrow for her generous help in recruiting and running students at Westminster Choir College of Rider University.<br><a href="#FN0REF">Return to text</a></p><div id="fndiv0" class="flyoverdiv">I would like to thank Sharon Morrow for her generous help in recruiting and running students at Westminster Choir College of Rider University.</div><p><a name="FN1">1.</a> Sisman (<a href="#sisman_1994" id="citation_sisman_1994_67dc99ab77697">1994</a>) provides an excellent discussion of the role of <i>pathos</i> in the eighteenth century and how this relates directly to the form of musical expression taken in the <i>Path&eacute;tique</i> Sonata.<br><a href="#FN1REF">Return to text</a></p><p><a name="FN2">2.</a> For a more detailed discussion of the gap between music theories and scientific theories, focusing on the problem of falsifiability and rigorous scientific testing, see <a href="#wiggins_m&uuml;llensiefen_and_pearce_2010" id="citation_wiggins_m&uuml;llensiefen_and_pearce_2010_67dc99ab7769f">Wiggins, M&uuml;llensiefen, and Pearce 2010</a>.<br><a href="#FN2REF">Return to text</a></p><p><a name="FN3">3.</a> Readers more generally suspicious about expressive analysis may take issue with my assumption that &#8216;the music&#8217; expresses anything at all emotionally, which has famously been the subject of much philosophical discussion. For example, Davies (<a href="#davies_1994" id="citation_davies_1994_67dc99ab776a4">1994</a>) and Kivy (<a href="#kivy_1980" id="citation_kivy_1980_67dc99ab776a7">1980</a>) reject the notion that music expresses emotion directly as a reflection of some internal emotion or intention of the composer. Rather, they argue that musical features reveal the appearance of characteristics that typically co-occur with various emotions, but are not direct expressions of emotions themselves, in the same way that basset hounds look sad while not necessarily feeling sad. Under this paradigm, listeners who think the music is expressing emotion are simply assigning an emotion to acoustical patterns they <i>perceive</i> as emotional through association.<br><br>Instead of wrestling with the ontological question of musical agency, I will rather take a practical approach by focusing on the emotional expression <i>perceived by</i> the listener. If the focus of the study is then entirely on what the listener perceives, in what sense does an analysis regard the music at all? Would the emotional responses evoked in the listener by the music best be regarded as arbitrary? Hatten&#8217;s (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab776ac">2004</a>) answer to this question again lies in the notion of intersubjective agreement between listeners. Sidestepping the problem of agency, there can still be communally recognized expression attached to particular musical gestures. Even if one avoids the agential implication that musical gestures actually &#8220;communicate&#8221; these emotions, one can still speak about patterns of emotional expression that are correlated with these gestures reliably over time and between listeners. If particular musical structures reliably evoke expressive connotations, then one may say that those gestures are expressive of those emotional states.<br><a href="#FN3REF">Return to text</a></p><p><a name="FN4">4.</a> For example, listeners tend to be much more interpersonally and intrapersonally reliable when judging perceived emotion than induced emotion (<a href="#juslin_and_laukka_2004" id="citation_juslin_and_laukka_2004_67dc99ab776b0">Juslin and Laukka 2004</a>). The emotion aroused by music is notoriously impacted by much more than just the music itself; time of day, personal circumstances, one&rsquo;s current mood and arousal levels, the environment in which the music is heard, and the degree to which a listener is attending to the music all can impact the emotion felt in response to music much more strongly than the emotion perceived in the music. There are also stronger differences between listeners regarding felt than perceived emotion (<a href="#gabrielsson_2002" id="citation_gabrielsson_2002_67dc99ab776b3">Gabrielsson 2002</a>). For example, the research on <i>frisson</i>, the experience of music-induced goose bumps or chills, indicates that while the experience is reliable for listeners in specific moments in music (<a href="#sloboda_1991" id="citation_sloboda_1991_67dc99ab776b6">Sloboda 1991</a>), there are low levels of correlation between listeners for the same excerpt (<a href="#blood_and_zatorre_2001" id="citation_blood_and_zatorre_2001_67dc99ab776ba">Blood and Zatorre 2001</a>) &#8212; music that induces <i>frisson</i> for one listener leaves another unmoved and vice versa.<br><a href="#FN4REF">Return to text</a></p><p><a name="FN5">5.</a> Although I will be focusing on perceived emotion, the instructions that I give to the participants do not always reflect this. Framing my prompts with these kinds of subtle philosophical distinctions would likely unnecessarily complicate the issue for the participants of the study. Although in my instructions I routinely refer to concepts like &#8220;the emotions you think the music is trying to express or convey,&#8221; it is important to remember that my inquiry is limited to the perceptions of emotional expression that are correlated with the musical gestures heard, rather than any essentialized claim of the ontological reality of agency in the music.<br><a href="#FN5REF">Return to text</a></p><p><a name="FN6">6.</a> Hatten&#8217;s (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab776be">2004</a>, 94) definition of musical gesture also suggests a minimum segment length. Hatten considers gestures to be &#8220;perceptually <i>synthetic</i> gestalts with <i>emergent</i> meaning&#8221; that consist, among other things, of &#8220;specific timbres, articulations, dynamics, tempi, pacing, and their coordination with various syntactic levels (e.g., voice-leading, metric placement, phrase structure).&#8221; Moreover, gestures are units &#8220;in the perceptual present (typically within two seconds).&#8221; According to this definition, segments should be at least two seconds in length to capture musical gestures.<br><a href="#FN6REF">Return to text</a></p><p><a name="FN7">7.</a> As Kendall and Carterette (<a href="#kendall_and_carterette_1990" id="citation_kendall_and_carterette_1990_67dc99ab776c3">1990</a>) argue, one way of conceptualizing the emotional meaning a listener perceives a work to be expressing is as the intersection of at least the compositional intent of the composer and the interpretation of the performer. Similarly, Juslin and Lindstr&ouml;m (<a href="#juslin_and_lindstr&oulm;m_2011" id="citation_juslin_and_lindstr&oulm;m_2011_67dc99ab776c7">2011</a>) have shown that the way that listeners perceive emotional expression in music involves a complicated combination of structural and performative elements.<br><a href="#FN7REF">Return to text</a></p><p><a name="FN8">8.</a> This approach was systematized in a fascinating study by Repp (<a href="#repp_1997" id="citation_repp_1997_67dc99ab776cb">1997</a>). In this study, Repp averaged together the mictrotiming decisions of ten different performances of Schumann&#8217;s <i>Traumerei</i> and compared this &#8220;average&#8221; performance to the original ten recordings. The average was rated second highest in quality, but second lowest in individuality. He did the same with thirty performances of Chopin&#8217;s Etude in E major and found similarly high ratings of quality and low ratings of individuality. Similar studies have been conducted by Sapp (<a href="#sapp_2007" id="citation_sapp_2007_67dc99ab776ce">2007</a> and <a href="#sapp_2008" id="citation_sapp_2008_67dc99ab776d2">2008</a>) on large collections of Chopin&#8217;s mazurkas. See also: The Mazurka Project (<a href="http://www.mazurka.org.uk">http://www.mazurka.org.uk</a>). Unfortunately, at the time of the study no &#8220;average&#8221; recording of the second movement of Beethoven&#8217;s <i>Path&eacute;tique</i> Sonata was available.<br><a href="#FN8REF">Return to text</a></p><p><a name="FN9">9.</a> Interested readers are referred to Juslin and Sloboda (<a href="#juslin_and_sloboda_2010" id="citation_juslin_and_sloboda_2010_67dc99ab776d6">2010</a>) for a detailed survey of different approaches with their strengths and weaknesses. By way of quick summary, common approaches include free response descriptions, looking at a small number of &#8220;basic emotions&#8221; (e.g. <a href="#ekman_1992" id="citation_ekman_1992_67dc99ab776d9">Ekman 1992</a>), a dimensional model in which all emotions are plotted in a continuous space consisting of a small number of dimensions such as arousal and valence (e.g. <a href="#hevner_1936" id="citation_hevner_1936_67dc99ab776dc">Hevner 1936</a>, <a href="#russell_1980" id="citation_russell_1980_67dc99ab776df">Russell 1980</a>), or compiling an eclectic list of terms deemed appropriate for the music under study (e.g. <a href="#zentner_grandjean_and_scherer_2008" id="citation_zentner_grandjean_and_scherer_2008_67dc99ab776e2">Zentner, Grandjean, and Scherer 2008</a>). This paper uses a modified version of the strategy suggested by Zentner et al. (<a href="#zentner_grandjean_and_scherer_2008" id="citation_zentner_grandjean_and_scherer_2008_67dc99ab776e6">2008</a>).<br><a href="#FN9REF">Return to text</a></p><p><a name="FN10">10.</a> See footnote 4.<br><a href="#FN10REF">Return to text</a></p><p><a name="FN11">11.</a> Intra-participant reliability could not be calculated for cheeky/sassy due to a mathematical property of correlations in which they are unable to be directly averaged when they are exactly +1. Because cheeky/sassy ratings were exactly 0 for all segments tested, the correlations were unable to be calculated. Moreover, post-experiment interviews revealed that many participants found this category was not relevant to the movement, and so it was discarded from further consideration.<br><a href="#FN11REF">Return to text</a></p><p><a name="FN12">12.</a> <a href="#robinson_2005" id="citation_robinson_2005_67dc99ab776e9">Robinson 2005</a> argues that categories like &#8220;being moved&#8221; might simply reflect <i>that</i> a listener is emotionally affected without specifying <i>in what way</i> they are affected.<br><a href="#FN12REF">Return to text</a></p><p><a name="FN13">13.</a> To illustrate this point, consider the most two extreme participants. For the sake of comparison, we will assign 1 to the extreme left of the scale and 7 to the extreme right of the scale, with a midpoint of 4. The most positive participant has an average rating of 5.2, and the most negative participant has an average rating of 2.6. The lowest rating for the positive participant is 2.3; although significantly low for that participant, it would only be slightly below average for the negative participant. Likewise, the highest rating for the negative participant is 6.2; although significantly high for that participant, nearly 20% of the positive participant&#8217;s ratings are above that mark. For these reasons, using standard deviations provides a useful means of controlling participant scale-usage style and identifying which segments participants find exceptional against the context of the movement. By focusing on exceptional moments within the context of a movement, this empirically derived expressive analysis more closely mirrors traditional analyses.<br><a href="#FN13REF">Return to text</a></p><p><a name="FN14">14.</a> The tool works best on Google Chrome, and takes a few seconds to load the first time. For more help in using the tool, consult the &ldquo;Detailed Instructions&rdquo; tab of the tool.<br><a href="#FN14REF">Return to text</a></p><p><a name="FN15">15.</a> These results are consistent with traditional associations of the minor mode with negatively valenced emotion and faster rhythms with higher levels of arousal.<br><a href="#FN15REF">Return to text</a></p><p><a name="FN16">16.</a> This observation is consistent with Robinson and Hatten&#8217;s (<a href="#robinson_and_hatten_2012" id="citation_robinson_and_hatten_2012_67dc99ab776ed">2012</a>) notion of musical voices as agents or personae in a musical drama. In this case, it is likely that the two contrasting gestures may actually imply different agents or personae, as discussed in <a href="#hatten_2004" id="citation_hatten_2004_67dc99ab776f0">Hatten 2004</a>: &#8220;In terms of agency, the two contrasting gestural types.&nbsp;.&nbsp;.suggest the roles of protagonist and antagonist in conflict dramas, or more neutrally, actant and negactant&#8221; (225).<br><a href="#FN16REF">Return to text</a></p><p><a name="FN17">17.</a> Formally, this observation is statistically significant, t(1152.116) = -6.6, <i>p</i> &lt; .0001.<br><a href="#FN17REF">Return to text</a></p><p><a name="FN18">18.</a> Blending cognitively complex emotions is an important component of an effective emotion paradigm according to Robinson and Hatten (<a href="#robinson_and_hatten_2012" id="citation_robinson_and_hatten_2012_67dc99ab776f3">2012</a>, 71): &#8220;We claim that sometimes music can appropriately be heard as containing a &lsquo;persona&rsquo;.&nbsp;.&nbsp;. and that this persona can be experienced as expressing more <i>complex</i> emotions, such as hopefulness or resignation, as well as <i>blends</i> of emotion, and emotions that <i>develop and change</i> over time.&#8221; Robinson and Hatten (<a href="#robinson_and_hatten_2012" id="citation_robinson_and_hatten_2012_67dc99ab776f7">2012</a>, 71). Zentner et al. (<a href="#zentner_grandjean_and_scherer_2008" id="citation_zentner_grandjean_and_scherer_2008_67dc99ab776fb">2008</a>) likewise argues that music is particularly suited to express cognitively complex emotions; their research found, for example, that tender-longing is a particularly common emotion in musical expression, although it is often neglected because it is more complex than the set of &#8216;basic&#8217; emotions most often studied.<br><a href="#FN18REF">Return to text</a></p><p><a name="FN19">19.</a> Experimental paradigms usually force a tradeoff between ecological validity and experimental control, with more rigorous experimental designs manipulating specific musical features, but without any other musical context (for an overview, see <a href="#gabrielsson_and_lindstr&ouml;m_2010" id="citation_gabrielsson_and_lindstr&ouml;m_2010_67dc99ab776ff">Gabrielsson and Lindstr&ouml;m 2010</a>). Experimenters have manipulated mode (<a href="#heinlein_1928" id="citation_heinlein_1928_67dc99ab77702">Heinlein 1928</a>, <a href="#crowder_1985" id="citation_crowder_1985_67dc99ab77705">Crowder 1985</a>), rhythm and tempo (<a href="#de_la_motte-haber_1968" id="citation_de_la_motte-haber_1968_67dc99ab77708">de la Motte-Haber 1968</a>), melodic properties (<a href="#gabriel_1978" id="citation_gabriel_1978_67dc99ab7770b">Gabriel 1978</a>, <a href="#kaminska_and_woolf_2000" id="citation_kaminska_and_woolf_2000_67dc99ab7770f">Kaminska and Woolf 2000</a>), and synthesized tone sequences (<a href="#scherer_and_oshinsky_1977" id="citation_scherer_and_oshinsky_1977_67dc99ab77712">Scherer and Oshinsky 1977</a>) to attempt to assess the influence that these musical factors exert on perceived emotion. While permitting a high level of experimental control, the artificially constructed stimuli used in these experiments raise questions about the level to which this actually mirrors real listening situations.<br><br>By contrast, a different approach utilizes excerpts from real music and asks listeners to rate perceived emotion in these excerpts. Some approaches (e.g. <a href="#tagg_2006" id="citation_tagg_2006_67dc99ab77715">Tagg 2006</a>) ask listeners to write down free responses to real musical excerpts while others (<a href="#watson_1942" id="citation_watson_1942_67dc99ab77718">Watson 1942</a>) use a forced-choice paradigm. While this approach more closely reflects real listening situations, the stimuli used are very complicated real pieces of music, composed of so many musical parameters that it can be difficult to generalize about any specific parameters.<br><a href="#FN19REF">Return to text</a></p><p><a name="FN20">20.</a> Even literally repeated notation does not result in identical perceptions. Of course, the performance may be different, but even acoustically identical literal repetition, such as the difference between an initiating or continuing function, will be perceived differently as a matter of form or function: &#8220;At a minimum, a repeated element will sound different from its initial presentation by virtue of coming later and having been heard before. More subtly, it will sound different as a function of its position within the unfolding series of metric projection&#8221; (<a href="#margulis_2013" id="citation_margulis_2013_67dc99ab7771c">Margulis 2013</a>, 35).<br><a href="#FN20REF">Return to text</a></p><p><a name="FN21">21.</a> Narmour (<a href="#narmour_1990" id="citation_narmour_1990_67dc99ab77720">1990</a> and <a href="#narmour_1992" id="citation_narmour_1992_67dc99ab77723">1992</a>) theorized that reversals of implication or uncertain realizations would be accompanied by stronger emotional response. Similarly, Huron (<a href="#huron_2006" id="citation_huron_2006_67dc99ab77726">2006</a>) has outlined the role that unrealized expectation or uncertain continuation plays in heightening the emotional experience of a passage. For a more extensive overview, see <a href="#gabrielsson_and_lindstr&ouml;m_2010" id="citation_gabrielsson_and_lindstr&ouml;m_2010_67dc99ab7772a">Gabrielsson and Lindstr&ouml;m 2010</a>.<br><a href="#FN21REF">Return to text</a></p><p><a name="FN22">22.</a> Hepokoski and Darcy (<a href="#hepokoski_and_darcy_2006" id="citation_hepokoski_and_darcy_2006_67dc99ab7772e">2006</a>, 398&#8211;399) describe the particular character of a rondo refrain as light, playful, and tuneful, also citing Cole (<a href="#cole_2001" id="citation_cole_2001_67dc99ab77732">2001</a>), who describes rondo themes are simple and tuneful. Episodes, by contrast, are much less predictable and permit a wide variety of formulae. In describing specifically the second episode, or couplet, of a 5-part rondo, Caplin (<a href="#caplin_1998" id="citation_caplin_1998_67dc99ab77735">1998</a>, 234) points out the unpredictability of this formal section by saying, &#8220;[s]uch a wide variety of formal procedures can be found at this point in the form that generalizations are difficult to make. Most such cases have a certain development-like quality about them. Indeed, a few are organized along the lines of a true development section.&#8221;<br><a href="#FN22REF">Return to text</a></p><p><a name="FN23">23.</a> This difference was statistically significant, t(16596.26) = -27.77, <i>p</i> &lt; .0001.<br><a href="#FN23REF">Return to text</a></p><p><a name="FN24">24.</a> &#8220;Three varieties of deviation may be distinguished. (1) The normal, or probable, consequent event may be delayed. Such a delay may be purely temporal or it may also involve reaching the consequent through a less direct route, provided that the deviation is understandable as a means to the end in view. (2) The antecedent situation may be ambiguous. That is, several equally probable consequents may be envisaged. When this takes place, our automatic habit responses are inadequate, for they are attuned only to a clear decision about probabilities. And (3) there may be neither delay nor ambiguity, but the consequent event may be unexpected &#8211; improbable in the particular context&#8221; (<a href="#meyer_1967" id="citation_meyer_1967_67dc99ab77738">Meyer 1967</a>, 10&#8211;11).<br><a href="#FN24REF">Return to text</a></p><p><a name="FN25">25.</a> &#8220;the relationships between units of language are more important than any intrinsic properties of those units.&#8221;<br><a href="#FN25REF">Return to text</a></p><p><a name="FN26">26.</a> &#8220;the fusion of topics.&nbsp;.&nbsp;.is <i>emergent</i>, or beyond the mere sum of the correlations of each topic.&#8221;<br><a href="#FN26REF">Return to text</a></p><p><a name="FN27">27.</a> &#8220;pitch contour alone does not provide uniform results, given the many variables affecting our interpretation of such contours: metric placement and rhythmic duration, harmonic setting, articulation, dynamics, timing (both tempo and pacing), orchestration, and the like&#8221; (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab7773c">Hatten 2004</a>, 150).<br><a href="#FN27REF">Return to text</a></p><p><a name="FN28">28.</a> &#8220;a gestural accounting for all of these variables at least as a &#8216;fuzzy set&#8217;.&nbsp;.&nbsp;.can help us evaluate their contribution to an emergent affect&#8221; (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab7773f">Hatten 2004</a>, 150).<br><a href="#FN28REF">Return to text</a></p><p><a name="FN29">29.</a> See <a href="#lartillot_and_toiviainen_2007" id="citation_lartillot_and_toiviainen_2007_67dc99ab77742">Lartillot and Toiviainen 2007</a> and <a href="#eerola_2016" id="citation_eerola_2016_67dc99ab77745">Eerola 2016</a>. There are fifteen entries in the table because the pitch height variable is actually two separately encoded values&#8212;the highest and lowest pitch in semitones.<br><a href="#FN29REF">Return to text</a></p><p><a name="FN30">30.</a> The &#8220;variance&#8221; values in a regression model (technically adjusted R2) indicate how much of the variance in listener response can be explained through the analysis of the given musical features alone. All models were able to explain 19-38% of the variance in participant response.<br><a href="#FN30REF">Return to text</a></p><p><a name="FN31">31.</a> An imperfect analogy can be made between the pastoral topic and the calm/serene category. According to Hatten, this topic would be correlated with the major mode and slower harmonic tempi. In this movement calm/serene is indeed correlated with the major mode, although calm/serene is actually associated with faster harmonic tempi in this movement. For Hatten, turns to the minor mode and marked dissonance lead to increased agitation. As predicted, unsettled/anxious is correlated with the minor mode. However, harmonic dissonance was not significantly correlated with unsettled/anxious ratings in this movement, although the results are not incompatible with Hatten&#8217;s theory. Hatten associates yearning with upward melodic motion. While, contrary to expectation, pitch direction was not significantly related to striving/yearning, the emotion was associated with a lower lowest pitch. As one last example, Hatten associates greater harmonic dissonance (specifically the diminished seventh chord) with increased anguish or grief. While the analysis is not fine-grained enough to distinguish types of dissonance, in this movement sad/depressed/tragic was not significantly correlated with the level of dissonance in the harmony.<br><a href="#FN31REF">Return to text</a></p><p><a name="FN32">32.</a> This point extends to any applications of this research to topic theory more broadly. The correspondence between the expressive categories tested and topic theory discussed is not exact, which may account for some of the discrepancies. Additionally, the analysis used in the regression equations in many cases is not fine-grained enough to neatly map onto predictions about gestures in music broadly construed.<br><a href="#FN32REF">Return to text</a></p><p><a name="FN33">33.</a> Where True = truthful/sincere, Moody = emotional/moody, Joy = happy/joyful, Import = important/serious, Yearn = striving/yearning, Weight = weighty, and Sad = sad/depressed/tragic.<br><a href="#FN33REF">Return to text</a></p><div id="fndiv1" class="flyoverdiv">Sisman (<a href="#sisman_1994" id="citation_sisman_1994_67dc99ab77697">1994</a>) provides an excellent discussion of the role of <i>pathos</i> in the eighteenth century and how this relates directly to the form of musical expression taken in the <i>Path&eacute;tique</i> Sonata.</div><div id="fndiv2" class="flyoverdiv">For a more detailed discussion of the gap between music theories and scientific theories, focusing on the problem of falsifiability and rigorous scientific testing, see <a href="#wiggins_m&uuml;llensiefen_and_pearce_2010" id="citation_wiggins_m&uuml;llensiefen_and_pearce_2010_67dc99ab7769f">Wiggins, M&uuml;llensiefen, and Pearce 2010</a>.</div><div id="fndiv3" class="flyoverdiv">Readers more generally suspicious about expressive analysis may take issue with my assumption that &#8216;the music&#8217; expresses anything at all emotionally, which has famously been the subject of much philosophical discussion. For example, Davies (<a href="#davies_1994" id="citation_davies_1994_67dc99ab776a4">1994</a>) and Kivy (<a href="#kivy_1980" id="citation_kivy_1980_67dc99ab776a7">1980</a>) reject the notion that music expresses emotion directly as a reflection of some internal emotion or intention of the composer. Rather, they argue that musical features reveal the appearance of characteristics that typically co-occur with various emotions, but are not direct expressions of emotions themselves, in the same way that basset hounds look sad while not necessarily feeling sad. Under this paradigm, listeners who think the music is expressing emotion are simply assigning an emotion to acoustical patterns they <i>perceive</i> as emotional through association.<br><br>Instead of wrestling with the ontological question of musical agency, I will rather take a practical approach by focusing on the emotional expression <i>perceived by</i> the listener. If the focus of the study is then entirely on what the listener perceives, in what sense does an analysis regard the music at all? Would the emotional responses evoked in the listener by the music best be regarded as arbitrary? Hatten&#8217;s (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab776ac">2004</a>) answer to this question again lies in the notion of intersubjective agreement between listeners. Sidestepping the problem of agency, there can still be communally recognized expression attached to particular musical gestures. Even if one avoids the agential implication that musical gestures actually &#8220;communicate&#8221; these emotions, one can still speak about patterns of emotional expression that are correlated with these gestures reliably over time and between listeners. If particular musical structures reliably evoke expressive connotations, then one may say that those gestures are expressive of those emotional states.</div><div id="fndiv4" class="flyoverdiv">For example, listeners tend to be much more interpersonally and intrapersonally reliable when judging perceived emotion than induced emotion (<a href="#juslin_and_laukka_2004" id="citation_juslin_and_laukka_2004_67dc99ab776b0">Juslin and Laukka 2004</a>). The emotion aroused by music is notoriously impacted by much more than just the music itself; time of day, personal circumstances, one&rsquo;s current mood and arousal levels, the environment in which the music is heard, and the degree to which a listener is attending to the music all can impact the emotion felt in response to music much more strongly than the emotion perceived in the music. There are also stronger differences between listeners regarding felt than perceived emotion (<a href="#gabrielsson_2002" id="citation_gabrielsson_2002_67dc99ab776b3">Gabrielsson 2002</a>). For example, the research on <i>frisson</i>, the experience of music-induced goose bumps or chills, indicates that while the experience is reliable for listeners in specific moments in music (<a href="#sloboda_1991" id="citation_sloboda_1991_67dc99ab776b6">Sloboda 1991</a>), there are low levels of correlation between listeners for the same excerpt (<a href="#blood_and_zatorre_2001" id="citation_blood_and_zatorre_2001_67dc99ab776ba">Blood and Zatorre 2001</a>) &#8212; music that induces <i>frisson</i> for one listener leaves another unmoved and vice versa.</div><div id="fndiv5" class="flyoverdiv">Although I will be focusing on perceived emotion, the instructions that I give to the participants do not always reflect this. Framing my prompts with these kinds of subtle philosophical distinctions would likely unnecessarily complicate the issue for the participants of the study. Although in my instructions I routinely refer to concepts like &#8220;the emotions you think the music is trying to express or convey,&#8221; it is important to remember that my inquiry is limited to the perceptions of emotional expression that are correlated with the musical gestures heard, rather than any essentialized claim of the ontological reality of agency in the music.</div><div id="fndiv6" class="flyoverdiv">Hatten&#8217;s (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab776be">2004</a>, 94) definition of musical gesture also suggests a minimum segment length. Hatten considers gestures to be &#8220;perceptually <i>synthetic</i> gestalts with <i>emergent</i> meaning&#8221; that consist, among other things, of &#8220;specific timbres, articulations, dynamics, tempi, pacing, and their coordination with various syntactic levels (e.g., voice-leading, metric placement, phrase structure).&#8221; Moreover, gestures are units &#8220;in the perceptual present (typically within two seconds).&#8221; According to this definition, segments should be at least two seconds in length to capture musical gestures.</div><div id="fndiv7" class="flyoverdiv">As Kendall and Carterette (<a href="#kendall_and_carterette_1990" id="citation_kendall_and_carterette_1990_67dc99ab776c3">1990</a>) argue, one way of conceptualizing the emotional meaning a listener perceives a work to be expressing is as the intersection of at least the compositional intent of the composer and the interpretation of the performer. Similarly, Juslin and Lindstr&ouml;m (<a href="#juslin_and_lindstr&oulm;m_2011" id="citation_juslin_and_lindstr&oulm;m_2011_67dc99ab776c7">2011</a>) have shown that the way that listeners perceive emotional expression in music involves a complicated combination of structural and performative elements.</div><div id="fndiv8" class="flyoverdiv">This approach was systematized in a fascinating study by Repp (<a href="#repp_1997" id="citation_repp_1997_67dc99ab776cb">1997</a>). In this study, Repp averaged together the mictrotiming decisions of ten different performances of Schumann&#8217;s <i>Traumerei</i> and compared this &#8220;average&#8221; performance to the original ten recordings. The average was rated second highest in quality, but second lowest in individuality. He did the same with thirty performances of Chopin&#8217;s Etude in E major and found similarly high ratings of quality and low ratings of individuality. Similar studies have been conducted by Sapp (<a href="#sapp_2007" id="citation_sapp_2007_67dc99ab776ce">2007</a> and <a href="#sapp_2008" id="citation_sapp_2008_67dc99ab776d2">2008</a>) on large collections of Chopin&#8217;s mazurkas. See also: The Mazurka Project (<a href="http://www.mazurka.org.uk">http://www.mazurka.org.uk</a>). Unfortunately, at the time of the study no &#8220;average&#8221; recording of the second movement of Beethoven&#8217;s <i>Path&eacute;tique</i> Sonata was available.</div><div id="fndiv9" class="flyoverdiv">Interested readers are referred to Juslin and Sloboda (<a href="#juslin_and_sloboda_2010" id="citation_juslin_and_sloboda_2010_67dc99ab776d6">2010</a>) for a detailed survey of different approaches with their strengths and weaknesses. By way of quick summary, common approaches include free response descriptions, looking at a small number of &#8220;basic emotions&#8221; (e.g. <a href="#ekman_1992" id="citation_ekman_1992_67dc99ab776d9">Ekman 1992</a>), a dimensional model in which all emotions are plotted in a continuous space consisting of a small number of dimensions such as arousal and valence (e.g. <a href="#hevner_1936" id="citation_hevner_1936_67dc99ab776dc">Hevner 1936</a>, <a href="#russell_1980" id="citation_russell_1980_67dc99ab776df">Russell 1980</a>), or compiling an eclectic list of terms deemed appropriate for the music under study (e.g. <a href="#zentner_grandjean_and_scherer_2008" id="citation_zentner_grandjean_and_scherer_2008_67dc99ab776e2">Zentner, Grandjean, and Scherer 2008</a>). This paper uses a modified version of the strategy suggested by Zentner et al. (<a href="#zentner_grandjean_and_scherer_2008" id="citation_zentner_grandjean_and_scherer_2008_67dc99ab776e6">2008</a>).</div><div id="fndiv10" class="flyoverdiv">See footnote 4.</div><div id="fndiv11" class="flyoverdiv">Intra-participant reliability could not be calculated for cheeky/sassy due to a mathematical property of correlations in which they are unable to be directly averaged when they are exactly +1. Because cheeky/sassy ratings were exactly 0 for all segments tested, the correlations were unable to be calculated. Moreover, post-experiment interviews revealed that many participants found this category was not relevant to the movement, and so it was discarded from further consideration.</div><div id="fndiv12" class="flyoverdiv"><a href="#robinson_2005" id="citation_robinson_2005_67dc99ab776e9">Robinson 2005</a> argues that categories like &#8220;being moved&#8221; might simply reflect <i>that</i> a listener is emotionally affected without specifying <i>in what way</i> they are affected.</div><div id="fndiv13" class="flyoverdiv">To illustrate this point, consider the most two extreme participants. For the sake of comparison, we will assign 1 to the extreme left of the scale and 7 to the extreme right of the scale, with a midpoint of 4. The most positive participant has an average rating of 5.2, and the most negative participant has an average rating of 2.6. The lowest rating for the positive participant is 2.3; although significantly low for that participant, it would only be slightly below average for the negative participant. Likewise, the highest rating for the negative participant is 6.2; although significantly high for that participant, nearly 20% of the positive participant&#8217;s ratings are above that mark. For these reasons, using standard deviations provides a useful means of controlling participant scale-usage style and identifying which segments participants find exceptional against the context of the movement. By focusing on exceptional moments within the context of a movement, this empirically derived expressive analysis more closely mirrors traditional analyses.</div><div id="fndiv14" class="flyoverdiv">The tool works best on Google Chrome, and takes a few seconds to load the first time. For more help in using the tool, consult the &ldquo;Detailed Instructions&rdquo; tab of the tool.</div><div id="fndiv15" class="flyoverdiv">These results are consistent with traditional associations of the minor mode with negatively valenced emotion and faster rhythms with higher levels of arousal.</div><div id="fndiv16" class="flyoverdiv">This observation is consistent with Robinson and Hatten&#8217;s (<a href="#robinson_and_hatten_2012" id="citation_robinson_and_hatten_2012_67dc99ab776ed">2012</a>) notion of musical voices as agents or personae in a musical drama. In this case, it is likely that the two contrasting gestures may actually imply different agents or personae, as discussed in <a href="#hatten_2004" id="citation_hatten_2004_67dc99ab776f0">Hatten 2004</a>: &#8220;In terms of agency, the two contrasting gestural types.&nbsp;.&nbsp;.suggest the roles of protagonist and antagonist in conflict dramas, or more neutrally, actant and negactant&#8221; (225).</div><div id="fndiv17" class="flyoverdiv">Formally, this observation is statistically significant, t(1152.116) = -6.6, <i>p</i> &lt; .0001.</div><div id="fndiv18" class="flyoverdiv">Blending cognitively complex emotions is an important component of an effective emotion paradigm according to Robinson and Hatten (<a href="#robinson_and_hatten_2012" id="citation_robinson_and_hatten_2012_67dc99ab776f3">2012</a>, 71): &#8220;We claim that sometimes music can appropriately be heard as containing a &lsquo;persona&rsquo;.&nbsp;.&nbsp;. and that this persona can be experienced as expressing more <i>complex</i> emotions, such as hopefulness or resignation, as well as <i>blends</i> of emotion, and emotions that <i>develop and change</i> over time.&#8221; Robinson and Hatten (<a href="#robinson_and_hatten_2012" id="citation_robinson_and_hatten_2012_67dc99ab776f7">2012</a>, 71). Zentner et al. (<a href="#zentner_grandjean_and_scherer_2008" id="citation_zentner_grandjean_and_scherer_2008_67dc99ab776fb">2008</a>) likewise argues that music is particularly suited to express cognitively complex emotions; their research found, for example, that tender-longing is a particularly common emotion in musical expression, although it is often neglected because it is more complex than the set of &#8216;basic&#8217; emotions most often studied.</div><div id="fndiv19" class="flyoverdiv">Experimental paradigms usually force a tradeoff between ecological validity and experimental control, with more rigorous experimental designs manipulating specific musical features, but without any other musical context (for an overview, see <a href="#gabrielsson_and_lindstr&ouml;m_2010" id="citation_gabrielsson_and_lindstr&ouml;m_2010_67dc99ab776ff">Gabrielsson and Lindstr&ouml;m 2010</a>). Experimenters have manipulated mode (<a href="#heinlein_1928" id="citation_heinlein_1928_67dc99ab77702">Heinlein 1928</a>, <a href="#crowder_1985" id="citation_crowder_1985_67dc99ab77705">Crowder 1985</a>), rhythm and tempo (<a href="#de_la_motte-haber_1968" id="citation_de_la_motte-haber_1968_67dc99ab77708">de la Motte-Haber 1968</a>), melodic properties (<a href="#gabriel_1978" id="citation_gabriel_1978_67dc99ab7770b">Gabriel 1978</a>, <a href="#kaminska_and_woolf_2000" id="citation_kaminska_and_woolf_2000_67dc99ab7770f">Kaminska and Woolf 2000</a>), and synthesized tone sequences (<a href="#scherer_and_oshinsky_1977" id="citation_scherer_and_oshinsky_1977_67dc99ab77712">Scherer and Oshinsky 1977</a>) to attempt to assess the influence that these musical factors exert on perceived emotion. While permitting a high level of experimental control, the artificially constructed stimuli used in these experiments raise questions about the level to which this actually mirrors real listening situations.<br><br>By contrast, a different approach utilizes excerpts from real music and asks listeners to rate perceived emotion in these excerpts. Some approaches (e.g. <a href="#tagg_2006" id="citation_tagg_2006_67dc99ab77715">Tagg 2006</a>) ask listeners to write down free responses to real musical excerpts while others (<a href="#watson_1942" id="citation_watson_1942_67dc99ab77718">Watson 1942</a>) use a forced-choice paradigm. While this approach more closely reflects real listening situations, the stimuli used are very complicated real pieces of music, composed of so many musical parameters that it can be difficult to generalize about any specific parameters.</div><div id="fndiv20" class="flyoverdiv">Even literally repeated notation does not result in identical perceptions. Of course, the performance may be different, but even acoustically identical literal repetition, such as the difference between an initiating or continuing function, will be perceived differently as a matter of form or function: &#8220;At a minimum, a repeated element will sound different from its initial presentation by virtue of coming later and having been heard before. More subtly, it will sound different as a function of its position within the unfolding series of metric projection&#8221; (<a href="#margulis_2013" id="citation_margulis_2013_67dc99ab7771c">Margulis 2013</a>, 35).</div><div id="fndiv21" class="flyoverdiv">Narmour (<a href="#narmour_1990" id="citation_narmour_1990_67dc99ab77720">1990</a> and <a href="#narmour_1992" id="citation_narmour_1992_67dc99ab77723">1992</a>) theorized that reversals of implication or uncertain realizations would be accompanied by stronger emotional response. Similarly, Huron (<a href="#huron_2006" id="citation_huron_2006_67dc99ab77726">2006</a>) has outlined the role that unrealized expectation or uncertain continuation plays in heightening the emotional experience of a passage. For a more extensive overview, see <a href="#gabrielsson_and_lindstr&ouml;m_2010" id="citation_gabrielsson_and_lindstr&ouml;m_2010_67dc99ab7772a">Gabrielsson and Lindstr&ouml;m 2010</a>.</div><div id="fndiv22" class="flyoverdiv">Hepokoski and Darcy (<a href="#hepokoski_and_darcy_2006" id="citation_hepokoski_and_darcy_2006_67dc99ab7772e">2006</a>, 398&#8211;399) describe the particular character of a rondo refrain as light, playful, and tuneful, also citing Cole (<a href="#cole_2001" id="citation_cole_2001_67dc99ab77732">2001</a>), who describes rondo themes are simple and tuneful. Episodes, by contrast, are much less predictable and permit a wide variety of formulae. In describing specifically the second episode, or couplet, of a 5-part rondo, Caplin (<a href="#caplin_1998" id="citation_caplin_1998_67dc99ab77735">1998</a>, 234) points out the unpredictability of this formal section by saying, &#8220;[s]uch a wide variety of formal procedures can be found at this point in the form that generalizations are difficult to make. Most such cases have a certain development-like quality about them. Indeed, a few are organized along the lines of a true development section.&#8221;</div><div id="fndiv23" class="flyoverdiv">This difference was statistically significant, t(16596.26) = -27.77, <i>p</i> &lt; .0001.</div><div id="fndiv24" class="flyoverdiv">&#8220;Three varieties of deviation may be distinguished. (1) The normal, or probable, consequent event may be delayed. Such a delay may be purely temporal or it may also involve reaching the consequent through a less direct route, provided that the deviation is understandable as a means to the end in view. (2) The antecedent situation may be ambiguous. That is, several equally probable consequents may be envisaged. When this takes place, our automatic habit responses are inadequate, for they are attuned only to a clear decision about probabilities. And (3) there may be neither delay nor ambiguity, but the consequent event may be unexpected &#8211; improbable in the particular context&#8221; (<a href="#meyer_1967" id="citation_meyer_1967_67dc99ab77738">Meyer 1967</a>, 10&#8211;11).</div><div id="fndiv25" class="flyoverdiv">&#8220;the relationships between units of language are more important than any intrinsic properties of those units.&#8221;</div><div id="fndiv26" class="flyoverdiv">&#8220;the fusion of topics.&nbsp;.&nbsp;.is <i>emergent</i>, or beyond the mere sum of the correlations of each topic.&#8221;</div><div id="fndiv27" class="flyoverdiv">&#8220;pitch contour alone does not provide uniform results, given the many variables affecting our interpretation of such contours: metric placement and rhythmic duration, harmonic setting, articulation, dynamics, timing (both tempo and pacing), orchestration, and the like&#8221; (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab7773c">Hatten 2004</a>, 150).</div><div id="fndiv28" class="flyoverdiv">&#8220;a gestural accounting for all of these variables at least as a &#8216;fuzzy set&#8217;.&nbsp;.&nbsp;.can help us evaluate their contribution to an emergent affect&#8221; (<a href="#hatten_2004" id="citation_hatten_2004_67dc99ab7773f">Hatten 2004</a>, 150).</div><div id="fndiv29" class="flyoverdiv">See <a href="#lartillot_and_toiviainen_2007" id="citation_lartillot_and_toiviainen_2007_67dc99ab77742">Lartillot and Toiviainen 2007</a> and <a href="#eerola_2016" id="citation_eerola_2016_67dc99ab77745">Eerola 2016</a>. There are fifteen entries in the table because the pitch height variable is actually two separately encoded values&#8212;the highest and lowest pitch in semitones.</div><div id="fndiv30" class="flyoverdiv">The &#8220;variance&#8221; values in a regression model (technically adjusted R2) indicate how much of the variance in listener response can be explained through the analysis of the given musical features alone. All models were able to explain 19-38% of the variance in participant response.</div><div id="fndiv31" class="flyoverdiv">An imperfect analogy can be made between the pastoral topic and the calm/serene category. According to Hatten, this topic would be correlated with the major mode and slower harmonic tempi. In this movement calm/serene is indeed correlated with the major mode, although calm/serene is actually associated with faster harmonic tempi in this movement. For Hatten, turns to the minor mode and marked dissonance lead to increased agitation. As predicted, unsettled/anxious is correlated with the minor mode. However, harmonic dissonance was not significantly correlated with unsettled/anxious ratings in this movement, although the results are not incompatible with Hatten&#8217;s theory. Hatten associates yearning with upward melodic motion. While, contrary to expectation, pitch direction was not significantly related to striving/yearning, the emotion was associated with a lower lowest pitch. As one last example, Hatten associates greater harmonic dissonance (specifically the diminished seventh chord) with increased anguish or grief. While the analysis is not fine-grained enough to distinguish types of dissonance, in this movement sad/depressed/tragic was not significantly correlated with the level of dissonance in the harmony.</div><div id="fndiv32" class="flyoverdiv">This point extends to any applications of this research to topic theory more broadly. The correspondence between the expressive categories tested and topic theory discussed is not exact, which may account for some of the discrepancies. Additionally, the analysis used in the regression equations in many cases is not fine-grained enough to neatly map onto predictions about gestures in music broadly construed.</div><div id="fndiv33" class="flyoverdiv">Where True = truthful/sincere, Moody = emotional/moody, Joy = happy/joyful, Import = important/serious, Yearn = striving/yearning, Weight = weighty, and Sad = sad/depressed/tragic.</div>
       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- FOOTER -------------------------------------------->

    <hr>
<h3>Copyright Statement</h3>
<p><h4>Copyright &copy; 2018 by the Society for Music Theory. All rights reserved.</h4></p>
<p class="small">[1] Copyrights for individual items published in  <i>Music Theory Online</i> (<i>MTO</i>) 
are held by their authors. Items appearing in  <i>MTO</i> may be saved and stored in electronic or paper form, and may be shared among individuals for purposes of 
scholarly research or discussion, but may  <i>not</i>  be republished in any form, electronic or print, without prior, written permission from the author(s), and advance 
notification of the editors of  <i>MTO.</i></p>
<p class="small">[2] Any redistributed form of items published in  <i>MTO</i> must include the following information in a form appropriate to the medium in which the items are 
to appear: </p>
<blockquote>
<p class="small">This item appeared in  <i>Music Theory Online</i> in [VOLUME #, ISSUE #] on [DAY/MONTH/YEAR]. It was authored by [FULL NAME, EMAIL ADDRESS], with whose written 
permission it is reprinted here.</p>
</blockquote>
<p class="small">[3] Libraries may archive issues of  <i>MTO</i> in electronic or paper form for public access so long as each issue is stored in its entirety, and no access fee 
is charged. Exceptions to these requirements must be approved in writing by the editors of  <i>MTO,</i> who will act in accordance with the decisions of the Society 
for Music Theory. </p>
<p class="small">This document and all portions thereof are protected by U.S. and international copyright laws. Material contained herein may be copied and/or distributed for research 
purposes only. </p>
       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
    	

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 


<div style="width:55%;float:right"><a href="https://societymusictheory.org">
<img alt="SMT" longdesc="Society for Music Theory" src="https://mtosmt.org/gifs/smtlogo_black.png" width="180"></a></div>
	
<div>
<p style='font-size:1.1rem'>Prepared by Michael McClimon, Senior Editorial Assistant  


<br>
		
			<br>Number of visits:  

		12057		
	</p><br><br>
</i>		

</div>
</div>
</article>
</body>
</html>

