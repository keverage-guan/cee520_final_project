 
 

<link rel=StyleSheet href="../../scripts/mtostyle.css" type="text/css" media=all>

<!-------------------------------- HEADER -------------------------------------------->

	  
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> 
<head>

<title> MTO 16.2: Casacuberta, Review of Music and Probability</title>

<link rel="SHORTCUT ICON" href="https://www.mtosmt.org/gifs/favicon.ico">
<link rel="stylesheet" href="https://www.mtosmt.org/scripts/colorbox.css">
<link rel=StyleSheet href="https://www.mtosmt.org/scripts/mto-tufte.css" type="text/css" media=all>
<link rel="stylesheet" href="//code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

<script src="https://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">_uacct = "UA-968147-1"; urchinTracker();</script>

<script type="text/javascript" src="https://www.mtosmt.org/scripts/expandingMenu.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/dropdownMenu.js"></script>
<!--<script language="JavaScript" type="text/javascript" src="https://www.mtosmt.org/scripts/AC_QuickTime.js"></script>-->
<!--<script type="text/javascript" src="https://www.mtosmt.org/scripts/examples.js"></script>-->
<script type="text/javascript" src="https://www.mtosmt.org/scripts/hover.js"></script>  
<script src="https://code.jquery.com/jquery-1.10.2.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
<script src="https://www.mtosmt.org/scripts/colorbox-master/jquery.colorbox.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/jQueryRotate.2.2.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script>
MathJax.Hub.Config({
    TeX: { noErrors: { disabled: true } }
});
</script>

  <script>
   $(function () {
      $(document).tooltip({
        position: { my: "center bottom-10", at: "center top", },
    content: function () {
              return $(this).prop('title');
          }
      });
  });
  </script>

  <style>
    .ui-tooltip {
      color: #3a3a3a;
      font: 300 14px/20px "Lato", "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
      max-width: 600px;
      box-shadow: 0 0 7px gray;
    }
    ol.mto-alpha {
        list-style: lower-alpha none outside;
    }
   ol.mto-alpha li {
       margin-bottom: 0.75em;
       margin-left: 2em;
       padding-left: 0.5em;
    }
  </style>

    <script language="Javascript">
        $(document).ready(function() {
            $(".mp3").colorbox({iframe:true, internalWidth:360, width:400, internalHeight:100, rel:'mp3', height:150, opacity:0.1, onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });
            $(".youtube").colorbox({iframe:true, innerWidth:640, innerHeight:390, opacity:0.1, rel:'youtube', onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });

      $("a[id^=footnote]").each(function(){
        var fnnum = $(this).attr('id').substring(8);
	var foot_me = '#fndiv'+fnnum;
        $("#footnote" + fnnum).attr('title', $(foot_me).html());

        });


        $("a[id^=citation]").each(function(){
         var separatorPos = $(this).attr('id').lastIndexOf('_');
         var linkid = $(this).attr('id');
         var citeref = $(this).attr('id').substring(8,separatorPos);
         var cite_me = '#citediv'+citeref;
         $("#" + linkid).attr('title', $(cite_me).html());

        });
    });

    </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-968147-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-968147-1');
</script>


<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 

<meta name="citation_title" content="Review of David Temperley, <i>Music and Probability</i> <br>(Cambridge: MIT Press, 2007)">

    <meta name="citation_author" content="Casacuberta, David">
      

<meta name="citation_publication_date" content="2010/03/01">
<meta name="citation_journal_title" content="Music Theory Online">
<meta name="citation_volume" content="16">
<meta name="citation_issue" content="2">

</head>

<body>
<div class="bannertop">
	<a id="smt-link" alt="Society for Music Theory" href="https://www.societymusictheory.org">&nbsp;</a>
</div>
		
		<div style = "height:160px; width:900px; background-image: url('../../gifs/banner_blue_grey_900px.png'); background-repeat: no-repeat; background-position: 0px 0px"></div>
		
<!-------------------------------- MENU -------------------------------------------->

	
<div class="dropdown_menu">

<ul class="fullwidth" id="ddm">
    <li><a href="https://www.mtosmt.org/index.php">MTO Home</a>
    </li>
    <li><a href="https://www.mtosmt.org/issues/mto.24.30.4/toc.30.4.html">Current Issue</a>    </li>
    <li><a href="https://www.mtosmt.org/issues/issues.php"
    	onmouseover="mopen('m3')" 
        onmouseout="mclosetime()">Previous Issues</a>
        <div id="m3" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/index-author.php">By Author</a>
	        <a href="https://www.mtosmt.org/issues/issues.php">By Volume&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
	</li>
	
    <li><a href="https://www.mtosmt.org/docs/authors.html.php"
    	onmouseover="mopen('m4')" 
        onmouseout="mclosetime()">For Authors</a>
        <div id="m4" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/mto-editorial-policy.html">MTO Editorial Policy</a>
	      <a href="https://www.mtosmt.org/docs/mto-style-guidelines.html">MTO Style Guidelines</a>
	      <a href="https://www.mtosmt.org/docs/how-to-submit-an-article-to-mto.html">How to Submit an Article</a>
	      <a href="https://www.mtosmt.org/ojs">Submit Article Online</a>
	      <a href="https://www.mtosmt.org/docs/reviewers.html">Book Review Guidelines</a>
        </div>
	</li>

 <!--   <li><a href="https://www.mtosmt.org/docs/authors.html">Submit</a>
	</li> -->
	
    <li><a href="https://www.mtosmt.org/mto-jobs.php"
    	onmouseover="mopen('m6')" 
        onmouseout="mclosetime()">Jobs</a>
        <div id="m6" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/mto-jobs.php">Current Job Listings</a>
	        <a href="https://www.mtosmt.org/mto-job-post.php">Submit Job Listing</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/docs/diss-index.php"
    	onmouseover="mopen('m7')" 
        onmouseout="mclosetime()">Dissertations</a>
        <div id="m7" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/diss-index.php">All Dissertations</a>
	        <a href="https://www.mtosmt.org/docs/diss-index.php?new=true">New Dissertations</a>
	        <a href="https://www.mtosmt.org/mto-diss-post.php">List Your Dissertation</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/about.html">About</a>
	</li>
<!--    <li><a href="https://www.mtosmt.org/mto_links.html">Journals</a>  
	</li> -->
    <li><a href="https://societymusictheory.org">SMT</a>
	</li>
   <!-- <li><a href="https://societymusictheory.org/announcement/contest-new-mto-logo-2024-02"><span style="color:yellow">Logo Design Contest</span></a>
	</li>-->

</ul>

</div>


<!-------------------------------- TITLE -------------------------------------------->

	<article>

<div id="content">
<a name="Beginning"></a>


	<h1 style="width:900px; margin-top:1em; font-size: 2.4rem;">Review of David Temperley, <i>Music and Probability</i> <br>(Cambridge: MIT Press, 2007)

	</h1>
	<div style="width:900px">
				</div>
				<h2><span style="font-weight: 400"><font size="5"><a style="color:black" href="#AUTHORNOTE1">David Casacuberta</a></font></span></h2><br><br>			
	<div style='width:800px'><div style='float:right; font-size:1.2rem;'><a href="http://www.mtosmt.org/issues/mto.10.16.2/mto.10.16.2.casacuberta.pdf">PDF text </a></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div>
			<div style="float:left; font-size:1.1rem;"><i>Received December 2009</i></div>
		<div style="width:850px">
	<div style="text-align:center; font-size: 1.1rem; margin-bottom:2em;margin-top:4em;margin-right:auto;margin-left:auto;width:870px">
		Volume 16, Number 2, March 2010 <br> Copyright &#0169; 2010 Society for Music Theory	</div>
	</div>

<hr style="width:850px"><br>
<section>
<!-------------------------------- ARTICLE BODY (begin) -------------------------------------->

<p style="text-align: center"><b>Introduction</b></p>

<p>[1] In <i>Music and Probability,</i> David Temperley presents a meaningful analysis of the cognitive resources implied in music perception, providing a sound and coherent series of models based on a probabilistic 
perspective.</p>

<p>[2] Cognitive sciences aim at understanding how our minds&#8212;and perhaps 
even artificial ones&#8212;are able to combine information about the external world with internal mental representations, in order to perform certain actions 
and achieve specific goals. Cognition gives us a more or less realistic, accurate perspective of the existence and behavior of the outside world. By processing 
this information we are able to plan our actions, solve problems, and obtain 
desired results (<a href="#von_eckardt_1993" id="citation_von_eckardt_1993_67dc9ae25fee8">Von Eckardt 1993</a>).</p>

<p>[3] Originally, cognitive sciences employed a symbolic approach. According to 
this paradigm, minds are viewed as symbolic processors, and syntactic rules&#8212;rules that correlate with the form of information only, not its contents&#8212;were enough in principle to represent knowledge and the way humans think and solve problems (<a href="#gardner_1985" id="citation_gardner_1985_67dc9ae25feec">Gardner 1985</a>). Since computers were particularly well suited to perform syntactic analysis, it seemed conceivable 
that one could turn them into cognitive agents (<a href="#turing_1950" id="citation_turing_1950_67dc9ae25feee">Turing 1950</a>).</p>

<p>[4] Due to its formal structure, music was one of the early targets in cognitive research. Several researchers and experimental musicians were convinced that music could be analyzed mathematically as some sort of code, and could 
therefore be artificially generated (<a href="#meyer_1967" id="citation_meyer_1967_67dc9ae25fef0">Meyer 1967</a>). Avant-garde artists dreamed of 
ensembles of humans and computers improvising in jam sessions. Those interested in cognitive processes and music believed we could understand those processes better by assimilating them into the way computers and humans processed syntax (<a href="#jackendoff_1983" id="citation_jackendoff_1983_67dc9ae25fef2">Jackendoff 1983</a>).</p>

<p>[5] When this paradigm proved to be too limiting (<a href="#dreyfus_1992" id="citation_dreyfus_1992_67dc9ae25fef3">Dreyfus 1992</a>, <a href="#varela_1991" id="citation_varela_1991_67dc9ae25fef5">Varela 1991</a>), emphasis was directed towards statistical and probabilistic approaches, the same as in <i>Music and Probability.</i> The older models, however, were &#8220;black box&#8221; approaches to mathematical generation of music. There was no attempt to give any psychological reality to models, despite the fact that this 
has been one of the main aims of the cognitive sciences since their inception  (<a href="#johnson-laird_1983" id="citation_johnson-laird_1983_67dc9ae25fef7">Johnson-Laird 1983</a>).</p>

<p>[6] Much of this earlier research mirrored cognitive science&#8217;s 
understanding of neural networks at the time (<a href="#rumelhart_1989" id="citation_rumelhart_1989_67dc9ae25fef8">Rumelhart 1989</a>). Neural networks were trained to recognize certain patterns and structures, and they did astonishing things that symbolic AI (Artificial Intelligence) could not. 
For example, they could recognize faces and speech, and they could play backgammon better than humans. Yet cognitive scientists could not explain how these networks worked. They found it very difficult to extract useful information, 
which would help them to better understand how humans perceive or generate music. An early appreciation of such difficulties within a probabilistic study of music can be found in Cohen (<a href="#cohen_1962" id="citation_cohen_1962_67dc9ae25fefb">1962</a>).</p>

<p>[7] Early statistical and probabilistic approaches only showed that, when 
humans recognize a musical passage, some sort of statistical process occurred in 
their neurons. Although the process was thought to be equivalent in some sense to that of neural networks, it was impossible to develop an algorithm that could 
predict what the cognitive processes would be like. This is a general problem that most probabilistic and neural networks models share, as stated in Clark (<a href="#clark_1989" id="citation_clark_1989_67dc9ae25fefd">1989</a>).</p>

<p>[8] <i>Music and Probability </i> is different from earlier probabilistic 
studies of music cognition. Temperley clearly understands mathematics, music, and cognitive sciences, and 
he successfully and convincingly combines them in his book. He leads the reader 
into a deeper interaction with cognitive processes. The reader learns how the 
brain uses the mathematical nature of music to perceive and create music.</p>

<p style="text-align: center"><b><i>Music and Probability?</i> Main Contents</b></p>

<p>[9] This book serves as an introductory and systematic course on the probabilistic analysis of music, and on how to use that approach in music theory as well as in the cognitive sciences. Its main goal, then, is to establish relationships between probability and musical style, in order to gain insight 
about music from a cognitive perspective.</p>

<p>[10] Temperley bases his theory on three principles:<br>
<ol>
<li>Perception is an inferential, multileveled, uncertain process.</li>
<li>Our knowledge of probability comes, in large part, from regularities in the environment.</li>
<li>Producers of communication are sensitive to, and affected by, its probabilistic nature.</li>
</ol>
<p>The application of these principles allows Temperley to go beyond the &#8220;black box&#8221; effect mentioned above, to bridge 
the gap between the probabilistic analysis of music and cognitive science.</p>

<p>[11] Once the objectives and main principles of the book are discussed, the author presents the basics of probability in a simple and clear 
manner so that the general reader can follow the calculations and proofs that appear throughout the text. After 
this introduction, the book presents relevant concepts as needed.</p>

<p>[12] In the book, the Bayesian approach to probability plays a central role. By means of the Bayes 
rule, one is able to make inferences about a hidden variable that is related to 
a structure not directly accessible, based on knowledge about an observable 
variable. Temperley does not apply the Bayesian approach as just a mathematical instrument 
used to make predictions. Rather, it shapes his theory about how our mind actually perceives specific musical elements such as dynamics, rhythm, chords, melody, harmony, and so on.</p>

<p>[13] It is important to keep in mind that neither rhythm nor pitch are perceived directly; our brains need to make several inferences in order to process the rhythm of a musical passage or to assign pitch (<a href="#parncutt_1994" id="citation_parncutt_1994_67dc9ae25ff10">Parncutt 1994</a>, <a href="#krumhansl_1990" id="citation_krumhansl_1990_67dc9ae25ff12">Krumhansl 1990</a>). The seemingly straightforward task of detecting the spatial origin of a sound is a complex cognitive issue that requires several neural systems working together.</p>

<p>[14] Using a Bayesian modeling of music perception, the author presents a formally coherent and cognitively realistic account of how basic musical categories such as rhythm or pitch are perceived. Based on those results he is also able to analyze common human expectations in music 
and how errors are detected. Further, he can explain some paradoxes in music perception.</p>

<p>[15] Temperley uses this understanding of basic music elements to build more ambitious models, which 
he applies in order to predict how humans process polyphonic music and determine keys. His model is then 
compared with experimental results of how humans detect key in polyphonic music so as to show the robustness and cognitive reality of the model.</p>

<p>[16] Temperley then focuses on the concept of &ldquo;tonalness,&rdquo; that is, 
&ldquo;the degree to which a segment of music is characteristic of the language of 
common-practice tonality&rdquo; (110). Tonalness is used to explain human perception and judgments 
of key relations, and to solve some problems of ambiguity.</p>

<p>[17] It could be argued that former probabilistic models have already dealt 
with such issues (<a href="#dixon_2001" id="citation_dixon_2001_67dc9ae25ff14">Dixon 2001</a>, <a href="#chew_2002" id="citation_chew_2002_67dc9ae25ff15">Chew 2002</a>, <a href="#kashino_et_al_1998" id="citation_kashino_et_al_1998_67dc9ae25ff17">Kashino et al. 1998</a>, <a href="#margulis_2005" id="citation_margulis_2005_67dc9ae25ff19">Margulis 2005</a>). 
However, it is important to keep in mind the two principal ways in which 
Temperley&#8217;s work differs from earlier studies: it is a systematic approach to 
the analysis of all the main phenomena related to music perception, and it aims to bring a psychological and cognitive reality to the model.</p>

<p>[18] In addition, the author models music perception issues that have 
previously been absent from the literature. A good example is the way Temperley amplifies his Bayesian models to comprehend how humans are able to identify individual notes and musical phrases, both 
of which are significant issues in a realistic cognitive model of music perception.</p>

<p>[19] Once perception processes have been rigorously analyzed and modeled, Temperley 
considers human creativity, trying to model&#8212;always using the Bayesian approach&#8212;the way in which music is composed and how we establish musical styles. 
He explains how probability is used to detect pitch or rhythm, and argues that in order to state that a certain composition is within a specific style we generate probabilities 
from different models, and assign the one with higher probability. This idea may sound strange to music theorists, but Temperley makes a convincing 
case for its application.</p>

<p>[20] Temperley&#8217;s results are not only of theoretical value, they are of 
great pedagogical value as well since he expands his model to explain certain pedagogical practices. Based on 
earlier descriptions of how and when musical structure can be obtained from raw 
auditory data, Temperley presents his concept of &#8220;communicative pressure,&#8221; 
which is a heuristic principle in music theory that avoids the indetermination of the musical structure (181&#8211;207).</p>

<p>[21] All of the chapters are organized in the same format: first, main problems associated with perception and/or 
the generation of a specific musical parameter are formally introduced. Next, the foremost cognitive and mathematical models are presented and discussed, specifying both their applicability and their 
weaknesses. Finally, Temperley introduces his models, which are always justified and compared to the other established models. The book is designed in a cumulative way, so it is 
best if it is read sequentially.</p>

<p style="text-align: center"><b>Who Should Read This Book</b></p>

<p>[22] The interdisciplinary approach and subject matter of this book should appeal to 
a wide range of scholars and researchers, with diverse aims and backgrounds.</p>

<p>[23] Researchers of music and AI are presented with another model that 
simulates music perception and generation processes. However, Temperley&#8217;s model aims 
at empirical realism, which probabilistic AI music models typically lack.</p>

<p>[24] Music theorists will gain insight on some aspects of music structure that are difficult to grasp when the probabilistic nature of music is not taken into account. Once music scholars become accustomed to a Bayesian approach to music, they will find the reliability and scope of the models 
to be of great assistance.</p>

<p>[25] Cognitive scientists interested in music cognition will indeed find this book helpful, 
since it makes a comprehensive case for probability and music perception, and links a mathematical model with empirical results.</p>

<p>[26] Readers lacking a mathematical background on probability should not worry about not understanding the book. As mentioned above, chapter 2 is a basic introduction to conditional probability, and other mathematical concepts are presented and explained when needed. The author himself acknowledges that this book is not an introductory course in probability; he only presents those results from mathematics that will help 
to clarify the book&#8217;s main concepts. The book is self-explanatory. Hence, an interested reader 
(even one without a background in probability) will learn much about mathematics and 
the psychological modeling of music perception and creation.</p>

<!-------------------------------- END Article Body -------------------------------------------->

	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Author Info -------------------------------------------->

	
<hr>

	<p><a name="AUTHORNOTE1"></a>
	
	David Casacuberta<br>
	Universitat Aut&ograve;noma de Barcelona<br>Philosophy Department<br>Barcelona, Spain<br><a href="mailto:david.casacuberta@gmail.com">david.casacuberta@gmail.com</a><br>	
</p>
	
       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Works Cited List -------------------------------------------->

	
	<hr>
	
	<h3><a name="WorksCited">Works Cited</a></h3>
	
	<div id="citediv_chew_2002" class="flyoverdiv">Chew, Elaine. 2002. &#8220;The Spiral Array: An Algorithm for Determining Key Boundaries.&#8221; In <i>Music and Artificial Intelligence,</i> ed. Christina Anagnostopoulou, Miguel Ferrand, and Alan Smaill. Berlin: Springer-Verlag.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="chew_2002"></a>Chew, Elaine. 2002. &#8220;The Spiral Array: An Algorithm for Determining Key Boundaries.&#8221; In <i>Music and Artificial Intelligence,</i> ed. Christina Anagnostopoulou, Miguel Ferrand, and Alan Smaill. Berlin: Springer-Verlag.</p><div id="citediv_clark_1989" class="flyoverdiv">Clark, Andy. 1989. <i>Microcognition: Philosophy, Cognitive Science and Parallel Distributed Processing.</i> Cambridge: The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="clark_1989"></a>Clark, Andy. 1989. <i>Microcognition: Philosophy, Cognitive Science and Parallel Distributed Processing.</i> Cambridge: The MIT Press.</p><div id="citediv_cohen_1962" class="flyoverdiv">Cohen, Joel E. 1962. &#8220;Information Theory and Music.&#8221; <i>Behavioral Science</i> 7, no. 2: 137&#8211;163.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="cohen_1962"></a>Cohen, Joel E. 1962. &#8220;Information Theory and Music.&#8221; <i>Behavioral Science</i> 7, no. 2: 137&#8211;163.</p><div id="citediv_dixon_2001" class="flyoverdiv">Dixon, Simon. 2001. &#8220;Automatic Extraction of Tempo and Beat from Expressive Performances.&#8221; <i>Journal of New Music Research</i> 30: 39&#8211;58.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="dixon_2001"></a>Dixon, Simon. 2001. &#8220;Automatic Extraction of Tempo and Beat from Expressive Performances.&#8221; <i>Journal of New Music Research</i> 30: 39&#8211;58.</p><div id="citediv_dreyfus_1992" class="flyoverdiv">Dreyfus, Hubert L. 1992. <i>What Computers Still Can&#8217;t Do.</i> Cambridge: The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="dreyfus_1992"></a>Dreyfus, Hubert L. 1992. <i>What Computers Still Can&#8217;t Do.</i> Cambridge: The MIT Press.</p><div id="citediv_gardner_1985" class="flyoverdiv">Gardner, Howard. 1985. <i>The Mind's New Science: A History of the Cognitive Revolution.</i> New York: Basic Books.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="gardner_1985"></a>Gardner, Howard. 1985. <i>The Mind's New Science: A History of the Cognitive Revolution.</i> New York: Basic Books.</p><div id="citediv_jackendoff_1983" class="flyoverdiv">Jackendoff, Ray. 1983. <i>Semantics and Cognition.</i> Cambridge: MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="jackendoff_1983"></a>Jackendoff, Ray. 1983. <i>Semantics and Cognition.</i> Cambridge: MIT Press.</p><div id="citediv_johnson-laird_1983" class="flyoverdiv">Johnson-Laird, Philip N. 1983. <i>Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness.</i> Cambridge: Cambridge University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="johnson-laird_1983"></a>Johnson-Laird, Philip N. 1983. <i>Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness.</i> Cambridge: Cambridge University Press.</p><div id="citediv_kashino_et_al_1998" class="flyoverdiv">Kashino, Kunio, Kazuhiro Nakadai, Tomoyoshi Kinoshira, and Hidehiko Tanaka. 1998. &#8220;Application of Bayesian probability networks to musical scene analysis.&#8221; In <i>Computational Auditory Scene Analysis,</i> ed. David F. Rosenthal and Hiroshi G. Okuno. Mahwah, New Jersey: Lawrence Erlbaum Associates.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="kashino_et_al_1998"></a>Kashino, Kunio, Kazuhiro Nakadai, Tomoyoshi Kinoshira, and Hidehiko Tanaka. 1998. &#8220;Application of Bayesian probability networks to musical scene analysis.&#8221; In <i>Computational Auditory Scene Analysis,</i> ed. David F. Rosenthal and Hiroshi G. Okuno. Mahwah, New Jersey: Lawrence Erlbaum Associates.</p><div id="citediv_krumhansl_1990" class="flyoverdiv">Krumhansl, Carol L. 1990. <i>Cognitive Foundations of Musical Pitch.</i> New York: Oxford University Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="krumhansl_1990"></a>Krumhansl, Carol L. 1990. <i>Cognitive Foundations of Musical Pitch.</i> New York: Oxford University Press.</p><div id="citediv_margulis_2005" class="flyoverdiv">Margulis, Elizabeth H. 2005. &#8220;A Model of Melodic Expectation.&#8221; <i>Music Perception</i> 22, no. 4: 663&#8211;714.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="margulis_2005"></a>Margulis, Elizabeth H. 2005. &#8220;A Model of Melodic Expectation.&#8221; <i>Music Perception</i> 22, no. 4: 663&#8211;714.</p><div id="citediv_meyer_1967" class="flyoverdiv">Meyer, Leonard B. 1967. <i>Music, the Arts, and Ideas.</i> Chicago: University of Chicago Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="meyer_1967"></a>Meyer, Leonard B. 1967. <i>Music, the Arts, and Ideas.</i> Chicago: University of Chicago Press.</p><div id="citediv_parncutt_1994" class="flyoverdiv">Parncutt, Richard. 1994. &#8220;A Perceptual Model of Pulse Salience and Metrical Accent in Musical Rhythms.&#8221; <i>Music Perception</i> 11, no. 4: 409&#8211;464.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="parncutt_1994"></a>Parncutt, Richard. 1994. &#8220;A Perceptual Model of Pulse Salience and Metrical Accent in Musical Rhythms.&#8221; <i>Music Perception</i> 11, no. 4: 409&#8211;464.</p><div id="citediv_rumelhart_1989" class="flyoverdiv">Rumelhart, David E. 1989. &#8220;The Architecture of Mind: the Connectist Approach.&#8221; In <i>Mind Design II, Philosophy, Psychology, Artificial Intelligence,</i> ed. John Haugeland. Cambridge: The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="rumelhart_1989"></a>Rumelhart, David E. 1989. &#8220;The Architecture of Mind: the Connectist Approach.&#8221; In <i>Mind Design II, Philosophy, Psychology, Artificial Intelligence,</i> ed. John Haugeland. Cambridge: The MIT Press.</p><div id="citediv_turing_1950" class="flyoverdiv">Turing, A. M. 1950. &#8220;Computing Machinery and Intelligence.&#8221; In <i>Mind Design II, Philosophy, Psychology, Artificial Intelligence,</i> ed. Haugeland, John. Cambridge: The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="turing_1950"></a>Turing, A. M. 1950. &#8220;Computing Machinery and Intelligence.&#8221; In <i>Mind Design II, Philosophy, Psychology, Artificial Intelligence,</i> ed. Haugeland, John. Cambridge: The MIT Press.</p><div id="citediv_varela_1991" class="flyoverdiv">Varela, Francisco, Eleanor Rosch, and Evan Thompson. 1991. <i>The Embodied Mind: Cognitive Science and Human Experience.</i> Cambridge: The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="varela_1991"></a>Varela, Francisco, Eleanor Rosch, and Evan Thompson. 1991. <i>The Embodied Mind: Cognitive Science and Human Experience.</i> Cambridge: The MIT Press.</p><div id="citediv_von_eckardt_1993" class="flyoverdiv">Von Eckardt, Barbara. 1993. <i>What is Cognitive Science?</i> Cambridge: The MIT Press.</div><p style="text-indent: -1em; margin-left: 1em; margin-top: 0em"><a name="von_eckardt_1993"></a>Von Eckardt, Barbara. 1993. <i>What is Cognitive Science?</i> Cambridge: The MIT Press.</p>
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- FOOTER -------------------------------------------->

	<hr>
<h3>Copyright Statement</h3>
<p><h4>Copyright &copy; 2010 by the Society for Music Theory. All rights reserved.</h4></p>
<p class="small">[1] Copyrights for individual items published in  <i>Music Theory Online</i> (<i>MTO</i>) 
are held by their authors. Items appearing in  <i>MTO</i> may be saved and stored in electronic or paper form, and may be shared among individuals for purposes of 
scholarly research or discussion, but may  <i>not</i>  be republished in any form, electronic or print, without prior, written permission from the author(s), and advance 
notification of the editors of  <i>MTO.</i></p>
<p class="small">[2] Any redistributed form of items published in  <i>MTO</i> must include the following information in a form appropriate to the medium in which the items are 
to appear: </p>
<blockquote>
<p class="small">This item appeared in  <i>Music Theory Online</i> in [VOLUME #, ISSUE #] on [DAY/MONTH/YEAR]. It was authored by [FULL NAME, EMAIL ADDRESS], with whose written 
permission it is reprinted here.</p>
</blockquote>
<p class="small">[3] Libraries may archive issues of  <i>MTO</i> in electronic or paper form for public access so long as each issue is stored in its entirety, and no access fee 
is charged. Exceptions to these requirements must be approved in writing by the editors of  <i>MTO,</i> who will act in accordance with the decisions of the Society 
for Music Theory. </p>
<p class="small">This document and all portions thereof are protected by U.S. and international copyright laws. Material contained herein may be copied and/or distributed for research 
purposes only. </p>
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

		
		

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 


<div style="width:55%;float:right"><a href="https://societymusictheory.org">
<img alt="SMT" longdesc="Society for Music Theory" src="https://mtosmt.org/gifs/smtlogo_black.png" width="180"></a></div>
	
<div>
<p style='font-size:1.1rem'>Prepared by Sean Atkinson, Editorial Assistant  


<br>
		
	
					Number of visits:
			<!-- Start of StatCounter Code ----- UPDATE sc_project and sc_security WITH EACH NEW ITEM-->
			<script type="text/javascript">
			var sc_project="5936950"; 
			var sc_invisible=0; 
			var sc_partition=63; 
			var sc_click_stat=1;
			var sc_security="eaef3a89"; 
			var sc_text=2; 
			</script>
			
			<script type="text/javascript" 
			src="https://www.statcounter.com/counter/counter.js">
			</script><noscript><div class="statcounter">
			<a class="statcounter" href="https://www.statcounter.com/">
			<img class="statcounter" src="https://c.statcounter.com/5936950/0/eaef3a89/0/" alt="click tracking" />
			</a></div></noscript>
			<!-- End of StatCounter Code -->
		
	</p><br><br>
</i>		

</div>
</div>
</article>
</body>
</html>

