 
 

<!-------------------------------- HEADER -------------------------------------------->

	  
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> 
<head>

<title> MTO 2.7: Isaacson, Issues in the Study of Similarity in Atonal Music</title>

<link rel="SHORTCUT ICON" href="https://www.mtosmt.org/gifs/favicon.ico">
<link rel="stylesheet" href="https://www.mtosmt.org/scripts/colorbox.css">
<link rel=StyleSheet href="https://www.mtosmt.org/scripts/mto-tufte.css" type="text/css" media=all>
<link rel="stylesheet" href="//code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

<script src="https://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">_uacct = "UA-968147-1"; urchinTracker();</script>

<script type="text/javascript" src="https://www.mtosmt.org/scripts/expandingMenu.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/dropdownMenu.js"></script>
<!--<script language="JavaScript" type="text/javascript" src="https://www.mtosmt.org/scripts/AC_QuickTime.js"></script>-->
<!--<script type="text/javascript" src="https://www.mtosmt.org/scripts/examples.js"></script>-->
<script type="text/javascript" src="https://www.mtosmt.org/scripts/hover.js"></script>  
<script src="https://code.jquery.com/jquery-1.10.2.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
<script src="https://www.mtosmt.org/scripts/colorbox-master/jquery.colorbox.js"></script>
<script type="text/javascript" src="https://www.mtosmt.org/scripts/jQueryRotate.2.2.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script>
MathJax.Hub.Config({
    TeX: { noErrors: { disabled: true } }
});
</script>

  <script>
   $(function () {
      $(document).tooltip({
        position: { my: "center bottom-10", at: "center top", },
    content: function () {
              return $(this).prop('title');
          }
      });
  });
  </script>

  <style>
    .ui-tooltip {
      color: #3a3a3a;
      font: 300 14px/20px "Lato", "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
      max-width: 600px;
      box-shadow: 0 0 7px gray;
    }
    ol.mto-alpha {
        list-style: lower-alpha none outside;
    }
   ol.mto-alpha li {
       margin-bottom: 0.75em;
       margin-left: 2em;
       padding-left: 0.5em;
    }
  </style>

    <script language="Javascript">
        $(document).ready(function() {
            $(".mp3").colorbox({iframe:true, internalWidth:360, width:400, internalHeight:100, rel:'mp3', height:150, opacity:0.1, onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });
            $(".youtube").colorbox({iframe:true, innerWidth:640, innerHeight:390, opacity:0.1, rel:'youtube', onComplete: function(e) {
                $('#colorbox').on({
                    mousedown: function(e){
                        if (~$.inArray(e.target, $('input, textarea, button, a, .no_drag', $('#colorbox')))) return;
                        var os = $('#colorbox').offset(),
                            dx = e.pageX-os.left, dy = e.pageY-os.top;
                        $(document).on('mousemove.drag', function(e){
                            $('#colorbox').offset({ top: e.pageY-dy, left: e.pageX-dx } );
                        });
                    },
                    mouseup: function(){ $(document).unbind('mousemove.drag'); }
                });
            }
        });

      $("a[id^=footnote]").each(function(){
        var fnnum = $(this).attr('id').substring(8);
	var foot_me = '#fndiv'+fnnum;
        $("#footnote" + fnnum).attr('title', $(foot_me).html());

        });


        $("a[id^=citation]").each(function(){
         var separatorPos = $(this).attr('id').lastIndexOf('_');
         var linkid = $(this).attr('id');
         var citeref = $(this).attr('id').substring(8,separatorPos);
         var cite_me = '#citediv'+citeref;
         $("#" + linkid).attr('title', $(cite_me).html());

        });
    });

    </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-968147-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-968147-1');
</script>


<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
 

<meta name="citation_title" content="Issues in the Study of Similarity in Atonal Music">

    <meta name="citation_author" content="Isaacson, Eric J.">
      

<meta name="citation_publication_date" content="1996/11/01">
<meta name="citation_journal_title" content="Music Theory Online">
<meta name="citation_volume" content="2">
<meta name="citation_issue" content="7">

</head>

<body>
<div class="bannertop">
	<a id="smt-link" alt="Society for Music Theory" href="https://www.societymusictheory.org">&nbsp;</a>
</div>
		
		<div style = "height:160px; width:900px; background-image: url('../../gifs/banner_blue_grey_900px.png'); background-repeat: no-repeat; background-position: 0px 0px"></div>
		
<!-------------------------------- MENU -------------------------------------------->

	
<div class="dropdown_menu">

<ul class="fullwidth" id="ddm">
    <li><a href="https://www.mtosmt.org/index.php">MTO Home</a>
    </li>
    <li><a href="https://www.mtosmt.org/issues/mto.24.30.4/toc.30.4.html">Current Issue</a>    </li>
    <li><a href="https://www.mtosmt.org/issues/issues.php"
    	onmouseover="mopen('m3')" 
        onmouseout="mclosetime()">Previous Issues</a>
        <div id="m3" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/index-author.php">By Author</a>
	        <a href="https://www.mtosmt.org/issues/issues.php">By Volume&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
	</li>
	
    <li><a href="https://www.mtosmt.org/docs/authors.html.php"
    	onmouseover="mopen('m4')" 
        onmouseout="mclosetime()">For Authors</a>
        <div id="m4" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/mto-editorial-policy.html">MTO Editorial Policy</a>
	      <a href="https://www.mtosmt.org/docs/mto-style-guidelines.html">MTO Style Guidelines</a>
	      <a href="https://www.mtosmt.org/docs/how-to-submit-an-article-to-mto.html">How to Submit an Article</a>
	      <a href="https://www.mtosmt.org/ojs">Submit Article Online</a>
	      <a href="https://www.mtosmt.org/docs/reviewers.html">Book Review Guidelines</a>
        </div>
	</li>

 <!--   <li><a href="https://www.mtosmt.org/docs/authors.html">Submit</a>
	</li> -->
	
    <li><a href="https://www.mtosmt.org/mto-jobs.php"
    	onmouseover="mopen('m6')" 
        onmouseout="mclosetime()">Jobs</a>
        <div id="m6" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/mto-jobs.php">Current Job Listings</a>
	        <a href="https://www.mtosmt.org/mto-job-post.php">Submit Job Listing</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/docs/diss-index.php"
    	onmouseover="mopen('m7')" 
        onmouseout="mclosetime()">Dissertations</a>
        <div id="m7" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
	        <a href="https://www.mtosmt.org/docs/diss-index.php">All Dissertations</a>
	        <a href="https://www.mtosmt.org/docs/diss-index.php?new=true">New Dissertations</a>
	        <a href="https://www.mtosmt.org/mto-diss-post.php">List Your Dissertation</a>
        </div>
	</li>
    <li><a href="https://www.mtosmt.org/about.html">About</a>
	</li>
<!--    <li><a href="https://www.mtosmt.org/mto_links.html">Journals</a>  
	</li> -->
    <li><a href="https://societymusictheory.org">SMT</a>
	</li>
   <!-- <li><a href="https://societymusictheory.org/announcement/contest-new-mto-logo-2024-02"><span style="color:yellow">Logo Design Contest</span></a>
	</li>-->

</ul>

</div>


<!-------------------------------- TITLE -------------------------------------------->

	<article>

<div id="content">
<a name="Beginning"></a>

			
	<h1 style="width:900px; margin-top:1em">Issues in the Study of Similarity in Atonal Music

	</h1>
	<div style="width:900px">
			<div style="width:100px;float:right;border:none"><a href="https://www.mtosmt.org/classic/mto.96.2.7/mto.96.2.7.isaacson.html"><img src="https://www.mtosmt.org/gifs/mto_classic2.gif"></a></div>
				</div>
				<h2><span style="font-weight: 400"><font size="5"><a style="color:black" href="#AUTHORNOTE1">Eric J. Isaacson</a></font></span></h2><br><br><p><font size='4'>KEYWORDS: similarity, pcsets, atonal, interval-class, analysis</font></p>			
	<div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'><a href="http://www.mtosmt.org/issues/mto.96.2.7/mto.96.2.7.isaacson.pdf">PDF text </a> | <a href="http://www.mtosmt.org/issues/mto.96.2.7/isaacson_examples.pdf">PDF examples </a></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div><div style='width:800px'><div style='float:right; font-size:1.2rem;'></div></div>
		<div style="width:850px">
	<div style="text-align:center; font-size: 1.1rem; margin-bottom:2em;margin-top:4em;margin-right:auto;margin-left:auto;width:870px">
		Volume 2, Number 7, November 1996 <br> Copyright &#0169; 1996 Society for Music Theory	</div>
	</div>

<hr style="width:850px"><br>
<section>
<!-------------------------------- ARTICLE BODY (begin) -------------------------------------->

<p style="text-align: center"><b>Introduction</b></p>

<p>[1] A number of recent studies have considered 
the measurement of
similarity between pcset classes.<sup><a name="FN1REF" href="#FN1" id="footnote1">(1)</a></sup> 
The similarity measures
proposed in these studies all relate <i>set classes</i>. Yet such
measures are of practical value only if they are used in
connection with instances of these set classes, whether they be
created compositionally or identified analytically.<sup><a name="FN2REF" href="#FN2" id="footnote2">(2)</a></sup>   The
context in which a pcset is presented, however, can distort the
features of a set in numerous ways.  Furthermore, pitch is only
one of several aspects of music in which similarity can affect
our judgment of musical meaning.  As David Lewin 
notes in
comments broadcast to mto-list in response to an article
published in this journal by Thomas Demske, the word &ldquo;similarity&rdquo;
is being overworked these days in music analytic settings.<sup><a name="FN3REF" href="#FN3" id="footnote3">(3)</a></sup> 
Lewin objects, for example, when two musical segments are called
&ldquo;similar&rdquo; when in the most perceptually immediate fashions they
may be quite dissimilar.  While I would not go so far as to
suggest banning the word from our discourse (a possibility Lewin
grudgingly admits would likely be impossible), it is certainly
the case that invoking the term &ldquo;similarity&rdquo; without further
qualification is problematic, because any two things will be
similar in some ways and dissimilar in others.  Though I would
argue that there is nothing wrong with the word, per se, it is
clear that we need to be more specific about what we mean when we
say two musical gestures are similar.  Furthermore, we should
acknowledge that we have a poorly developed understanding of the
roles similarity plays in music, and are therefore using crude
tools in a crude fashion.  Refining these tools 
will require
getting acquainted with the theoretical and experimental
literature on similarity in cognitive science and psychology. 
Recent work by Robert Goldstone would provide a good jumping-in
point.<sup><a name="FN4REF" href="#FN4" id="footnote4">(4)</a></sup>  Further exploration of this 
literature lies outside my
intended scope here.</p>

<p>[2] It is the concern with the effects of context on similarity
judgments that motivates this paper.  The paper begins first,
however, with a critical examination of the state of research in
the area of set-class similarity.  Specifically, it articulates
some unresolved issues surrounding this narrowly focussed aspect
of similarity.  After this close-up shot on set-class similarity,
the paper begins to zoom out, considering next how we might take
musical context into account when considering similarity of this
sort.  Zooming further out, it will look at how set class
similarity might interact with similarity in other dimensions
through an analysis of Schoenberg&rsquo;s Op. 19, No. 4.  Finally, the
paper looks at some more general issues relating to context-sensitive similarity, and briefly considers the place of these
fairly limited notions of similarity in the larger context of
human cognition.</p>


<p style="text-align: center"><b>Some Questions</b></p>

<p>[3] We begin by considering the measurement of similarity between
uninstantiated pitch-class sets, or set classes.  &ldquo;Similarity
measures&rdquo; here will mean those functions which propose to measure
similarity of interval-class or other subset content.  I believe
that Rahn&rsquo;s view remains viable: that an effective context-<i>sensitive</i> measure of pcset similarity (what Rahn calls a
&ldquo;theory of harmony&rdquo;) will need to be based on a suitable context-<i>free</i> similarity measure.<sup><a name="FN5REF" href="#FN5" id="footnote5">(5)</a></sup></p>

<p>[4] There are some unresolved questions pertaining to such
measures, however, and we begin by exploring these.  First, what
does it mean for two set classes to be maximally or minimally
similar?   This is important because the various 
similarity
measures described in the literature do not fully agree about
what constitutes maximum and minimum similarity.  For example,
under Lewin&rsquo;s REL, Rahn&rsquo;s ATMEMB, and Castren&rsquo;s RECREL,<sup><a name="FN6REF" href="#FN6" id="footnote6">(6)</a></sup> all
set-class pairs having no common subsets are considered minimally
similar.  My IcVSIM, on the other hand, measures the extent of
&ldquo;skewedness&rdquo; of two set classes&rsquo; difference-vector entries, not
the extent of their shared ic content.  No skew means maximum
similarity; maximum skew (within the possibilities of the 12-pc
SC universe) indicates minimum similarity.   The 
extent of shared
subset content thus only indirectly affects the similarity value. 
For example, the dyads 2-1 and 2-2 have an IcVSIM value of 0.577,
in the 95th percentile of all IcVSIM values.<sup><a name="FN7REF" href="#FN7" id="footnote7">(7)</a></sup>  But 3-1 (0,1,2)
[210000] and 3-10 (0,3,6) [002001], which also have no common
ics, have a value of 1.291 (39%; increasing IcVSIM values
indicate decreasing similarity).  The contrast between these two
views seems somewhat Orwellian: all disjoint SCs are equally
dissimilar (according to one set of functions), but some are more
equally dissimilar than others (according to other functions). 
Nevertheless, there is a certain sensibility to both views.  The
first group of functions says that sets with no common features
cannot be viewed as having any more than absolute minimum
similarity.  IcVSIM, on the other hand, takes the view (though
not explicitly) that, for example, dyad pairs are more likely to
be non-intersecting than trichord pairs.  Thus, 
the fact that a
pair of trichords is non-intersecting is more striking than the
fact that a pair of dyads is.<sup><a name="FN8REF" href="#FN8" id="footnote8">(8)</a></sup></p>

<p>[5] At the other end of the scale, does it make sense for non-identical set classes to be judged maximally similar?  All
measures which base their similarity rating only on interval-class content necessarily judge Z-related set classes to be
maximally similar.  My IcVSIM also considers sets to be maximally
similar whenever their ic-vector entries differ by a constant
value, the vectors thus having the same &ldquo;contour.&rdquo;  Set classes
5-11 (0,2,3,4,7) [222220] and 8Z15 (0,1,2,3,4,6,8,9) [555553]
form such a pair, since adding 3 to each entry of 5-11&rsquo;s ic
vector yields the vector for 8Z15.  Measures based on the
proportional distribution of the vectors&rsquo; contained elements,
such as Castren&rsquo;s RECREL, find pairs like the whole-tone set
class 6-35 (0,2,4,6,8,10) [060603] and its lone pentachordal
subset 5-33 (0,2,4,6,8) [040402] to be maximally similar. 
Lewin&rsquo;s REL_2_ function&mdash;that is, REL using the dyads as the TEST
sets&mdash;also finds these set classes maximally similar.  REL where
TEST contains all set classes does not, however, because 6-35
contains an instance of 6-35 which 5-33 does not.  The REL value
of 0.97 (99.1%) reflects the subtle dissimilarity of these set
classes.  There is no question that this latter pair of set
classes is particularly closely related, but it would seem
desirable to judge non-identical set classes to be less than
maximally similar.  This is not possible when considering only ic
content.</p>

<p>[6] Another question is how similarity should correlate with
inclusion.   In their study of musical contour, 
Marvin and Laprade
assert that &ldquo;one of the most intuitively satisfying ways of
judging similarity in csegs [contour segments] of differing
cardinalities is to count the number of times the smaller cseg is
embedded in the larger&rdquo;.<sup><a name="FN9REF" href="#FN9" id="footnote9">(9)</a></sup>  Given 
that they go on to propose a
number of measures of cseg similarity based on parallel
constructions in pcset theory, I take the authors to suggest that
the embedding of one set in another would also be a suitable
measure of the similarity of those sets.   This 
would be akin to
using Lewin&rsquo;s embedding function (EMB) as a similarity measure
for pcsets.<sup><a name="FN10REF" href="#FN10" id="footnote10">(10)</a></sup>  This assertion is 
unsatisfying for two reasons. 
First, since same-sized sets cannot be embedded in one another,
two different criteria for measuring similarity are required&mdash;one
for same-sized and one for different-sized sets.  Further, the
potential for embedding increases as the difference in the sets&rsquo;
sizes grows.  A six-note set contains only six five-note subsets,
but twenty three-note subsets.  According to this view, a three-note set would,<i>on average</i>, be more similar to a six-note set
than would a five-note set.  Yet my intuition suggests that,  <i>on
average</i>, we would expect five- and six-note sets to be more
closely related than three- and six-note sets because they tend
to have more common features.  The embedding number between two
sets tells us something quite different than does their shared
subset content.  The embedding number sets up a dependent
relationship&mdash;set X is <i>contained in</i> set Y n times.  But in
measuring their similarity, we need to examine the objects on the
same basis.</p>


<p>[7] Metaphorically, we might consider how the relationship
between a set and its (perhaps multiply embedded) subset
parallels the relationship between a daughter and her mother.  To
judge the similarity of a daughter and her mother, we compare
their features: hair color, nose shape, laugh, temperament, and
so on.  Though similarity in any of these features may <i>result</i>
from their genetic lineage, lineage is not the same as
similarity.  After all, there are certainly instances in which
one pair of unrelated people is more similar in appearance than
another pair with shared genes (consider Jay Leno&rsquo;s Dancing Itos,
or the world&rsquo;s overabundance of Elvis look-alikes, for example!). 
Likewise, multiple embedding of set class X in set class Y may
make X and Y similar, but not necessarily more similar than Y and
a third set, Z.  Thus, while the similarity between musical
objects <i>may</i> correlate with an embedding relationship&mdash;and often
does to a large, if not perfect extent&mdash;it need not.</p>

<div style="width:400px;float:right;border:none;margin-left:30px">
                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Table 1</b></p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=0&nonav=true"><img border="1" alt="Table 1 thumbnail" src="isaacson_table1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></div>
<p>[8] One such case is illustrated in <b>Table 1</b>.  The table shows the
relationship between the embedding number (EMB) and two
similarity measures, REL (with all set classes in TEST) and
RECREL (the former of which is based explicitly on the embedding
number), for set class 7-28 and the tetrachords.  The choice of
similarity functions here is insignificant; other functions yield
similar results.  For each function, the tetrachords are sorted
according to their similarity to 7-28.  Nineteen four-note set
classes are subsets of 7-28, with four set classes (4-12, 4-13,
4-18, and 4-27) occurring as many as three times.  Ten
tetrachordal set classes are not subsets of 7-28.  If the
embedding number and the similarity values were maximally
correlated, the embedding numbers would decrease as one moves
down the list.  While those set classes occurring as subsets of
7-28 three times are among those set classes most similar to
7-28, a number of 7-28 subsets are found far down both lists,
including set-class 4-28, which is the tetrachord least similar
to 7-28 according to both functions.  On the other hand, set
classes not found in 7-28 can be found as high as the thirteenth
position in the REL list and tenth in the RECREL list.</p>

<p>
[9] Another issue is whether all instances of an interval class
(or other embedded subset) contained in a set class should be
considered equivalent.  Existing measures of ic similarity, for
example, treat the fourth instance of an ic as having the same
&ldquo;value&rdquo; as the first.   Yet the difference 
between having one
instance compared to zero of some ic is proportionately more
dramatic than the difference between having four compared to
three.<sup><a name="FN11REF" href="#FN11" id="footnote11">(11)</a></sup> With each additional 
instance of an ic, the collection
becomes increasingly saturated with that ic and changes are
(presumably) less noticeable.  Lewin&rsquo;s REL takes this into effect
to some extent.  At the core of REL is the summing of the
geometric means of corresponding subset vector entries: SQRT(X_i_
* Y_i_).  If both sets being compared contain two instances of
some interval class, SQRT(2 * 2) = 2 is added to the summation. 
But if set X has half as many instances of that ic, 1, set Y must
have twice as many, 4, to achieve the same result: SQRT(1 * 4) =
2.  In other words, instances 3 and 4 of set Y are effectively
equal in value to instance 2 of set X.</p>

<div style="width:400px;float:right;border:none;margin-left:30px">
                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 1</b>. Similarity of Set Classes 6-1 and 7-1</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=1&nonav=true"><img border="1" alt="Example 1 thumbnail" src="isaacson_ex1_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></div>
<p>[10] Any of the similarity measures based on 
difference vectors,
such as Morris&rsquo;s SIM <sup><a name="FN12REF" href="#FN12" id="footnote12">(12)</a></sup> and my 
IcVSIM, could be modified to work
with a scaled ic vector which gives less value to each additional
ic instance.  There are many ways one might scale vector entries. 
One would be to replace each ic-vector entry with its square
root.  The vector for set class 6-32 (0,2,4,5,7,9) [143250] would
become [1.00 2.00 1.73 1.41 2.24 0.00].  The first instance of an
ic is therefore worth 1.0, the second is worth SQRT(2) - SQRT(1)
= 0.41, the third is worth SQRT(3) - SQRT(2)=0.32, and so on.  A
pair of vectors scaled in this way could then be supplied as
input to the IcVSIM function (which calculates the standard
deviation of the difference vector entries).   I 
will call the
measure that uses this scaling function ISIM2.<sup><a name="FN13REF" href="#FN13" id="footnote13">(13)</a></sup>  <b>Example 1</b> illustrates how scaling the ic vector in this way
affects the similarity rating between the chromatic six- and
seven-note collections. The first row of graphs shows the ic
vectors for the two sets and their difference vector.  Since the
entries in the difference vector are all 1, IcVSIM judges the
sets to be maximally similar (IcVSIM=0.0).  The second row of
graphs shows the vector entries scaled by the square root
function.  The difference vector at the lower right shows that
the extra ic1 in 7-1 is much less significant (0.21) than the
extra ic6 (1.0).  The difference vector is no longer level and
the similarity value of 0.273 puts these two sets at the 78th
percentile of all ISIM2 values, compared to the 100th percentile
under IcVSIM. </p>


<p>[11] Another factor not taken into account in the existing
similarity literature is the qualitative differences between the
interval classes.  For example, do we hear ic1 and ic2 as equal
in dissimilarity to, say, ic1 and ic5?   Might 
their similarity be
affected by factors such as relative consonance or dissonance? 
(Interval-classes 1, 2, and 6 are relatively dissonant, for
example, while ics 3, 4, and 5 are relatively consonant<sup><a name="FN14REF" href="#FN14" id="footnote14">(14)</a></sup>.  Or
perhaps we might also hear ic4 as more similar to ic2 than to
ic1, for example, because ic4 sounds more &ldquo;whole-tone&rdquo; than
&ldquo;chromatic.&rdquo;  To take this into account, we might create a scaled
ic vector along the lines of the previous paragraph in which each
instance of an interval-class would evoke a weaker sense of the
other ics according to some empirically determined formula.</p>

<p>[12] Having now backed into the issue of perception, let us now
consider it more explicitly.  There is a sometimes unstated, and
always unsubstantiated, claim among the authors of similarity
measures that there is a correlation between theoretical and
actually perceivable similarity.  Morris, for 
example, suggests
his measure would provide &ldquo;a rationale for the selection of sets
that insure predictable degrees of aural similitude.&rdquo;<sup><a name="FN15REF" href="#FN15" id="footnote15">(15)</a></sup>  I have
been more cautious, saying only that a correlation between
similarity measures in the abstract and the music as heard would
be &ldquo;interesting.&rdquo;<sup><a name="FN16REF" href="#FN16" id="footnote16">(16)</a></sup> Castren goes 
furthest, perhaps.   Through
informal and, by his own admission, unscientific testing, with
himself as the lone subject, Castren found that &ldquo;chords derived
from set-class pairs with RECREL values approximately up to 20
seemed to cause an impression of similarity.&rdquo;<sup><a name="FN17REF" href="#FN17" id="footnote17">(17)</a></sup> (RECREL values
range from 0 to 100, with 0 indicating maximum similarity.  A
value of 20 represents approximately the 90th percentile.)  The
lack of any published work which confirms or refutes the
perceptual validity of the similarity measures found in the
literature makes all such claims speculative, however.</p>

<p>[13] Stepping back a little further, we can now consider this
more interesting and more difficult question: How does musical
context affect our judgment of similarity?  Measures of set-<i>class</i> similarity must assume that all pcs in a set are equally
&ldquo;connected&rdquo; and implicitly treat the intervals found between them
as perceptually equivalent.  But once a set class is
instantiated, the salience of its members will vary, and the
connection strength between those pitches will likewise vary,
influencing our aural picture of a musical segment&rsquo;s interval-class content.  Factors that affect the relative salience of
pitches include their registral placement, dynamics, duration,
and timbre.  Lerdahl includes these and other 
salience conditions
in an engaging article in which he proposes an extension of his
and Jackendoff&rsquo;s theory of tonal prolongational structure to the
atonal repertoire.<sup><a name="FN18REF" href="#FN18" id="footnote18">(18)</a></sup>  Morris, in his presentation of a contour
reduction algorithm, grants greater salience status to the first
and last pitches of a melodic line and to registral maxima and
minima.<sup><a name="FN19REF" href="#FN19" id="footnote19">(19)</a></sup>  The salience of the 
interval-classes formed by those
variously salient pitches is also based on a number of factors,
including at least the relative registral, temporal, and order
proximity of the pitches.  (Our reliance on the artificial
partitioning of the musical surface into discrete analytical
objects is another complex issue that is discussed briefly below. 
It is an area which merits further discussion in another forum.)</p>

<div style="width:400px;float:right;border:none;margin-left:30px">
                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 2</b></p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=2&nonav=true"><img border="1" alt="Example 2 thumbnail" src="isaacson_ex2_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge)</font></p></div>

<p>[14] Consider Examples. 2A and B, which show two
instances of the segment [D-<nobr><span style= 'letter-spacing:-0.8px'>F<span style='font-family: Arial Unicode MS, Lucida Sans Unicode;'>&#x266f;</span><span></nobr>-G].  In <b>Example 2A</b>, the pitches are in
a similar register and have equal durations and dynamics.  All
three pitches are relatively equal in salience and the interval
classes found between them (1, 4, and 5) would seem to be
represented approximately equally.  In <b>Example 2B</b>, the middle pitch
is dropped an octave and its dynamic level reduced.  Here the
salience of ics 1 and 4 would seem to be reduced relative to that
of <nobr>ic 5.</nobr></p>

<p>[15] Consider now <b>Examples 2C-E</b> which show three realizations of the
chromatic hexachord, set class 6-1, whose ic vector is [543210]. 
The version in Example 2C&mdash;the set in its &ldquo;prime&rdquo; form&mdash;emphasizes
the set class&rsquo;s chromatic features, though I think we would be
inclined to hear the other ics in roughly the same proportion as
they are found in the ic vector.  In Examples 2D and E, rhythmic
differentiation is introduced.  Because their attack points are
closer together, we are inclined to group a short note with a
following rather than a preceding long note.  Thus, in Example 2D,
the semi-tonal connections, indicated on the example by slurs,
would be heard more strongly than the whole-tone connections. 
This is reversed in Example 2E, where the temporally more proximate
pitches are related by whole step.  We might thus expect a
contextually derived interval-class vector for Example 2D to weight
ic1 more than a similar vector for Example 2E. Likewise, Example 2E&rsquo;s
vector would reflect the greater emphasis on ic2, relative to Example
2D.  The issue of ic weighting in large vertical 
structures is
explored by Robison, who suggests that the greater the registral
distance between two pitches, the less the interval-class between
those pitches should count in the ic vector.<sup><a name="FN20REF" href="#FN20" id="footnote20">(20)</a></sup></p>

<p>[16] We have been concerned to this point with a narrowly defined
notion of &ldquo;similarity&rdquo;&mdash;the intervallic or subset similarity of
pitch-class sets.  As noted at the beginning of this paper,
however, in most Western music musical meaning derives
substantially from the manipulation of similarity and
dissimilarity in various musical dimensions.  Frequently, musical
objects being compared will be similar in some ways and
dissimilar in others.  This is clearly central to such concepts
as &ldquo;motivic development&rdquo; and &ldquo;theme and variations,&rdquo; but it plays
a role in many other ways.  There are numerous other dimensions
along which we might measure similarity.  These would include,
but certainly not be limited to, contour, rhythm, metric
orientation, register, distribution in pitch-space, textural
deployment (vertical versus horizontal), location within the
overall texture, articulation, dynamics, and timbre.   Similarity
in some non-pitch parameters has been the formal subject of
recent studies.  For example, Marvin and Laprade, 
and Morris,
discuss contour similarity, and Marvin discusses rhythmic
contours in the music of Varese.<sup><a name="FN21REF" href="#FN21" id="footnote21">(21)</a></sup> 
  Orpen and Huron discuss how
similarity in various parameters might be measured quantitatively
(giving examples from J. S. Bach) through a single mechanism, the
Damerau-Levenshtein metric for measuring edit distances between
data sets.<sup><a name="FN22REF" href="#FN22" id="footnote22">(22)</a></sup></p>


<p style="text-align: center"><b>Analytic Implications</b></p>

<p>[17] We will focus here specifically on the interaction between
pcset similarity and similarity in other dimensions.  Though
means of quantifying similarity in some of these other dimensions
either exist or could be proposed, my approach is sufficiently
informal to allow a more informal approach.  Examples 3 through 8
are excerpts from Schoenberg&rsquo;s Kleine Klavierstuck, Op. 19, No.
4.  In each example, musical segments are labeled with Forte
numbers, while similarity ratings of various segment pairs are
shown using the ISIM2 function described above.  The ISIM2 value
is followed by the percentile ranking placing that value in the
context of ISIM2 values for all set-class.  The percentile
ranking makes it unnecessary to interpret the ISIM2 values
(which, incidentally, range from 0 to 1.54).  I should note
further that, although the various similarity measures do not
always agree so nicely, all the points I will be making hold,
save one or two, which are noted, if Lewin&rsquo;s REL or Castren&rsquo;s
RECREL functions are used instead.</p>

<div style="width:400px;float:right;border:none;margin-left:30px">
                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 3</b>. Schoenberg, op. 19, no. 4, measures 1&ndash;2</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=3&nonav=true"><img border="1" alt="Example 3 thumbnail" src="isaacson_ex3_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and listen)</font></p>                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 4</b>. Schoenberg, op. 19, no. 4, measures 3&ndash;5</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=4&nonav=true"><img border="1" alt="Example 4 thumbnail" src="isaacson_ex4_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and listen)</font></p>                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 5</b>. Schoenberg, op. 19, no. 4, measures 6&ndash;9</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=5&nonav=true"><img border="1" alt="Example 5 thumbnail" src="isaacson_ex5_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and listen)</font></p>                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 6</b>. Schoenberg, op. 19, no. 4, measures 11&ndash;13</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=6&nonav=true"><img border="1" alt="Example 6 thumbnail" src="isaacson_ex6_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and listen)</font></p>                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 7</b>. Schoenberg, op. 19, no. 4, measure 10</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=7&nonav=true"><img border="1" alt="Example 7 thumbnail" src="isaacson_ex7_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and listen)</font></p>                
<p class='fullwidth' style="text-align: center; margin-top:0em"><b>Example 8</b>. Schoenberg, op. 19, no. 4, measures 3&ndash;5 (right hand)</p><p class='fullwidth' style="text-align: center; margin-bottom:0em"><a class='youtube'  target="blank" href="isaacson_examples.php?id=8&nonav=true"><img border="1" alt="Example 8 thumbnail" src="isaacson_ex8_small.png"></a></p><p class='fullwidth' style="text-align: center; margin-top:0em"><font size="2">(click to enlarge and listen)</font></p></div>
<p>[18] In the opening bars of Op. 19, No. 4 (<b>Example 3</b>),
a melodic fragment is interrupted by a short, accented dyad. 
These two gestures are dissimilar in many ways: one is melodic,
the other harmonic; one extends over two bars, the other lasts
just a 32nd note; the melodic gesture is marked piano, while the
dyad is forte (dynamics are not shown on the example). The
gestures are also dissimilar intervallically.  The melodic line,
set-class 5Z17 (0,1,3,4,8) [212320], lacks only a tritone; the
dyad with which it is juxtaposed is exactly that interval class,
set-class 2-6.  The ISIM2 value for these sets is at just the 5th
percentile, reflecting strong dissimilarity.  These contrasts in
various dimensions establish a theme for the rest of the piece.</p>

<p>[19] The following phrase, shown in <b>Example 4</b>, is like
the first in many ways.  A melodic line&mdash;with more notes than
that of the first phrase, but with an obviously derivative
general contour&mdash;is again interrupted by a shorter harmonic
gesture, marked with a contrasting articulation (legato versus
staccato). The example shows the melodic line divided into two
segments based on the recovery of the initial register upon the
leap up to D5.  As in the first phrase, the contrasting parts of
the texture also contrast with respect to their intervallic
similarity.  The ISIM2 percentile values for the first melodic
segment compared to the two harmonic segments are 8.0% and 12.7%,
while those for the second melodic segment compared to the
harmonic segments are 0.3% and 0.8%.  Consider now, however, the
relation between the two melodic segments.  Although they are
clearly similar in many ways&mdash;rhythm, register, general contour,
articulation&mdash;intervallically they are quite dissimilar (2.9%). 
Likewise, the two components of the harmonic gesture at the end
of the phrase are also very dissimilar (2.5%).  This becomes a
pattern in this piece.  With one exception, adjacent musical
segments which are similar in one or more ways are made up of
distinctly dissimilar set classes.</p>

<p>[20] Examples 5 and 6 show this for two of the three remaining
phrases of the piece.   In <b>Example 5</b>, 
the chords in measure 6 have an ISIM2 value below the 10th percentile, while the ISIM2
percentile for the two melodic segments is 4.0%.<sup><a name="FN23REF" href="#FN23" id="footnote23">(23)</a></sup> Finally, in <b>Example 6</b>, the two chords that accompany the closing
melodic gesture have an ISIM2 value below the 10th percentile. 
Each of the phrases shown in these examples seems to contain a
sense of progression through a change in intervallic content
within segments that are otherwise similar in one or more
&ldquo;surface&rdquo; ways.  Though I am not sure that my hearing isn&rsquo;t being
affected by my analysis, I am certain that I hear the piece going
this way.</p>

<p>[21] The one exception to this pattern occurs in the rapid figure
played between the previous two examples (<b>Example 7</b>). 
The melody here divides into two segments which are similar in
overall contour, register, rhythm, and, uniquely in this piece,
ic content (87.6% according to ISIM2). This measure goes by very
quickly, and again I may be imagining this, but I do not hear the
sense of progression or contrast that I hear in the earlier
examples.</p>

<p>[22] This is a natural point to discuss the crucial role
segmentation plays in analysis of this sort.  The identification
of musical segments can have a powerful effect on similarity
relations.  Adding one note to a five-note segment, for example,
increases the number of interval classes by 50%.  Depending on
the circumstances this can sometimes change substantially the
intervallic makeup of that segment and thereby affect the
relations between that and other segments. The extent of the
effect, however, depends on what interval classes are actually
added.</p>

<p>[23] This issue is explored in Example 8, which reconsiders the
melodic line of measures 3&ndash;5, a passage originally examined in Example 4. 
As shown in <b>Example 8A</b>, this melodic line includes four non-overlapping major seconds (set class 2-2), with an additional M2
between the last two notes. The saturation of this interval
provides considerable unity to the melodic line.  Yet combining
these dyads in different ways, or segmenting the notes in ways
which do not preserve this feature, reveals dissimilarities on a
larger-scale.  In Example 4, for example, this line was divided into
two segments based on recovery of the higher register, 6-2 and
5-33, strongly dissimilar sets (their ISIM2 value ranks at 2.9%).</p>

<p>[24]  Examples 8B-D show three other possible 
segmentations.<sup><a name="FN24REF" href="#FN24" id="footnote24">(24)</a></sup> 
ISIM values and their respective percentiles are shown for each
pair of sets in each segmentation.  In <b>Example 8B</b> the phrase is
divided into four segments based on registral proximity.  Here,
segments 1 and 2 are fairly closely related (76%), as are
segments 3 and 4 (58%).  The apparent dissimilarity between
segments 2 and 3 (21%) is exaggerated by the fact that similarity
ratings involving dyads tend to be quite low for most similarity
functions because of the paucity of interval-classes. 
Nevertheless, segment 3 is notably more similar to segment 4 than
to segment 2.  Considering non-adjacent segments, segments 1 and
3 are as similar as a dyad could be to 3-2, but segments 2 and 4
are decidedly dissimilar (7%), suggesting again a 2+2 grouping of
these segments.  Finally, segments 1 and 4 are also quite
dissimilar (15%).  Though there are some changes in the
particulars, the segmentation in Example 8B bears out the relations
shown in Example 4.</p>

<p>[25] The three-segment partitioning of the melody in <b>Example 8C</b> is
based on the underlying metric framework, the similarity in
articulation between beats 1 and 2 in measure 3, and the quasi-contour
inversion (high dyad&mdash;low dyad &rarr; low dyad&mdash;high dyad) in those
same beats. The resulting melodic set classes, 3-2, 4-23, and
3-6, are again highly dissimilar to one another, with the closest
relation, that between segments 1 and 3, reaching only 15%. 
Including the anacrusis <nobr><span style= 'letter-spacing:-0.8px'>C<span style='font-family: Arial Unicode MS, Lucida Sans Unicode;'>&#x266f;</span><span></nobr> in the first segment seems justified,
given the parallel with the opening of the movement.  Doing so,
however, changes things somewhat.  In particular, the new melodic
segment 1 (including the <nobr><span style= 'letter-spacing:-0.8px'>C<span style='font-family: Arial Unicode MS, Lucida Sans Unicode;'>&#x266f;</span><span></nobr>) and segment 2 are more closely
related, having reached the middle third of ISIM2 values (36%). 
Lewin&rsquo;s RELt function, in fact, rates these sets at the 71st
percentile among RELt values.  (This is so because 4-10 (0235)
and 4-23 (0257) each contain two (025) subsets.)  On the other
hand, including the <nobr><span style= 'letter-spacing:-0.8px'>C<span style='font-family: Arial Unicode MS, Lucida Sans Unicode;'>&#x266f;</span><span></nobr> anacrusis increases the dissimilarity
between segments 1 and 3&mdash;in agreement with the other
segmentations considered so far.  What segmentation 8C shows that
the others do not is the repetition, not just of set class, but
pitch-class content as well, between melodic segment 2 and the
first left-hand segment of measure 4, 4-23 (see Example 4).</p>

<p>[26] One last segmentation, <b>Example 8D</b>, divides the twelve
pitches into three groups of four notes, each beginning with a
16th-note anacrusis. Though this segmentation is perhaps more
salient visually than aurally, it shares with the others a
notable dissimilarity between the earlier segments and the final
segment&mdash;a dissimilarity which persists despite unity within
dimensions such as rhythm, articulation, and small-scale
intervallic organization.  It agrees nicely, however, with the
contour relations among the three segments.  Segments 1 and 2,
which could be termed &ldquo;neutrally&rdquo; similar (47%), share a contour
feature in which their &ldquo;downbeats&rdquo; are approached from below and
&ldquo;resolve&rdquo; downward in the manner of an appoggiatura.  Segment 3,
which is strongly dissimilar to the other segments, is approached
from above and &ldquo;resolves&rdquo; upward.  </p>


<p style="text-align: center"><b>Conclusions</b></p>


<p>[27] In the examples cited above, musical segments with very
similar surface features were often quite dissimilar in terms of
their intervallic makeup.  On the other hand, it is equally
likely that in a given composition musical segments which are
similar in an abstract sense may be realized in very dissimilar
ways in the music.  Just as people have features which may or may
not be similar (mouth and nose shape, eye and hair color, height
and weight, sense of humor, style of laughter, political
leanings, ethnic background, and so on), the similarity of
musical segments will vary across various musical features.  So
how should we deal with the conflicts found in the various
musical parameters with regard to similarity?  We should probably
revel in those conflicts since the tension between similarity and
contrast is central to the way much western art music works.</p>

<p>[28] This argues for continuing to consider similarity on an
individual parameter basis, rather than looking for a generalized
similarity index.  In the detailed study of individual works, a
generalized index would sacrifice much interesting information. 
(Deciding which parameters to include and how to weight them
seems like a impossible task, as well.)  But comparing similarity
in two or more selected dimensions as above might be useful
sometimes.  Specific types of similarity relationships could be
used in defining musical features. <i>Klangfarbenmelodie</i>, for
example, could be defined as a negative correlation between
textural stratum and timbre.  And observations such as those made
above in connection with Op. 19, No. 4, help us understand more
about the musical &ldquo;vectors&rdquo; at work in a piece.  On the other
hand, there are undoubtedly times when a generalized notion of
similarity would be useful, too.  The music history course
exercise of distinguishing the music of Mozart and Haydn is a
categorization problem in which, through a sometimes (but not
always) unconscious comparing of various musical parameters
against remembered features of each composer and his music,
students attribute a piece to one or the other composer. </p>

<p>[29] To these ends, continued work at developing and refining
meaningful similarity measures for different musical parameters
would be useful.  Similarity of various sorts is implicated in
such varied musical concepts as motive, phrase, theme, contrast,
variation, development, recapitulation, cadence, meter, form,
pitch class, interval, set class, instrument families, and
register.  It would be fruitful to evaluate more systematically
the relative significance of the various parameters for evoking
musical meaning, since it is through the manipulation of
similarity in various of these domains that composers communicate
meaning.  In which parameters do similarities and differences
help create structural boundaries in a piece?  Which help to
relate sections to one another?  Which help us understand more
local organizational levels?  Which help to define a particular
composer&rsquo;s style?  Do some seem to work in combination with
others?  The role of context in listening needs more explicit
attention as well.   Goldstone, for example, 
discusses five types
of context which can influence experiments on similarity judgment
(not musical similarity specifially): cultural context,
perspectival context, recent (laboratory) context, concurrently
displayed information, and &ldquo;context that is created by subjects
when there is none.&rdquo;<sup><a name="FN25REF" href="#FN25" id="footnote25">(25)</a></sup>  Though 
some of these questions may be
more interesting to psychologists, we in the music theory
community would do well to keep them in mind as well.</p>

<!-------------------------------- END Article Body -------------------------------------------->

	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Author Info -------------------------------------------->

	
<hr>

	<p><a name="AUTHORNOTE1"></a>
	
	Eric J. Isaacson<br>
	Indiana University<br>Department of Music Theory<br>Music Department<br>Bloomington<br>Indiana 47405<br><a href="mailto:isaacso@indiana.edu">isaacso@indiana.edu</a><br>	
</p>
	
       
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- Works Cited List -------------------------------------------->



	
<!-------------------------------- Footnotes List -------------------------------------------->

		
	<hr>
	
	<h3><a name="Footnotes">Footnotes</a></h3>
	
	<p><a name="FN1">1.</a> Critical reviews of this literature appear in the 
most recent
of these: see Eric Isaacson, &ldquo;Similarity of Interval-class
Content Between Pitch-class Sets: The IcVSIM Relation,&rdquo; <i>Journal
of Music Theory</i>  34 (1990): 1&ndash;28; Isaacson, &ldquo;Similarity of
Interval-class Content Between Pitch-class Sets: The IcVSIM
Relation and Its Application&rdquo; (Ph.D. diss., Indiana University,
1992), esp. pages 12&ndash;135; and Marcus Castren, &ldquo;RECREL: A Similarity
Measure for Pitch-classes&rdquo; (Ph.D. diss., Sibelius Academy
(Helsinki), 1994), esp. pages 16&ndash;100.<br><a href="#FN1REF">Return to text</a></p><p><a name="FN2">2.</a> Robert Morris comments on the compositional potential 
of
similarity relations in &ldquo;A Similarity Index for Pitch-class
Sets,&rdquo; <i>Perspectives of New Music</i> 18 (1979&ndash;80): 446.  In his
dissertation, James Bennighof bases a composition on John Rahn&rsquo;s
similarity function, ATMEMB.  See James M. Bennighof, &ldquo;A Theory
of Harmonic Areas Defined by Pitch-class Sets&rdquo; (Ph.D.
dissertation, University of Iowa, 1984); and John Rahn, &ldquo;Relating
Sets,&rdquo; Perspectives of New Music 18 (1979&ndash;80): 483&ndash;497.<br><a href="#FN2REF">Return to text</a></p><p><a name="FN3">3.</a> Thomas R. Demske, &ldquo;Relating Sets: On Considering a
Computational Model of Similarity Analysis,&rdquo; <i>Music Theory Online</i> 
1.2 (1995).  Lewin&rsquo;s remarks were broadcast to mto-talk, the
electronic discussion forum associated with <i>Music Theory
Online</i>, on 30 March 1995.  The comments are available in the MTO
archive under the filename mto-talk.march95
(ftp://societymusictheory.org/pub/mto/mto-talk/mto-talk.march95).<br><a href="#FN3REF">Return to text</a></p><p><a name="FN4">4.</a> See 
<a href='http://cognitrn.psych.indiana.edu/rgoldsto/papers.html'>http://cognitrn.psych.indiana.edu/rgoldsto/papers.html</a> for
a list of Goldstone&rsquo;s papers.<br><a href="#FN4REF">Return to text</a></p><p><a name="FN5">5.</a> John Rahn, &ldquo;Toward a Theory of Chord 
Progression.&rdquo; <i>In Theory
Only</i> 11/1&ndash;2 (1989): 9.<br><a href="#FN5REF">Return to text</a></p><p><a name="FN6">6.</a> David Lewin, &ldquo;A Response to a Response: On Pcset 
Relatedness,&rdquo; <i>Perspectives of New Music </i> 18 (1979&ndash;80): 498&ndash;502; John Rahn,
&ldquo;Relating Sets,&rdquo; <i>Perspectives of New Music</i> 18 (1979&ndash;80): 483&ndash;497;
and Castren, &ldquo;RECREL,&rdquo; pages 101&ndash;125.<br><a href="#FN6REF">Return to text</a></p><p><a name="FN7">7.</a> Throughout this paper, similarity values are often given with
a percentile figure.  The percentile indicates where that
particular value falls in the context of all values produced by
that similarity function.  For all functions, a percentile of 0
indicates minimum similarity, while a 100 indicates maximum
similarity.<br><a href="#FN7REF">Return to text</a></p><p><a name="FN8">8.</a> Having invoked intuition, we must acknowledge that 
this is a
sticky area, since what we call intuition is largely subjective. 
There will always be situations where people&rsquo;s intuitions differ,
sometimes because of differences in musical experience, sometimes
because of different choices from among multiple possible
hearings.  But while it seems somewhat slippery to insist, &ldquo;Well,
that&rsquo;s how <i>I </i> hear it,&rdquo; absent some objective measure&mdash;whatever
that would be&mdash;it will have to do.<br><a href="#FN8REF">Return to text</a></p><p><a name="FN9">9.</a> Elizabeth West Marvin and Paul Laprade, &ldquo;Relating 
Musical
Contours,&rdquo; <i>Journal of Music Theory</i>31 (1987): 237.<br><a href="#FN9REF">Return to text</a></p><p><a name="FN10">10.</a> David Lewin, &ldquo;Forte&rsquo;s Interval Vector, My Interval 
Function,
and Regener&rsquo;s Common-note Function,&rdquo; <i> Journal of Music Theory</i> 21
(1977): 194&ndash;237.  The embedding number counts the number of
members of an equivalence class contained in some specific set
and forms the basis for Lewin&rsquo;s REL function.  For any set
classes X and Y, REL(X,Y) is based on the suitably scaled
summation, as Z ranges over the sets in TEST, of SQRT(EMB(/Z/,X)
times EMB(/Z/,Y)), where TEST might be the dyad classes to
measure intervallic similarity, or all set classes to measure
total subset similarity (Lewin, &ldquo;A Response to a Response&rdquo;).<br><a href="#FN10REF">Return to text</a></p><p><a name="FN11">11.</a> This point was raised by Michael Friedman in 
response to a
paper I read at the 1992 meeting of the Society for Music Theory.<br><a href="#FN11REF">Return to text</a></p><p><a name="FN12">12.</a> Robert Morris, &ldquo;A Similarity Index for Pitch-class 
Sets.&rdquo;<br><a href="#FN12REF">Return to text</a></p><p><a name="FN13">13.</a> This and other ISIM measures using different scaling
functions are included in my WinSIMS and DosSIMS computer
programs.  These programs are available for download from my
World-Wide Web home page
(<a href='http://ezinfo.ucs.indiana.edu/~isaacso/'>http://ezinfo.ucs.indiana.edu/~isaacso/</a>).  Descriptions of the
scaling functions are also available there.<br><a href="#FN13REF">Return to text</a></p><p><a name="FN14">14.</a> David Huron, &ldquo;Interval-Class Content in Equally 
Tempered
Pitch-Class Sets: Common Scales Exhibit Optimum Tonal
Consonance,&rdquo; <i>Music Perception</i> 11 (1994): 289&ndash;305.<br><a href="#FN14REF">Return to text</a></p><p><a name="FN15">15.</a> Morris, &ldquo;A Similarity Index for Set Classes,&rdquo; page 446.<br><a href="#FN15REF">Return to text</a></p><p><a name="FN16">16.</a> Isaacson, &ldquo;Similarity of Interval-Class Content,&rdquo; Ph.D. diss., page 251.<br><a href="#FN16REF">Return to text</a></p><p><a name="FN17">17.</a> Castren, &ldquo;RECREL,&rdquo; page 148.<br><a href="#FN17REF">Return to text</a></p><p><a name="FN18">18.</a> Fred Lerdahl, &ldquo;Atonal Prolongational 
Structure,&rdquo; <i>Contemporary
Music Review</i> 4 (1989): 65&ndash;88; Fred Lerdahl and Ray Jackendoff,<i>A
Generative Theory of Tonal Music</i> (Cambridge: MIT Press, 
1983).<br><a href="#FN18REF">Return to text</a></p><p><a name="FN19">19.</a> Robert D. Morris, &ldquo;New Directions in the Theory and 
Analysis
of Musical Contour,&rdquo; <i>Music Theory Spectrum</i> 15/2 (1993): 
205&ndash;228.<br><a href="#FN19REF">Return to text</a></p><p><a name="FN20">20.</a> Brian Robison, &ldquo;Modifying Interval-Class Vectors of 
Large
Collections to Reflect Registral Proximity Among Pitches,&rdquo; <i>Music
Theory Online</i> 0.10 (1994).<br><a href="#FN20REF">Return to text</a></p><p><a name="FN21">21.</a> Marvin and Laprade, &ldquo;Relating Musical Contours&rdquo;; 
Robert
Morris,<i>Composition with Pitch-Classes</i> (New Haven: Yale
University Press, 1987), esp. Ch. 2; Elizabeth West Marvin, &ldquo;The
Perception of Rhythm in Non-Tonal Music: Rhythmic Contours in the
Music of Edgard Varese,&rdquo; <i>Music Theory Spectrum</i>  13 (1991): 61&ndash;78.<br><a href="#FN21REF">Return to text</a></p><p><a name="FN22">22.</a> Keith R. Orpen and David Huron, &ldquo;The Measurement of
Similarity in Music: A Quantitative Approach for Non-parametric
Representations,&rdquo; <i>Computers in Music Research</i> 4 (1991): 
1&ndash;44.<br><a href="#FN22REF">Return to text</a></p><p><a name="FN23">23.</a> An alternate segmentation associating the 
anacrusis with the
downbeat chord rather than the following melodic line, and
dividing that melodic line into two 5-note segments, yields very
similar results, except that the melodic segments are more
similar to the chords than in the segmentation used here.  I have
not shown the inter-textural relations to reduce visual clutter
in the example, except the relation between the second melodic
segment, 7-34, and the chord which is heard in measure 8, 4Z29.  This
is the only pair of sets from different dimensions of the texture
that are closely related in this piece.  The question of
alternate segmentations is addressed below.<br><a href="#FN23REF">Return to text</a></p><p><a name="FN24">24.</a> The effects of various musical factors on grouping, 
the
resulting possibility of multiple segmentations, and choosing
among these, is explored effectively in Christopher Hasty,
&ldquo;Segmentation and Process in Post-Tonal Music,&rdquo; <i> Music Theory
Spectrum</i> 3 (1981): 54&ndash;73.<br><a href="#FN24REF">Return to text</a></p><p><a name="FN25">25.</a> Robert. L. Goldstone, &ldquo;Mainstream and Avant-garde
Similarity,&rdquo; <i>Psychologica Belgica</i> 35 (1995): 145&ndash;165.<br><a href="#FN25REF">Return to text</a></p><div id="fndiv1" class="flyoverdiv">Critical reviews of this literature appear in the 
most recent
of these: see Eric Isaacson, &ldquo;Similarity of Interval-class
Content Between Pitch-class Sets: The IcVSIM Relation,&rdquo; <i>Journal
of Music Theory</i>  34 (1990): 1&ndash;28; Isaacson, &ldquo;Similarity of
Interval-class Content Between Pitch-class Sets: The IcVSIM
Relation and Its Application&rdquo; (Ph.D. diss., Indiana University,
1992), esp. pages 12&ndash;135; and Marcus Castren, &ldquo;RECREL: A Similarity
Measure for Pitch-classes&rdquo; (Ph.D. diss., Sibelius Academy
(Helsinki), 1994), esp. pages 16&ndash;100.</div><div id="fndiv2" class="flyoverdiv">Robert Morris comments on the compositional potential 
of
similarity relations in &ldquo;A Similarity Index for Pitch-class
Sets,&rdquo; <i>Perspectives of New Music</i> 18 (1979&ndash;80): 446.  In his
dissertation, James Bennighof bases a composition on John Rahn&rsquo;s
similarity function, ATMEMB.  See James M. Bennighof, &ldquo;A Theory
of Harmonic Areas Defined by Pitch-class Sets&rdquo; (Ph.D.
dissertation, University of Iowa, 1984); and John Rahn, &ldquo;Relating
Sets,&rdquo; Perspectives of New Music 18 (1979&ndash;80): 483&ndash;497.</div><div id="fndiv3" class="flyoverdiv">Thomas R. Demske, &ldquo;Relating Sets: On Considering a
Computational Model of Similarity Analysis,&rdquo; <i>Music Theory Online</i> 
1.2 (1995).  Lewin&rsquo;s remarks were broadcast to mto-talk, the
electronic discussion forum associated with <i>Music Theory
Online</i>, on 30 March 1995.  The comments are available in the MTO
archive under the filename mto-talk.march95
(ftp://societymusictheory.org/pub/mto/mto-talk/mto-talk.march95).</div><div id="fndiv4" class="flyoverdiv">See 
<a href='http://cognitrn.psych.indiana.edu/rgoldsto/papers.html'>http://cognitrn.psych.indiana.edu/rgoldsto/papers.html</a> for
a list of Goldstone&rsquo;s papers.</div><div id="fndiv5" class="flyoverdiv">John Rahn, &ldquo;Toward a Theory of Chord 
Progression.&rdquo; <i>In Theory
Only</i> 11/1&ndash;2 (1989): 9.</div><div id="fndiv6" class="flyoverdiv">David Lewin, &ldquo;A Response to a Response: On Pcset 
Relatedness,&rdquo; <i>Perspectives of New Music </i> 18 (1979&ndash;80): 498&ndash;502; John Rahn,
&ldquo;Relating Sets,&rdquo; <i>Perspectives of New Music</i> 18 (1979&ndash;80): 483&ndash;497;
and Castren, &ldquo;RECREL,&rdquo; pages 101&ndash;125.</div><div id="fndiv7" class="flyoverdiv">Throughout this paper, similarity values are often given with
a percentile figure.  The percentile indicates where that
particular value falls in the context of all values produced by
that similarity function.  For all functions, a percentile of 0
indicates minimum similarity, while a 100 indicates maximum
similarity.</div><div id="fndiv8" class="flyoverdiv">Having invoked intuition, we must acknowledge that 
this is a
sticky area, since what we call intuition is largely subjective. 
There will always be situations where people&rsquo;s intuitions differ,
sometimes because of differences in musical experience, sometimes
because of different choices from among multiple possible
hearings.  But while it seems somewhat slippery to insist, &ldquo;Well,
that&rsquo;s how <i>I </i> hear it,&rdquo; absent some objective measure&mdash;whatever
that would be&mdash;it will have to do.</div><div id="fndiv9" class="flyoverdiv">Elizabeth West Marvin and Paul Laprade, &ldquo;Relating 
Musical
Contours,&rdquo; <i>Journal of Music Theory</i>31 (1987): 237.</div><div id="fndiv10" class="flyoverdiv">David Lewin, &ldquo;Forte&rsquo;s Interval Vector, My Interval 
Function,
and Regener&rsquo;s Common-note Function,&rdquo; <i> Journal of Music Theory</i> 21
(1977): 194&ndash;237.  The embedding number counts the number of
members of an equivalence class contained in some specific set
and forms the basis for Lewin&rsquo;s REL function.  For any set
classes X and Y, REL(X,Y) is based on the suitably scaled
summation, as Z ranges over the sets in TEST, of SQRT(EMB(/Z/,X)
times EMB(/Z/,Y)), where TEST might be the dyad classes to
measure intervallic similarity, or all set classes to measure
total subset similarity (Lewin, &ldquo;A Response to a Response&rdquo;).</div><div id="fndiv11" class="flyoverdiv">This point was raised by Michael Friedman in 
response to a
paper I read at the 1992 meeting of the Society for Music Theory.</div><div id="fndiv12" class="flyoverdiv">Robert Morris, &ldquo;A Similarity Index for Pitch-class 
Sets.&rdquo;</div><div id="fndiv13" class="flyoverdiv">This and other ISIM measures using different scaling
functions are included in my WinSIMS and DosSIMS computer
programs.  These programs are available for download from my
World-Wide Web home page
(<a href='http://ezinfo.ucs.indiana.edu/~isaacso/'>http://ezinfo.ucs.indiana.edu/~isaacso/</a>).  Descriptions of the
scaling functions are also available there.</div><div id="fndiv14" class="flyoverdiv">David Huron, &ldquo;Interval-Class Content in Equally 
Tempered
Pitch-Class Sets: Common Scales Exhibit Optimum Tonal
Consonance,&rdquo; <i>Music Perception</i> 11 (1994): 289&ndash;305.</div><div id="fndiv15" class="flyoverdiv">Morris, &ldquo;A Similarity Index for Set Classes,&rdquo; page 446.</div><div id="fndiv16" class="flyoverdiv">Isaacson, &ldquo;Similarity of Interval-Class Content,&rdquo; Ph.D. diss., page 251.</div><div id="fndiv17" class="flyoverdiv">Castren, &ldquo;RECREL,&rdquo; page 148.</div><div id="fndiv18" class="flyoverdiv">Fred Lerdahl, &ldquo;Atonal Prolongational 
Structure,&rdquo; <i>Contemporary
Music Review</i> 4 (1989): 65&ndash;88; Fred Lerdahl and Ray Jackendoff,<i>A
Generative Theory of Tonal Music</i> (Cambridge: MIT Press, 
1983).</div><div id="fndiv19" class="flyoverdiv">Robert D. Morris, &ldquo;New Directions in the Theory and 
Analysis
of Musical Contour,&rdquo; <i>Music Theory Spectrum</i> 15/2 (1993): 
205&ndash;228.</div><div id="fndiv20" class="flyoverdiv">Brian Robison, &ldquo;Modifying Interval-Class Vectors of 
Large
Collections to Reflect Registral Proximity Among Pitches,&rdquo; <i>Music
Theory Online</i> 0.10 (1994).</div><div id="fndiv21" class="flyoverdiv">Marvin and Laprade, &ldquo;Relating Musical Contours&rdquo;; 
Robert
Morris,<i>Composition with Pitch-Classes</i> (New Haven: Yale
University Press, 1987), esp. Ch. 2; Elizabeth West Marvin, &ldquo;The
Perception of Rhythm in Non-Tonal Music: Rhythmic Contours in the
Music of Edgard Varese,&rdquo; <i>Music Theory Spectrum</i>  13 (1991): 61&ndash;78.</div><div id="fndiv22" class="flyoverdiv">Keith R. Orpen and David Huron, &ldquo;The Measurement of
Similarity in Music: A Quantitative Approach for Non-parametric
Representations,&rdquo; <i>Computers in Music Research</i> 4 (1991): 
1&ndash;44.</div><div id="fndiv23" class="flyoverdiv">An alternate segmentation associating the 
anacrusis with the
downbeat chord rather than the following melodic line, and
dividing that melodic line into two 5-note segments, yields very
similar results, except that the melodic segments are more
similar to the chords than in the segmentation used here.  I have
not shown the inter-textural relations to reduce visual clutter
in the example, except the relation between the second melodic
segment, 7-34, and the chord which is heard in measure 8, 4Z29.  This
is the only pair of sets from different dimensions of the texture
that are closely related in this piece.  The question of
alternate segmentations is addressed below.</div><div id="fndiv24" class="flyoverdiv">The effects of various musical factors on grouping, 
the
resulting possibility of multiple segmentations, and choosing
among these, is explored effectively in Christopher Hasty,
&ldquo;Segmentation and Process in Post-Tonal Music,&rdquo; <i> Music Theory
Spectrum</i> 3 (1981): 54&ndash;73.</div><div id="fndiv25" class="flyoverdiv">Robert. L. Goldstone, &ldquo;Mainstream and Avant-garde
Similarity,&rdquo; <i>Psychologica Belgica</i> 35 (1995): 145&ndash;165.</div>	
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

	
<!-------------------------------- FOOTER -------------------------------------------->

	<hr>
<h3>Copyright Statement</h3>
<p><h4>Copyright &copy; 1996 by the Society for Music Theory. All rights reserved.</h4></p>
<p class="small">[1] Copyrights for individual items published in  <i>Music Theory Online</i> (<i>MTO</i>) 
are held by their authors. Items appearing in  <i>MTO</i> may be saved and stored in electronic or paper form, and may be shared among individuals for purposes of 
scholarly research or discussion, but may  <i>not</i>  be republished in any form, electronic or print, without prior, written permission from the author(s), and advance 
notification of the editors of  <i>MTO.</i></p>
<p class="small">[2] Any redistributed form of items published in  <i>MTO</i> must include the following information in a form appropriate to the medium in which the items are 
to appear: </p>
<blockquote>
<p class="small">This item appeared in  <i>Music Theory Online</i> in [VOLUME #, ISSUE #] on [DAY/MONTH/YEAR]. It was authored by [FULL NAME, EMAIL ADDRESS], with whose written 
permission it is reprinted here.</p>
</blockquote>
<p class="small">[3] Libraries may archive issues of  <i>MTO</i> in electronic or paper form for public access so long as each issue is stored in its entirety, and no access fee 
is charged. Exceptions to these requirements must be approved in writing by the editors of  <i>MTO,</i> who will act in accordance with the decisions of the Society 
for Music Theory. </p>
<p class="small">This document and all portions thereof are protected by U.S. and international copyright laws. Material contained herein may be copied and/or distributed for research 
purposes only. </p>
	   
	<div style="height:24px;width:150px;background-color:#4c7381;float:left;text-align: center;vertical-align: middle;line-height: 24px;">
		&nbsp;&nbsp;&nbsp;
		<a style="color:white;" onmouseover="this.style.color='#0000ff';text-decoration:none" 
		onmouseout="this.style.color='white';" href="#Beginning">Return to beginning</a>
		&nbsp;&nbsp;&nbsp;
	</div><br><br>

		
		

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 


<div style="width:55%;float:right"><a href="https://societymusictheory.org">
<img alt="SMT" longdesc="Society for Music Theory" src="https://mtosmt.org/gifs/smtlogo_black.png" width="180"></a></div>
	
<div>
<p style='font-size:1rem'>Prepared by Nicholas S. Blanchard and Tahirih Motazedian, Editorial Assistants  


<br>
		
	
		
	</p><br><br>
</i>		

</div>
</div>
</article>
</body>
</html>

